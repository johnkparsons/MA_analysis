---
title: "MA_analysis_rmd"
author: "John Parsons"
date: "Compiled on `r format(Sys.Date(), '%B %d, %Y`"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Setup
```{r, eval=FALSE}
#install.packages(c("tidyverse", "dplyr", "lme4", "glmmTMB", "effects", "DHARMa", "MuMIn", "plyr", "broom.mixed", "ggthemes", "padr", "ptest", "maps", "mapdata", "hexbin", "car", "lubridate", "slider", "hms", "olsrr", "bbmle", "emmeans", "gt", "webshot", "cowplot", "jtools", "ggstance", "AER", "mgcv", "itsadug", "installr", "FSA"))
#install.packages("hexbin")
library(tidyverse)
slice <- dplyr::slice
#library(plyr); library(dplyr)
library(lme4) #modelling
library(glmmTMB) #modelling
library(DHARMa) #model diagnostics
library(sjstats)
library(effects)
library(broom.mixed)
library(MuMIn)
library(ggthemes) #visualizations
library(RColorBrewer) #visualizations
library(padr)
library(ptest)
library(maps)
library(mapdata)
library(ggmap)
library(hexbin) #heatmaps
library(zoo)
library(car)
library(lubridate) #dates
library(slider)
library(hms)
year <- lubridate::year
week <- lubridate::week
library(olsrr)
library(bbmle) #AIC tables
library(emmeans)#effects testing
library(gt)#nice tables
library(webshot) #saving gt tables
library(cowplot) #moo
library(simfit) #simulating models
library(jtools)
library(ggstance)
library(AER)
library(mgcv) #GAMs
library(visreg) #visualizing GAMs
library(itsadug)
library(installr)
library(FSA)
library(fifer)
library(multcomp)
#webshot::install_phantomjs() 
#citation("ptest")

updateR()
citation()
RStudio.Version()
```

===========================================================================

# Data Tidying

## 2019 Data Tidying

### Flight-Level Data Tidying (1 row = 1 day) - 2019
```{r}
dat_2019 <- read.csv("data_raw/2019_flight_data.csv")
#view(dat_2019)

dat_2019 <- dat_2019 %>% 
  dplyr::select(!c(3:9,13,14,16:17,20,21,23:25,28,29)) %>% 
  mutate(total_unique = transect_total) %>% 
  mutate(transect_datetime = as_datetime(transect_datetime))

dat_2019[dat_2019 == ""] <- NA

#dat_2019$date <- as.Date(dat_2019$date, "%m/%d/%Y")

dat_2019 <- dat_2019 %>%
  mutate(datetime = as_datetime(transect_datetime)) %>%
  mutate(date_hour = round_date(as_datetime(datetime), "hour"))
```

### Calculating density (sharks/km2) and effort (sharks/km2/min) - 2019
```{r}
dat_2019 <- dat_2019 %>%
  mutate(transect_area_km2 = transect_area_m2/1000000) %>% 
  mutate(transect_duration_min = transect_duration_sec/60) %>% 
  mutate(transect_density_effort = 
         transect_total/(transect_area_km2*transect_duration_min)) %>% 
  mutate(transect_density = transect_total/transect_area_km2) #%>% 
  #mutate(transect_small_density = if_else(transect_small == 0, 0,               #transect_small/transect_effort)) %>%
  #mutate(transect_large_density = if_else(transect_large == 0,0,
                                          #transect_large/transect_effort))
#view(dat_2019)
```

### Reading in tide data (Station 9411340) - 2019
```{r}
tide_dat_2019 <- read.csv("data_raw/2019_tide_dat.txt")
#View(tide_dat_2019)
#str(tide_dat_2019)

tide_dat_2019 <- tide_dat_2019 %>% 
  rename(time = 2) %>% 
  mutate(time = as_datetime(time, format = "%H:%M")) %>%
  mutate(time = substring(time, 12)) %>% 
  mutate(date = as_datetime(Date)) %>% 
  unite(date_hour, c(date, time), sep = " ") %>% 
  mutate(date_hour = as_datetime(date_hour)) %>% 
  select(-c(1,3,4)) %>%
  rename(tide = 2)

dat_2019 <- left_join(dat_2019, tide_dat_2019, by = "date_hour")
#view(dat_2019)
```

### Reading in channel buoy data (Station 46053) - 2019
```{r}
channel_dat_2019_raw <- read.table("data_raw/2019_buoy_dat.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))
#str(channel_dat_2019_raw)
#View(channel_dat_2019_raw)

channel_dat_2019 <- channel_dat_2019_raw %>%
                      mutate_if(is.character, as.numeric) %>% 
                      mutate_at(vars(WVHT, DPD, APD), ~na_if(., 99)) %>%  
                      mutate_at(vars(MWD, ATMP, WTMP, DEWP), ~na_if(., 999)) %>%
                      group_by(MM, DD, hh) %>% 
                      summarize_at(vars(3:13), mean, na.rm = TRUE) %>%
                      ungroup() %>% 
                      filter(MM > 4) %>% 
                      add_column(year = 2019, .before = 1) %>% 
                      mutate(datetime = make_datetime(year, MM, DD, hh)) %>% 
                      mutate(datetime = with_tz(datetime, "US/Pacific")) %>%
                      mutate(date_hour = round_date(datetime, "hour")) %>% 
                      select(!datetime) %>% 
                      select(!c(1:4)) %>% 
                      mutate(max_wtemp_previous_24 = 
                              slide_dbl(WTMP, max, .before = 24)) %>% 
                      mutate(min_wtemp_previous_24 = 
                              slide_dbl(WTMP, min, .before = 24)) %>% 
                      mutate(mean_wtemp_previous_24 = 
                              slide_dbl(WTMP, mean, .before = 24))
#view(channel_dat_2019)

#dat_2019$date_hour <- as_datetime(dat_2019$date_hour)
flights_plus_channel_dat_2019 <- left_join(dat_2019, channel_dat_2019, by = "date_hour")

dat_2019 <- flights_plus_channel_dat_2019 %>%
  mutate(wtemp_2 = mean_wtemp_previous_24^2)

#view(dat_2019)
```

### Size Data Tidying (1 row = 1 individual) - 2019
```{r}
size_dat_2019 <- read.csv("data_raw/size_dat_2019.csv")
#view(size_dat_2019)

size_dat_2019 <- size_dat_2019 %>% 
  select(1:19) %>% 
  dplyr::slice(-(48:49))

size_dat_2019 <- size_dat_2019 %>%
                  mutate(length_adj_NO_RES = as.character(length_adj_NO_RES)) %>% 
                  mutate(length_adj_m = length_adj/3.2808) %>% 
                  mutate(length_raw_m = length_raw/3.2808)

size_dat_2019 %>%
  filter(length_adj_m >= 3) %>% 
  filter(unique == "Y") %>% 
  nrow()
```
*no adults with unadjusted lengths, 15 with adjusted lengths!

## 2020 Data Tidying

### Flight-Level Data Tidying - 2020
```{r}
dat_2020 <- read.csv("data_raw/2020_flight_data.csv")
#view(dat_2020)

#dat_2020$date <- as_date(as.Date(dat_2020$date, "%m/%d/%Y"))

dat_2020$transect_total <- as.numeric(dat_2020$transect_total)

dat_2020$transect_datetime <- as_datetime(dat_2020$transect_datetime)
dat_2020$manual_datetime <- as_datetime(dat_2020$manual_datetime)

dat_2020 <- dat_2020 %>%
  mutate(datetime = as_datetime(
    pmin(transect_datetime, manual_datetime, na.rm = TRUE))) %>% 
  mutate(date_hour = round_date(datetime, "hour")) %>% 
  select(!c(2:8,13,14,16,17,20,21,25,26,28,29:31,38,39))
```

### Calculating density (sharks/km2) and effort (sharks/km2/min) - 2020
```{r}
dat_2020 <- dat_2020 %>%
  mutate(transect_area_km2 = transect_area_m2/1000000) %>% 
  mutate(transect_duration_min = transect_duration_sec/60) %>% 
  mutate(transect_effort_density =
         transect_total/(transect_area_km2*transect_duration_min)) %>% 
  mutate(transect_density = transect_total/transect_area_km2) #%>% 
  #mutate(transect_small_density = transect_small/transect_effort) %>%
  #mutate(transect_large_density = transect_large/transect_effort)

dat_2020 <- dat_2020 %>%
  mutate(manual_area_km2 = manual_area_m2/1000000) %>% 
  mutate(manual_duration_min = manual_duration_sec/60) %>% 
  mutate(manual_density_effort =
         manual_total/(manual_area_km2*manual_duration_min)) %>% 
  mutate(manual_density = manual_unique/manual_area_km2) #%>% 
  #mutate(manual_small_density = manual_small/manual_effort) %>%
  #mutate(manual_large_density = manual_large/manual_effort)
```

### Reading in tide data (Station 9411340)- 2020
```{r}
tide_dat_2020 <- read.csv("data_raw/2020_tide_dat.txt")
#View(tide_dat_2020)
#str(tide_dat_2020)

tide_dat_2020 <- tide_dat_2020 %>% 
  rename(time = 2) %>% 
  mutate(time = as_datetime(time, format = "%H:%M")) %>%
  mutate(time = substring(time, 12)) %>% 
  mutate(date = as_datetime(Date)) %>% 
  unite(date_hour, c(date, time), sep = " ") %>% 
  mutate(date_hour = as_datetime(date_hour)) %>%
  select(-c(1,3,4)) %>%
  rename(tide = 2)

tide_added_2020 <- left_join(dat_2020, tide_dat_2020, by = "date_hour")
#view(tide_added_2020)
```

### Reading in channel buoy data (Station 46053) - 2020
```{r}
channel_dat_2020_raw <- read.table("data_raw/2020_buoy_dat.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))
#str(channel_dat_2020_raw)
#View(channel_dat_2020_raw)

channel_dat_2020 <- channel_dat_2020_raw %>%
  mutate_if(is.character, as.numeric) %>% 
  mutate_at(vars(WVHT, DPD, APD), ~na_if(., 99)) %>%  
  mutate_at(vars(MWD, ATMP, WTMP, DEWP), ~na_if(., 999)) %>%
  group_by(MM, DD, hh) %>% 
  summarize_at(vars(3:13), mean, na.rm = TRUE) %>%
  ungroup() %>% 
  filter(MM > 4) %>% 
  add_column(year = 2020, .before = 1) %>% 
  mutate(datetime = make_datetime(year, MM, DD, hh)) %>% 
  mutate(datetime = with_tz(datetime, "US/Pacific")) %>%
  mutate(date_hour = round_date(datetime, "hour")) %>% 
  select(!datetime) %>% 
  select(!c(1:4)) %>%
  mutate(max_wtemp_previous_24 = slide_dbl(WTMP, max, .before = 24)) %>% 
  mutate(min_wtemp_previous_24 = slide_dbl(WTMP, min, .before = 24)) %>% 
  mutate(mean_wtemp_previous_24 = slide_dbl(WTMP, mean, .before = 24))

#tide_added_2020$date_hour <- as_datetime(tide_added_2020$date_hour)
flights_plus_channel_dat_2020 <- left_join(tide_added_2020, channel_dat_2020, by = "date_hour")
#view(flights_plus_channel_dat_2020)

dat_2020 <- flights_plus_channel_dat_2020 %>%
  mutate(wtemp_2 = mean_wtemp_previous_24^2) 
#view(dat_2020)
```

### Size Data Tidying (1 row = 1 individual) - 2020
```{r}
size_dat_2020 <- read.csv("data_raw/size_dat_2020.csv")
#view(size_dat_2020)

size_dat_2020 <- size_dat_2020 %>%
                  slice(-363) %>%
                  mutate(length_raw = as.numeric(length_raw)) %>%
                  mutate(length_adj = as.numeric(length_adj)) %>% 
                  mutate(order = as.numeric(order)) %>% 
                  mutate(length_adj_m = length_adj/3.2808) %>% 
                  mutate(length_raw_m = length_raw/3.2808) %>%
                  rename(video_YN = video) %>% 
                  rename(tagged = tagged.) %>%
                  mutate(depth.correction.factor =
                         as.numeric(depth.correction.factor)) %>% 
                  mutate(asl.correction.factor =
                           as.numeric(asl.correction.factor))

size_dat_2020 %>%
  filter(unique == "Y") %>%
  filter(length_raw_m >= 3) %>% 
  nrow()
#18 adults unadjusted
#48 adults adjusted

size_dat_2020 %>% 
  filter(unique == "Y") %>% 
  filter(length_raw_m < 3) %>% 
  nrow()
#171 juveniles unadjusted
#141 juveniles adjusted
```
* roughly 10x more juveniles than adults (uncorrected lengths)

## 2021 Data Tidying

### Flight-Level Data Tidying - 2021
```{r}
dat_2021 <- read.csv("data_raw/2021_flight_data.csv")
#view(dat_2021)

#dat_2021 <- dplyr::rename(dat_2021, date = 1)
#dat_2021$date <- as_date(as.Date(dat_2021$date, "%m/%d/%Y"))

dat_2021$transect_total <- as.numeric(dat_2021$transect_total)
dat_2021$manual_unique <- as.numeric(dat_2021$manual_unique)
dat_2021$manual_total <- as.numeric(dat_2021$manual_total)

dat_2021$transect_datetime <- as_datetime(dat_2021$transect_datetime)
dat_2021$manual_datetime <- as_datetime(dat_2021$manual_datetime)

dat_2021 <- dat_2021 %>%
  select(!c(3:6,9,10,15,16,18,19,22,23,29:32,39:41)) %>% 
  mutate(datetime = as_datetime(
    pmin(transect_datetime, manual_datetime, na.rm = TRUE))) %>% 
  mutate(date_hour = round_date(datetime, "hour"))
```

### Calculating density (sharks/km2) and effort (sharks/km2/min) - 2021
```{r}
dat_2021 <- dat_2021 %>%
  mutate(transect_area_km2 = transect_area_m2/1000000) %>% 
  mutate(transect_duration_min = transect_duration_sec/60) %>% 
  mutate(transect_density_effort =
         transect_total/(transect_area_km2*transect_duration_min)) %>% 
  mutate(transect_density = transect_total/transect_area_km2) #%>% 
  #mutate(transect_small_density = transect_small/transect_effort) %>%
  #mutate(transect_large_density = transect_large/transect_effort)

dat_2021 <- dat_2021 %>%
  mutate(manual_area_km2 = manual_area_m2/1000000) %>% 
  mutate(manual_duration_min = manual_duration_sec/60) %>% 
  mutate(manual_density_effort = 
         manual_unique/(manual_area_km2*manual_duration_min)) %>% 
  mutate(manual_density = manual_unique/manual_area_km2) #%>% 
  #mutate(manual_small_density = manual_small/manual_effort) %>%
  #mutate(manual_large_density = manual_large/manual_effort)
```

### Reading in tide data (Station 9411340) - 2021
```{r}
tide_dat_2021 <- read.csv("data_raw/2021_tide_dat.txt")
#View(tide_dat_2021)
#str(tide_dat_2021)
#Local time

tide_dat_2021 <- tide_dat_2021 %>% 
  rename(time = 2) %>% 
  mutate(time = as_datetime(time, format = "%H:%M")) %>%
  mutate(time = substring(time, 12)) %>% 
  mutate(date = as_datetime(Date)) %>% 
  unite(date_hour, c(date, time), sep = " ") %>% 
  mutate(date_hour = as_datetime(date_hour)) %>% 
  select(-c(1,3,4)) %>%
  rename(tide = 2)

dat_2021 <- left_join(dat_2021, tide_dat_2021, by = "date_hour")
#view(dat_2021)
```

### Reading in channel buoy data (Station 46053) - 2021
```{r}
channel_dat_2021_jan <- read.table("data_raw/2021_buoy_dat_jan.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_feb <- read.table("data_raw/2021_buoy_dat_feb.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_mar <- read.table("data_raw/2021_buoy_dat_mar.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_apr <- read.table("data_raw/2021_buoy_dat_apr.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_may <- read.table("data_raw/2021_buoy_dat_may.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_jun <- read.table("data_raw/2021_buoy_dat_jun.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_jul <- read.table("data_raw/2021_buoy_dat_jul.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_aug <- read.table("data_raw/2021_buoy_dat_aug.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_sep <- read.table("data_raw/2021_buoy_dat_sep.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_oct <- read.table("data_raw/2021_buoy_dat_oct.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_nov <- read.table("data_raw/2021_buoy_dat_nov.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_dec <- read.table("data_raw/2021_buoy_dat_dec.txt", header = FALSE, 
                                   col.names = c("#YY","MM","DD","hh","mm",
                                                 "WDIR","WSPD","GST","WVHT",
                                                 "DPD","APD","MWD","PRES",
                                                 "ATMP","WTMP","DEWP","VIS",
                                                 "TIDE"))

channel_dat_2021_raw <- dplyr::bind_rows(channel_dat_2021_jan, channel_dat_2021_feb, channel_dat_2021_mar, channel_dat_2021_apr, channel_dat_2021_may, channel_dat_2021_jun, channel_dat_2021_jul, channel_dat_2021_aug, channel_dat_2021_sep, channel_dat_2021_oct, channel_dat_2021_nov, channel_dat_2021_dec)
#View(channel_dat_2021_raw)

channel_dat_2021 <- channel_dat_2021_raw %>%
  mutate_if(is.character, as.numeric) %>% 
  mutate_at(vars(WVHT, DPD, APD), ~na_if(., 99)) %>%  
  mutate_at(vars(MWD, ATMP, WTMP, DEWP), ~na_if(., 999)) %>%
  group_by(MM, DD, hh) %>% 
  summarize_at(vars(3:13), mean, na.rm = TRUE) %>%
  ungroup() %>% 
  filter(MM > 3) %>% 
  add_column(year = 2021, .before = 1) %>% 
  mutate(date_hour = make_datetime(year, MM, DD, hh)) %>% 
  mutate(date_hour = with_tz(date_hour, "US/Pacific")) %>%
  select(!c(1:4)) %>%
  mutate(max_wtemp_previous_24 = slide_dbl(WTMP, max, .before = 24)) %>% 
  mutate(min_wtemp_previous_24 = slide_dbl(WTMP, min, .before = 24)) %>% 
  mutate(mean_wtemp_previous_24 = slide_dbl(WTMP, mean, .before = 24))
#View(channel_dat_2021)

#dat_2021$date_hour <- as_datetime(dat_2021$date_hour)
flights_plus_channel_dat_2021 <- left_join(dat_2021, channel_dat_2021, by = "date_hour")
#View(flights_plus_channel_dat_2021)

dat_2021 <- flights_plus_channel_dat_2021 %>%
  mutate(wtemp_2 = mean_wtemp_previous_24^2) 
```

### Size Data Tidying (1 row = 1 individual) - 2021
```{r}
size_dat_2021 <- read.csv("data_raw/size_dat_2021.csv")
#view(size_dat_2021)

size_dat_2021 <- size_dat_2021 %>%
                  mutate(length_raw = as.numeric(length_raw)) %>%
                  mutate(length_adj = as.numeric(length_adj)) %>%
                  mutate(length_adj_m = length_adj/3.2808) %>% 
                  mutate(length_raw_m = length_raw/3.2808) %>%
                  mutate(lat = as.numeric(lat)) %>% 
                  rename(video_YN = video) %>% 
                  rename(tagged = tagged.) %>%
                  mutate(depth.correction.factor =
                         as.numeric(depth.correction.factor)) %>% 
                  mutate(asl.correction.factor =
                           as.numeric(asl.correction.factor)) %>% 
                  mutate(altitude = as.numeric(altitude))

size_dat_2021 %>% 
  filter(unique == "Y") %>% 
  filter(length_adj_m >= 3) %>% 
  nrow()
#120 adults

size_dat_2021 %>%
  filter(unique == "Y") %>% 
  filter(length_raw_m < 3) %>% 
  nrow()
#337 juveniles
```
higher % of adults than 2020

## Three-Year ("3yr") dataset tidying

### Combine 2019, 2020, and 2021 datasets
```{r}
daily_2yr_dat <- full_join(dat_2019, dat_2020)
#view(daily_2yr_dat)

daily_3yr_dat <- full_join(daily_2yr_dat, dat_2021)
#view(daily_3yr_dat)

daily_3yr_dat <- daily_3yr_dat %>%
  mutate(year = as_factor(year(mdy(date)))) %>% 
  mutate(day = yday(datetime)) %>% 
  mutate(day2 = (yday(datetime))^2)

#View(daily_3yr_dat)
```

### Reading in Carp LTER data
```{r}
lter_dat_raw <- read.csv("data_raw/lter_dat.csv")
#View(lter_dat_raw)

lter_dat <- lter_dat_raw %>% 
  filter(year > 2018) %>% 
  filter(year < 2022) %>% 
  mutate(hour = (24*decimal_time)) %>%
  mutate(hour = round(hour, digits = 1)) %>% 
  mutate(date_hour = make_datetime(year, month, day, hour)) %>% 
  mutate(date_hour = force_tz(date_hour, tzone = "America/Los_Angeles")) %>%
  rename(day_of_month = day) %>% 
  group_by(date_hour) %>% 
  summarize(Temp_top = mean(Temp_top, na.rm = TRUE), salinity = mean(Salinity, na.rm = TRUE)) %>% 
  filter(Temp_top < 100) %>% 
  filter(salinity < 100)


lter_dat %>% 
  filter(month(date_hour) == 8) %>% 
  filter(day(date_hour) == 29) %>% 
  filter(year(date_hour) == 2021) %>% 
  ggplot(aes(x = date_hour, y = salinity)) +
    geom_point() +
    geom_smooth()
```

### Adding LTER data to daily 3yr dataset 
```{r}
daily_3yr_dat_backup <- left_join(daily_3yr_dat, lter_dat, by = "date_hour")

write.csv(daily_3yr_dat_backup, "data/daily_3yr_dat_backup.csv")

#View(daily_3yr_dat_backup)
```

### Recovery of daily_3yr_dat (so you don't have to re-run everything above if you mess it up)
```{r}
daily_3yr_dat <- read.csv("data/daily_3yr_dat_backup.csv")

#View(daily_3yr_dat)
```

## Building 3yr size dataset
```{r}
size_dat_2yr <- full_join(size_dat_2019, size_dat_2020)

size_dat_3yr <- full_join(size_dat_2yr, size_dat_2021)
#view(size_dat_3yr)

size_dat_3yr <- size_dat_3yr %>% 
                  select(!c(26:31))
```

### New 3yr df with size of each unique shark
(1 row = 1 shark, daily data is repeated for days where multiple sharks were observed)
```{r}
size_dat_unique <- size_dat_3yr %>%
                    filter(unique == "Y") %>%
                    filter(length_adj_m > 1) %>% 
                    mutate(date = sub("^0+", "", date))

joined_3yr <- left_join(daily_3yr_dat, size_dat_unique, by = "date")
```

## Adding size classes to daily 3yr dataframe
```{r}
ggplot(joined_3yr, aes(x = video_YN)) +
  geom_bar()

size_classed_3yr <- joined_3yr %>%
  group_by(date) %>%
  dplyr::summarize(juvenile = sum(length_adj_m < 3.00 & length_adj_m > 0, na.rm = TRUE), 
                   adult = sum(length_adj_m >= 3.00, na.rm = TRUE))

daily_3yr_dat <- left_join(daily_3yr_dat, size_classed_3yr, by = "date")
#View(daily_3yr_dat)

daily_3yr_dat <- daily_3yr_dat  %>%
  mutate(juvenile = ifelse(is.na(juvenile), 0, juvenile)) %>% 
  mutate(adult = ifelse(is.na(adult), 0, adult)) %>% 
  mutate(total_sized = juvenile + adult) %>% 
  filter(detection == "Y" | detection == "N") %>%
  mutate(total_area = ifelse(year == 2019, transect_area_km2,
                             ifelse(is.na(manual_area_km2), transect_area_km2, 
                                    ifelse(is.na(transect_area_km2),
                                           manual_area_km2,
                                           manual_area_km2 + transect_area_km2)))) %>% 
  mutate(area_20m = ifelse(year == 2019, transect_area_km2, manual_area_km2))
```

## CSULB data

### Read and filter
```{r}
#Check deployment log:
temp_deployment <- read.csv("data_raw/CSULB/JWS Receiver Deployment Log - Temperature_Log.csv")
#View(temp_deployment)

# UNFILTERED data for 2019:
OS1_1 <- read.csv("data_raw/CSULB/JWS_SantaClaus_OS1-SN20069755_20190515_20190701.csv")
OS2_1 <- read.csv("data_raw/CSULB/JWS_SantaClaus_OS2-SN20566751_20190515_20190701.csv")
OS2_2 <- read.csv("data_raw/CSULB/JWS_SantaClaus_OS2-SN20069754_20190628_20190829.csv") 
OS2_3 <- read.csv("data_raw/CSULB/JWS_SantaClaus_OS2-SN20031403_20190819_20191109.csv")
OS2_4 <- read.csv("data_raw/CSULB/JWS_SantaClaus_OS2-SN20069752_20191106_20191216.csv")

OS1_filtered <- OS1_1 %>%
  mutate(DateTimePST = as_datetime(DateTimePST)) %>% 
  filter(DateTimePST > as_datetime("2019-05-15 00:00:00") &
         DateTimePST < as_datetime("2019-06-28 00:00:00"))

OS2_1_filtered <- OS2_1 %>% 
  mutate(DateTimePST = as_datetime(DateTimePST)) %>% 
  filter(DateTimePST > as_datetime("2019-05-15 00:00:00") &
         DateTimePST < as_datetime("2019-06-28 00:00:00"))

OS2_2_filtered <- OS2_2 %>% 
  mutate(DateTimePST = as_datetime(DateTimePST)) %>% 
  filter(DateTimePST > as_datetime("2019-06-28 00:00:00") &
         DateTimePST < as_datetime("2019-08-27 00:00:00"))

OS2_3_filtered <- OS2_3 %>% 
  mutate(DateTimePST = as_datetime(DateTimePST)) %>% 
  filter(DateTimePST > as_datetime("2019-08-27 09:50:00") &
         DateTimePST < as_datetime("2019-11-07 10:37:00"))

OS2_4_filtered <- OS2_4 %>% 
  mutate(DateTimePST = as_datetime(DateTimePST)) %>% 
  filter(DateTimePST > as_datetime("2019-11-07 10:37:00") &
         DateTimePST < as_datetime("2019-12-12 00:00:00"))

sft_19 <- bind_rows(OS1_filtered, OS2_1_filtered, OS2_2_filtered,
                    OS2_3_filtered, OS2_4_filtered)

sft_19 <- sft_19 %>% 
  rename(sft = Temp_C, date_hour = DateTimePST) %>% 
  select(!c(1,3,4,6:11)) %>% 
  group_by(date_hour) %>% 
  summarize(sft = mean(sft, na.rm = TRUE))

#filtered temp data for 2020 and 2021:
filtered_temp_20_21_raw <- read.csv("data_raw/CSULB/All_2020-2021_filtered_temp_data.csv")
#View(filtered_temp_20_21_raw)

station_filtered_20_21 <- filtered_temp_20_21_raw %>% 
  filter(Station == "JWS_SantaClaus_OS1" | Station == "JWS_SantaClaus_OS2" | 
         Station == "JWS_Padaro_Inshore_A" | Station == "JWS_Padaro_Inshore_B" |
         Station == "JWS_Padaro_Inshore_C" | Station == "JWS_Padaro_Inshore_D") %>% 
  mutate(depth_level = if_else(LoggerDepth_m > 1, "sft", "sst")) %>% 
  select(!c(3:5)) %>% 
  mutate(DateTimeUTC = as_datetime(DateTimeUTC))

#View(station_filtered_20_21)

sst_20_21 <- station_filtered_20_21 %>% 
  filter(depth_level == "sst") %>% 
  group_by(date(DateTimeUTC), hour(DateTimeUTC)) %>% 
  summarize(sst = mean(Temp_C, na.rm = TRUE)) %>%
  ungroup() %>%
  rename(date = 1, hour = 2) %>% 
  mutate(date = as_date(date)) %>% 
  mutate(date_hour = make_datetime(year(date), month(date),
                                   day(date), hour)) %>% 
  select(!c(1,2)) %>% 
  mutate(date_hour = force_tz(date_hour, tzone = "America/Los_Angeles"))

sft_20_21 <- station_filtered_20_21 %>% 
  filter(depth_level == "sft") %>% 
  group_by(date(DateTimeUTC), hour(DateTimeUTC)) %>% 
  summarize(sft = mean(Temp_C, na.rm = TRUE)) %>%
  ungroup() %>%
  rename(date = 1, hour = 2) %>% 
  mutate(date = as_date(date)) %>% 
  mutate(date_hour = make_datetime(year(date), month(date), day(date), hour)) %>% 
  select(!c(1,2)) %>% 
  mutate(date_hour = force_tz(date_hour, tzone = "America/Los_Angeles"))

sft_sst_20_21 <- left_join(sft_20_21, sst_20_21, by = "date_hour")

#combine 2019 and 2020/2021 sft
sft_19_20_21 <- bind_rows(sft_19, sft_20_21)
#View(sft_19_20_21)

ggplot(sft_sst_20_21, aes(x = date_hour, y = sft)) +
  geom_point()

ggplot(sst_20_21, aes(x = date_hour, y = sst)) +
  geom_point()

ggplot(sft_sst_20_21, aes(x = sst, y = sft)) + 
  geom_point() +
  geom_abline(slope = 1, intercept = 0, size = 1, color = "blue")

sft_sst_lm <- lm(sft ~ sst, data = sft_sst_20_21)
summary(sft_sst_lm)
#r-squared = 0.75, but for any given sft, sst can vary by ~4 degrees C

cor.test(sft_sst_20_21$sft, sft_sst_20_21$sst, method = "pearson")
#highly correlated (0.87)
```

### Append to rest of data
```{r}
daily_3yr_dat <- daily_3yr_dat %>% 
  mutate(date_hour = as_datetime(date_hour))

daily_3yr_dat <- left_join(daily_3yr_dat, sft_19_20_21, by = "date_hour")

daily_3yr_dat <- left_join(daily_3yr_dat, sst_20_21, by = "date_hour")
```

### Adding NOAA satelite chlorophyll data
```{r}
chl_dat_raw <- read.csv("data_raw/chl_dat.csv")
#View(chl_dat_raw)

chl_dat <- chl_dat_raw %>% 
  slice(-1) %>%
  mutate(long = as.numeric(longitude)) %>%
  mutate(lat = as.numeric(latitude)) %>%
  mutate(chl = as.numeric(chlorophyll)) %>% 
  mutate(long = round(long, digits = 4)) %>% 
  mutate(lat = round(lat, digits = 4)) %>%
  filter(lat == 34.4 | lat == 34.4125) %>% 
  filter(long == -119.5625 | long == -119.5500) %>%
  filter(!(lat == 34.4125 & long == -119.5500)) %>%
  group_by(time) %>%
  summarize(chl = mean(chl, na.rm = TRUE)) %>% 
  mutate(chl_interp = na.approx(chl)) %>% 
  mutate(mdy = as_date(time), time = NULL)
#View(chl_dat)

daily_3yr_dat <- daily_3yr_dat %>% 
  mutate(mdy = as_date(datetime))

daily_3yr_dat <- left_join(daily_3yr_dat, chl_dat, by = "mdy")

daily_3yr_dat %>% 
  filter(!is.na(chl)) %>% 
  nrow()

nrow(daily_3yr_dat)
#>100 chl values missing so I added linearly interpolated ones (see below for exploration of that)

chl_dat_raw %>% 
  slice(-1) %>%
  mutate(long = as.numeric(longitude)) %>%
  mutate(lat = as.numeric(latitude)) %>%
  mutate(chl = as.numeric(chlorophyll)) %>% 
  mutate(long = round(long, digits = 4)) %>% 
  mutate(lat = round(lat, digits = 4)) %>%
  filter(lat == 34.4 | lat == 34.4125) %>% 
  filter(long == -119.5625 | long == -119.5500) %>%
  filter(!(lat == 34.4125 & long == -119.5500)) %>%
  group_by(time) %>%
  summarize(chl = mean(chl, na.rm = TRUE)) %>% 
  mutate(chl_interp = na.approx(chl)) %>% 
  mutate(mdy = as_date(time), time = NULL) %>% 
  ggplot(aes(x = mdy)) +
    geom_point(aes(y = chl_interp), color = "red") +
    geom_point(aes(y = chl))

chl_dat_raw %>% 
  slice(-1) %>%
  mutate(long = as.numeric(longitude)) %>%
  mutate(lat = as.numeric(latitude)) %>%
  mutate(chl = as.numeric(chlorophyll)) %>% 
  mutate(long = round(long, digits = 4)) %>% 
  mutate(lat = round(lat, digits = 4)) %>%
  filter(lat == 34.4 | lat == 34.4125) %>% 
  filter(long == -119.5625 | long == -119.5500) %>%
  filter(!(lat == 34.4125 & long == -119.5500)) %>%
  group_by(time) %>%
  summarize(chl = mean(chl, na.rm = TRUE)) %>% 
  mutate(chl_interp = na.approx(chl)) %>% 
  mutate(mdy = as_date(time), time = NULL) %>% 
  ggplot(aes(x = chl_interp)) +
    geom_histogram()

chl_dat_raw %>% 
  slice(-1) %>%
  mutate(long = as.numeric(longitude)) %>%
  mutate(lat = as.numeric(latitude)) %>%
  mutate(chl = as.numeric(chlorophyll)) %>% 
  mutate(long = round(long, digits = 4)) %>% 
  mutate(lat = round(lat, digits = 4)) %>%
  filter(lat == 34.4 | lat == 34.4125) %>% 
  filter(long == -119.5625 | long == -119.5500) %>%
  filter(!(lat == 34.4125 & long == -119.5500)) %>%
  group_by(time) %>%
  summarize(chl = mean(chl, na.rm = TRUE)) %>% 
  mutate(chl_interp = na.approx(chl)) %>% 
  mutate(mdy = as_date(time), time = NULL) %>% 
  ggplot(aes(x = chl)) +
    geom_histogram()

ks.test(daily_3yr_dat$chl, daily_3yr_dat$chl_interp)
#no difference in distribution of actual vs interpolated chl

daily_3yr_dat %>% 
  ggplot() +
    geom_density(aes(chl)) +
    geom_density(aes(chl_interp), color = "red")

daily_3yr_dat %>% 
  ggplot() +
    stat_ecdf(aes(chl)) +
    stat_ecdf(aes(chl_interp), color = "red")
```

## Clean up time, add inner/outer vis scores
```{r}
View(daily_3yr_dat)

daily_3yr_dat <- daily_3yr_dat %>% 
  select(-c(1, 20:22, 24:28, 30, 36))

transect_vis_dat <- read.csv("data_raw/transect_vis_dat.csv")
daily_3yr_dat <- left_join(daily_3yr_dat, transect_vis_dat, by = "date")

write.csv(daily_3yr_dat, "data/daily_3yr_dat_clean.csv")

size_dat_3yr <- size_dat_3yr %>% 
  mutate(length_raw_m = length_raw_m*res_adjustment_factor) %>% 
  mutate(length_adj_m = length_raw_m*depth.correction.factor*asl.correction.factor)

write.csv(size_dat_3yr, "data/size_dat_3yr_clean.csv")
```

## read clean csvs
```{r}
daily_3yr_dat <- read.csv("data/daily_3yr_dat_clean.csv")

size_dat_3yr <- read.csv("data/size_dat_3yr_clean.csv")
```

## Dataframe without 2019
```{r}
dat_no_19 <- daily_3yr_dat %>% 
  filter(year != 2019)
```

=============================================================================

# Analyses for Thesis

## Summary statistics
```{r}
nrow(daily_3yr_dat)
#351 total survey days

daily_3yr_dat %>% 
  filter(year == 2019) %>% 
  slice(-c(2:(n()-1)))
#2019 started on 5/30 and ended on 12/6:
as.period(mdy("5/30/2019") %--% mdy("12/6/2019"), "days")
#2019 field season was 190 days long
190/7 #roughly 27 weeks

nrow(filter(daily_3yr_dat, year == 2019))
98/(190/7) #3.6 surveys/week

daily_3yr_dat %>% 
  filter(year == 2020) %>% 
  slice(-c(2:(n()-1)))
#2020 started on 6/24 and ended on 12/11:
as.period(mdy("6/24/2020") %--% mdy("12/11/2020"), "days")
#2020 field season was 170 days long
170/7 #roughly 24 weeks

nrow(filter(daily_3yr_dat, year == 2020))
113/(170/7) #4.7 surveys/week

daily_3yr_dat %>% 
  filter(year == 2021) %>% 
  slice(-c(2:(n()-1)))
#2021 started on 4/20 and ended on 12/18:
as.period(mdy("4/20/2021") %--% mdy("12/18/2021"), "days")
#2021 field season was 242 days long
242/7 #roughly 35 weeks

nrow(filter(daily_3yr_dat, year == 2021))
140/(242/7) #4.0 surveys/week
  
sum(daily_3yr_dat$total_unique, na.rm = TRUE)
#912 total sightings

daily_3yr_dat %>% 
  group_by(year) %>% 
  summarize(surveys = n(), total_sightings = sum(total_unique, na.rm = TRUE), mean_count = mean(total_unique, na.rm = TRUE), sd_count = sd(total_unique, na.rm = TRUE))
#2019:     98 surveys, 44 total sharks, 0.449 sharks/survey, sd = 1.24
#2020:    113          271              2.42                 sd = 2.87
#2021:    140          597              4.36                 sd = 3.37

year_aov <- aov(total_unique ~ as.factor(year), data = daily_3yr_dat)
summary(year_aov)
TukeyHSD(year_aov)

ggplot(daily_3yr_dat, aes(x = total_unique)) +
  geom_density() +
  facet_wrap(vars(year))
#obviously not normally distributed so idk about anova for year...

kruskal_dat <- daily_3yr_dat %>% 
  mutate(year = as_factor(year))
kruskal.test(total_unique~year, data = kruskal_dat)
#significant difference in total counts between years (p < 0.001)

dunnTest(total_unique~year, data = kruskal_dat)
#all year contrasts significant

kruskal.test((total_unique/total_area)~year, data = kruskal_dat)
#significant difference in density between years (p < 0.001)

dunnTest((total_unique/total_area)~year, data = kruskal_dat)
#all year contrasts significant

daily_3yr_dat %>% 
  group_by(year) %>% 
  summarize(surveys = n(), mean_density = mean(total_unique/total_area, na.rm = TRUE), sd_density = sd(total_unique/total_area, na.rm = TRUE), median_density = median(total_unique/total_area, na.rm = TRUE), max_density = max(total_unique/total_area, na.rm = TRUE), min_density =  min(total_unique/total_area, na.rm = TRUE))

sum(daily_3yr_dat$adult)
#174 adults

sum(daily_3yr_dat$juvenile)
#342 juveniles

View(size_dat_3yr)

daily_3yr_dat %>%
  filter(year != 2019) %>% 
  summarize(mean_area = mean(transect_area_km2), mean_duration = mean(manual_duration_min, na.rm = TRUE), sd_duration = sd(manual_duration_min, na.rm = TRUE))

daily_3yr_dat %>%
  filter(year != 2019) %>% 
  summarize(trans_area = mean(transect_area_km2, na.rm = TRUE), trans_duration = mean(transect_duration_min, na.rm = TRUE), man_area = mean(manual_area_km2, na.rm = TRUE), man_area_sd = sd(manual_area_km2, na.rm = TRUE), man_duration = mean(manual_duration_min, na.rm = TRUE), man_duration_sd = sd(manual_duration_min, na.rm = TRUE))

daily_3yr_dat %>% 
  filter(manual_area_km2 > 0) %>% 
  nrow()
#238 manual surveys conducted

daily_3yr_dat %>% 
  filter(total_unique > 0) %>% 
  nrow()
#203 days w/ at least one shark
203/351

daily_3yr_dat %>% 
  filter(total_unique > 0) %>% 
  filter(year == 2019) %>% 
  nrow()
#17 detection days in 2019
17/98

daily_3yr_dat %>% 
  filter(total_unique > 0) %>% 
  filter(year == 2020) %>% 
  nrow()
#70 detection days in 2020
70/113

daily_3yr_dat %>% 
  filter(total_unique > 0) %>% 
  filter(year == 2021) %>% 
  nrow()
#116 detection days in 2021
116/140

detection_table <- table(daily_3yr_dat$year, daily_3yr_dat$detection)
chisq.test(detection_table)

#post-hoc w/ Bonferroni Adjustment - 3 comparisons so alpha = 0.05/3 = 0.0167

#2019-2020
chisq.test(detection_table[c(1,2),])
#different

#2019-2021
chisq.test(detection_table[c(1,3),])
#different

#2020-2021
chisq.test(detection_table[c(2,3),])
#different

daily_3yr_dat %>% 
  filter(year == 2019) %>% 
  summarize(max = max(total_unique))
# max 6

daily_3yr_dat %>% 
  filter(year == 2020) %>% 
  summarize(max = max(total_unique, na.rm = TRUE))
# max 12

daily_3yr_dat %>% 
  filter(year == 2021) %>% 
  summarize(max = max(total_unique, na.rm = TRUE))
#max 15
```

### SST satellite and LTER temp historical trends
```{r}
sat_sst_raw <- read.csv("data_raw/sat_sst.csv")
View(sat_sst)

sat_sst %>% 
  slice(2:n()) %>%
  mutate(SST = as.numeric(SST)) %>% 
  mutate(time = as_datetime(time)) %>%
  group_by(time) %>% 
  summarize(SST = mean(SST, na.rm = TRUE)) %>%
  ggplot(aes(x = time, y = SST)) +
    geom_line()

lter_dat_raw %>%
  filter(Temp_top < 100) %>%
  mutate(hour = (24*decimal_time)) %>%
  mutate(hour = round(hour, digits = 1)) %>% 
  mutate(date_hour = make_datetime(year, month, day, hour)) %>%
  mutate(year_month = make_datetime(year, month)) %>% 
  mutate(date_hour = force_tz(date_hour, tzone = "America/Los_Angeles")) %>%
  rename(day_of_month = day) %>% 
  group_by(year_month) %>% 
  summarize(Temp_top = mean(Temp_top, na.rm = TRUE)) %>% 
  ggplot(aes(x = year_month, y = Temp_top)) +
    geom_point() +
    geom_smooth(method = "lm")

lter_lm_dat <- lter_dat_raw %>% 
  filter(Temp_top < 100) %>%
  mutate(hour = (24*decimal_time)) %>%
  mutate(hour = round(hour, digits = 1)) %>% 
  mutate(date_hour = make_datetime(year, month, day, hour)) %>%
  mutate(year_month = make_datetime(year, month)) %>% 
  mutate(date_hour = force_tz(date_hour, tzone = "America/Los_Angeles")) %>%
  group_by(year_month) %>% 
  summarize(Temp_top = mean(Temp_top, na.rm = TRUE))

lter_temp_lm <- lm(Temp_top ~ year_month, data = lter_lm_dat)
summary(lter_temp_lm)

lter_2002_2011_avg <- lter_dat_raw %>%
  filter(Temp_top < 100) %>%
  mutate(hour = (24*decimal_time)) %>%
  mutate(hour = round(hour, digits = 1)) %>%
  filter(year > 2001) %>% 
  filter(year < 2012) %>% 
  mutate(year_month = make_datetime(year, month)) %>% 
  group_by(year_month) %>% 
  summarize(Temp_top = mean(Temp_top, na.rm = TRUE)) %>% 
  ungroup() %>% 
  summarize(Temp_top = mean(Temp_top))
#14.930

lter_2012_2021_avg <- lter_dat_raw %>%
  filter(Temp_top < 100) %>%
  mutate(hour = (24*decimal_time)) %>%
  mutate(hour = round(hour, digits = 1)) %>%
  filter(year >= 2012) %>% 
  mutate(year_month = make_datetime(year, month)) %>% 
  group_by(year_month) %>% 
  summarize(Temp_top = mean(Temp_top, na.rm = TRUE)) %>% 
  ungroup() %>% 
  summarize(Temp_top = mean(Temp_top))
#16.042

sat_sst <- sat_sst_raw %>%
  slice(-c(1)) %>% 
  mutate(date_hour = as_datetime(time)) %>% 
  mutate(date_hour = round_date(date_hour, "hour"))
View(sat_sst)
sat_vs_lb_sst <- left_join(sat_sst, sft_sst_20_21, by = "date_hour")
View(sat_vs_lb_sst)
```

## Investigating different metrics - raw count (each method and "unique") and density
```{r}
daily_3yr_dat %>% 
  group_by(year) %>% 
  summarize(density = mean(total_unique/total_area, na.rm = TRUE))

dat_no_19 %>%
  group_by(year(date_hour)) %>% 
  summarize("Unique count" = mean(total_unique, na.rm = TRUE),
            #"Maximum unique count" = max(total_unique, na.rm = TRUE),
            "Manual count" = mean(manual_total, na.rm = TRUE),
            #"Maximum manual count" = max(manual_total, na.rm = TRUE),
            "Transect count" = mean(transect_total, na.rm = TRUE),
            #"Maximum transect count" = max(transect_total, na.rm = TRUE),
            "Unique density" = mean(total_unique/(manual_area_m2 + transect_area_m2), na.rm = TRUE),
            #"Maximum unique density" = max(total_unique/(manual_area_km2 + transect_area_km2), na.rm = TRUE),
            "Manual density" = mean(manual_unique/manual_area_m2, na.rm = TRUE),
            #"Maximum manual density" = max(manual_unique/manual_area_km2, na.rm = TRUE),
            "Transect density" = mean(transect_total/transect_area_m2, na.rm = TRUE),
            #"Maximum transect density" = max(transect_total/transect_area_km2, na.rm = TRUE)
  )
```
* Looks like manual count was higher than transect count in 2020, but not 2021.

### Comparing methods
```{r}
mean(dat_no_19$transect_total/dat_no_19$transect_area_km2, na.rm = TRUE)
mean(dat_no_19$manual_unique/dat_no_19$manual_area_km2, na.rm = TRUE)
#transect actually has higher density

method_dat <- dat_no_19 %>% 
  filter(!is.na(transect_total)) %>% 
  filter(!is.na(transect_area_km2)) %>% 
  filter(!is.na(manual_unique)) %>% 
  filter(!is.na(manual_area_km2)) %>%
  mutate(manual = manual_unique/manual_area_km2) %>% 
  mutate(transect = transect_total/transect_area_km2) %>% 
  pivot_longer(c(manual, transect), names_to = "method",
                                    values_to = "density")
  
ggplot(method_dat, aes(x = density)) +
  geom_histogram(binwidth = 10) +
  facet_grid(~method)
#normal distribution obviously not going to work (for ANOVA or GLM)
```

```{r}
dat_no_19 %>% 
  filter(transect_total == 0) %>% 
  filter(manual_unique != 0) %>% 
  nrow()
#46 days where transect saw nothing and manual saw something

dat_no_19 %>% 
  filter(transect_total == 0) %>% 
  summarize(mean = mean(manual_unique, na.rm = TRUE))
#when no sharks are detected in transect, manual detects 0.898

dat_no_19 %>% 
  filter(manual_unique == 0) %>%
  filter(transect_total != 0) %>% 
  nrow()
#14 days where manual saw nothing and transect saw something

dat_no_19 %>% 
  filter(manual_unique == 0) %>% 
  summarize(mean = mean(transect_total, na.rm = TRUE))
#when no sharks are detected in manual, transect detects 0.539
```

### Wilcoxon signed-rank test on counts (IN THESIS)
```{r}
method_comp_dat <- dat_no_19 %>% 
  filter(!is.na(transect_total)) %>% 
  filter(!is.na(transect_area_km2)) %>% 
  filter(!is.na(manual_unique)) %>% 
  filter(!is.na(manual_area_km2)) %>%
  select(transect_area_km2, manual_area_km2,
         transect_total, manual_unique, date) %>%
  rename("transect" = transect_total) %>% 
  rename("manual" = manual_unique) %>% 
  pivot_longer(c(transect, manual), names_to = "method",
                                    values_to = "count") %>% 
  pivot_longer(c(transect_area_km2, manual_area_km2), names_to = "area_method",
                                    values_to = "area") %>% 
  filter(row_number() %% 4 == 1 | row_number() %% 4 == 0)

paired_dat <- method_comp_dat %>% 
  select(date, method, count) %>% 
  pivot_wider(names_from = method, values_from = count) %>%
  mutate(diff = manual - transect)
nrow(paired_dat)

ggplot(paired_dat, aes(x = diff)) +
    geom_bar()
#paired differences actually look pretty normally distributed...

shapiro.test(paired_dat$diff)
#jk, not normal
  
transect_counts <- method_glm_dat %>% 
  filter(method == "transect") %>% 
  select(count)
nrow(transect_counts)

manual_counts <- method_glm_dat %>% 
  filter(method == "manual") %>% 
  select(count)
nrow(manual_counts)

method_test <- wilcox.test(manual_counts$count, transect_counts$count, paired = TRUE)
method_test
#manual counts are higher (p<0.05)

# explicitly testing the hypothesis that manual count is higher than transect count:
method_test_onesided <- wilcox.test(manual_counts$count, transect_counts$count, paired = TRUE, alternative = "greater")
method_test_onesided
```

### Calculating effect size (basically just % of days where manual saw more, transect saw more, or they were the same)
```{r}
# number of days with no difference:
paired_dat %>%
  filter(diff == 0) %>% 
  nrow()
# 84 days

84/nrow(paired_dat)
# 38% of days

paired_dat %>%
  filter(transect == 0) %>% 
  filter(manual == 0) %>% 
  nrow()
# 61 days where BOTH were zero

61/84
# 72.6% of "manual = transect" days were days where no sharks were seen!

#number of days where manual saw more:
paired_dat %>%
  filter(diff > 0) %>% 
  nrow()
# 84 days (weird), 38%

#number of days where transect saw more:
paired_dat %>%
  filter(diff < 0) %>% 
  nrow()
# 53 days

53/nrow(paired_dat)
# 24% of days

mean(daily_3yr_dat$manual_unique, na.rm = TRUE)
#average manual count is 2.29
sd(daily_3yr_dat$manual_unique, na.rm = TRUE)
#sd is 2.44
median(daily_3yr_dat$manual_unique, na.rm = TRUE)
#2
range(daily_3yr_dat$manual_unique, na.rm = TRUE)

daily_3yr_dat %>%
  filter(year != 2019) %>%
  summarize(mean = mean(transect_total, na.rm = TRUE), sd = sd(transect_total, na.rm = TRUE), median = median(transect_total, na.rm = TRUE), range = range(transect_total, na.rm = TRUE))
# average 2020/2021 transect count is 2.13

daily_3yr_dat %>%
  filter(year == 2019) %>% 
  summarize(mean = mean(transect_total, na.rm = TRUE), sd = sd(transect_total, na.rm = TRUE), median = median(transect_total, na.rm = TRUE), range = range(transect_total, na.rm = TRUE))
# average 2019 transect count is 0.45
```
* Manual survey count was significantly more likely to be higher than transect survey count (p < 0.01), with manual count being higher than transect count for 38% of survey days, lower than transect count for 24% of survey days, and equal to transect count for 38% of survey days. Of the 84 days where manual and transect count were equal, 72.6% (61 days) were days where no sharks were seen.

### Wilcoxon signed-rank test on density (IN THESIS)
```{r}
paired_dens_dat <- method_comp_dat %>%
  mutate(density = count/area) %>% 
  select(date, method, density) %>% 
  pivot_wider(names_from = method, values_from = density) %>%
  mutate(diff = manual - transect)

shapiro.test(paired_dens_dat$diff)
#not normal

transect_dens <- method_glm_dat %>% 
  filter(method == "transect") %>% 
  mutate(density = count/area) %>% 
  select(density)
nrow(transect_dens)

manual_dens <- method_glm_dat %>% 
  filter(method == "manual") %>% 
  mutate(density = count/area) %>% 
  select(density)
nrow(manual_dens)

# do methods differ in density (2-sided, n = 221):
method_dens_test <- wilcox.test(manual_dens$density, transect_dens$density, paired = TRUE)
method_dens_test
# NOT more likely to see a higher density of sharks (count per unit area surveyed) in one survey method vs the other

mean((daily_3yr_dat$manual_unique/daily_3yr_dat$manual_area_km2), na.rm = TRUE)
#average manual density is 11.86
sd((daily_3yr_dat$manual_unique/daily_3yr_dat$manual_area_km2), na.rm = TRUE)
#sd is 2.44

daily_3yr_dat %>% 
  filter(year!= 2019) %>% 
  summarize(mean = mean(transect_total/transect_area_km2, na.rm = TRUE), sd = sd(transect_total/transect_area_km2, na.rm = TRUE))
```

### Comparing rates (count per unit time)
```{r}
method_rate_dat <- dat_no_19 %>% 
  filter(!is.na(transect_total)) %>% 
  filter(!is.na(transect_duration_min)) %>% 
  filter(!is.na(manual_unique)) %>% 
  filter(!is.na(manual_duration_min)) %>%
  select(transect_total, manual_unique, date, transect_duration_min, manual_duration_min) %>%
  rename("transect" = transect_total) %>% 
  rename("manual" = manual_unique) %>% 
  pivot_longer(c(transect, manual), names_to = "method",
                                    values_to = "count") %>% 
  pivot_longer(c(transect_duration_min, manual_duration_min), names_to = "time_method",
                                    values_to = "duration") %>% 
  filter(row_number() %% 4 == 1 | row_number() %% 4 == 0) %>% 
  #mutate(year = as.factor(year(date))) %>% 
  mutate(method = as.factor(method))

paired_rate_dat <- method_rate_dat %>%
  mutate(rate = count/duration) %>% 
  select(date, method, rate) %>% 
  pivot_wider(names_from = method, values_from = rate) %>%
  mutate(diff = manual - transect)

shapiro.test(paired_rate_dat$diff)
#not normal

transect_rate <- method_rate_dat %>% 
  filter(method == "transect") %>% 
  mutate(rate = count/duration) %>% 
  select(rate)
nrow(transect_rate)

manual_rate <- method_rate_dat %>% 
  filter(method == "manual") %>% 
  mutate(rate = count/duration) %>% 
  select(rate)
nrow(manual_rate)

# do methods differ in rate (2-sided, n = 221):
method_rate_test <- wilcox.test(manual_rate$rate, transect_rate$rate, paired = TRUE)
method_rate_test
# Not more likely for manual or transect to have a higher rate


mean((daily_3yr_dat$manual_unique/daily_3yr_dat$manual_duration_min), na.rm = TRUE)
#average manual rate is 0.21
sd((daily_3yr_dat$manual_unique/daily_3yr_dat$manual_duration_min), na.rm = TRUE)
#sd is 0.25

daily_3yr_dat %>% 
  filter(year!= 2019) %>% 
  summarize(mean = mean(transect_total/transect_duration_min, na.rm = TRUE), sd = sd(transect_total/transect_duration_min, na.rm = TRUE))
```

### Visualizing manual vs transect metrics - data prep
```{r}
manual_counts <- mutate(manual_counts, value = count, method = "manual", metric = "Count")
transect_counts <- mutate(transect_counts, value = count, method = "transect", metric = "Count")
manual_dens <- mutate(manual_dens, value = density, method = "manual", metric = "Density")
transect_dens <- mutate(transect_dens, value = density, method = "transect", metric = "Density")
manual_rate <- mutate(manual_rate, value = rate, method = "manual", metric = "Rate")
transect_rate <- mutate(transect_rate, value = rate, method = "transect", metric = "Rate")

comp_vis_dat <- bind_rows(manual_counts, transect_counts, manual_dens, transect_dens, manual_rate, transect_rate)

manual_counts_10x <- mutate(manual_counts, value = count*10, method = "manual", metric = "Count")
transect_counts_10x <- mutate(transect_counts, value = count*10, method = "transect", metric = "Count")
manual_dens <- mutate(manual_dens, value = density, method = "manual", metric = "Density")
transect_dens <- mutate(transect_dens, value = density, method = "transect", metric = "Density")
manual_rate_100x <- mutate(manual_rate, value = rate*100, method = "manual", metric = "Rate")
transect_rate_100x <- mutate(transect_rate, value = rate*100, method = "transect", metric = "Rate")

comp_vis_dat_scaled <- bind_rows(manual_counts_10x, transect_counts_10x, manual_dens, transect_dens, manual_rate_100x, transect_rate_100x)

#View(comp_vis_dat)
```

### Manual vs Transect 3 metric comparison plot (IN THESIS):
```{r}
comp_vis_dat$metric <- factor(comp_vis_dat$metric, labels = c("'Count'", expression(Density~(sharks/km^2)), expression(Rate~(sharks/min))))

ggplot(comp_vis_dat, aes(y = value)) +
  geom_boxplot(aes(color = method)) +
  facet_wrap(.~metric, scales = "free", strip.position = "left", labeller = label_parsed) +
  theme_cowplot() +
  scale_color_brewer(palette = "Dark2",
                     labels = c("Roaming", "Transect")) +
  guides(shape = "none") + 
  theme(panel.background = element_rect(fill = "white", colour = NA),
        plot.background = element_rect(fill = "white", colour = NA),
        strip.background = element_blank(),
        strip.placement = "outside",
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) +
  ylab(NULL) + xlab(NULL) +
  labs(color = "Method")

ggsave("plots/method_comp_plot_final.png", width = 7, height = 5)

method_comp_plot_scaled <- ggplot(comp_vis_dat, aes(x = metric, y = value)) +
  geom_boxplot(aes(color = method)) +
  theme_cowplot() +
  scale_color_brewer(palette = "Dark2",
                     labels = c("Roaming", "Transect")) +
  geom_point(aes(y = 139, shape = metric)) +
  scale_shape_manual(values = c(8, NA, NA)) + #significance asterisk
  guides(shape = "none") + 
  theme(panel.background = element_rect(fill = "white", colour = NA),
        plot.background = element_rect(fill = "white", colour = NA)) +
  labs(x = "Metric", y = "Value", color = "Method")
# count is scaled up by a factor of 10 and rate is scaled up by a factor of 100. Only sig diff is count.
```

## Tagged vs Untagged sharks (INCLUDED IN THESIS)
```{r}
size_dat_3yr %>%
  filter(unique == "Y") %>% 
  group_by(tagged) %>% 
  summarize(sharks = n())
83 + 170
#268 observations clear enough to determine tagged/untagged status
#of these, 97 were not tagged and 171 were

size_dat_3yr %>%
  filter(unique == "Y") %>%
  filter(tagged != "") %>% 
  filter(tagged != "?") %>%
  filter(tagged != "X") %>% 
  group_by(year(mdy(date)), tagged) %>% 
  summarize(sharks = n())

size_dat_3yr %>%
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>% 
  group_by(date) %>% 
  summarize(max = max(length_adj_m)) %>% 
  View()
```

## Spatial Analysis (inner vs outer) (INCLUDED IN THESIS)
```{r}
spatial_dat <- size_dat_3yr %>%
  filter(X > 47) %>% 
  group_by(date) %>% 
  summarize(inner_count = sum(video_YN == "inner", na.rm = TRUE),
                   outer_count = sum(video_YN == "outer", na.rm = TRUE),
                   manual_count = sum(video_YN == "manual", na.rm = TRUE) +
                                  sum(video_YN == "manual_1", na.rm = TRUE) +
                                  sum(video_YN == "manual_2", na.rm = TRUE))

sum(spatial_dat$inner_count)
mean(spatial_dat$inner_count)
sd(spatial_dat$inner_count)
View(spatial_dat)
#inner sum = 480, mean = 2.54, SD = 3.08

mean(spatial_dat$inner_count/0.0865)
sd(spatial_dat$inner_count/0.0865)

sum(spatial_dat$outer_count)
mean(spatial_dat$outer_count)
sd(spatial_dat$outer_count)
#outer mean = 0.13, SD = 0.38

mean(spatial_dat$outer_count/0.0865)
sd(spatial_dat$outer_count/0.0865)

spatial_test <- wilcox.test(dat_no_19$inner_count, dat_no_19$outer_count, paired = TRUE)
spatial_test

spatial_chi_dat <- size_dat_3yr %>% 
  mutate(year_fac = as_factor(year(parse_date_time(date, order = "%m/%d/%y")))) %>% 
  filter(year_fac == "2020" | year_fac == "2021") %>% 
  mutate(year_fac = factor(year_fac)) %>%
  filter(video_YN == "inner" | video_YN == "outer")

spatial_chi_table <- table(spatial_chi_dat$year_fac, spatial_chi_dat$video)
View(spatial_chi_table)

chisq.test(spatial_chi_table)

122/(122+25)
#83.0% inner in 2020

358/(358+36)
#90.9% inner in 2021

size_dat_3yr %>%
  mutate(class = ifelse(length_raw_m < 2.9, "juvenile", "adult")) %>%
  group_by(video_YN, class) %>%
  summarize(count = n())

size_dat_3yr %>%
  group_by(video_YN) %>%
  summarize(mean_size = mean(length_raw_m, na.rm = TRUE))

transect_vis_raw <- read.csv("data_raw/transect_vis.csv")

transect_vis_dat <- transect_vis_raw %>% 
  mutate(inner_cat = ifelse(inner_vis > 2, "good", "poor")) %>% 
  mutate(outer_cat = ifelse(outer_vis > 2, "good", "poor"))

transect_vis_dat %>% 
  group_by(as_factor(inner_cat)) %>% 
  summarize(inner_cat = n())
149/(149+91)
#62.1% inner transect poor visibility

transect_vis_dat %>% 
  group_by(as_factor(outer_cat)) %>% 
  summarize(outer_cat = n())
92/(92+146)
#38.7% outer transect poor visibility

transect_vis_long_dat <- transect_vis_dat %>% 
  select(c(4:5)) %>% 
  pivot_longer(cols = c(1:2), names_to = "transect_position", values_to = "vis")

transect_vis_chi_table <- table(transect_vis_long_dat$transect_position, transect_vis_long_dat$vis)

transect_vis_chi_table

chisq.test(transect_vis_chi_table)

spatial_size_dat <- size_dat_3yr %>% 
  filter(video_YN == "outer" | video_YN == "inner")

spatial_size_aov <- aov(length_raw_m ~ video_YN, data = spatial_size_dat)
summary(spatial_size_aov)

spatial_size_dat %>% 
  group_by(video_YN) %>% 
  summarize(mean = mean(length_raw_m, na.rm = TRUE))
```

## Patterns of Abundance

### What are the average and range of transect detections?
```{r}
daily_3yr_dat %>% 
  group_by(year) %>% 
  summarize("Total sightings" = sum(transect_total, na.rm = TRUE),
            "Survey days" = n(),
            "Average density" = 1000000*sum(transect_total/transect_area_m2, na.rm = TRUE)/n(),
            "Maximum abundance" = max(transect_total, na.rm = TRUE)) %>% 
  gt() %>% 
    fmt_number(columns = 4, decimals = 2) %>% 
    cols_label("year" = "Year") %>% 
    cols_width("Total sightings" ~ px(80),
               "Maximum abundance" ~ px(80),
               "Average density" ~ px(80)) #%>% 
    cols_align(align = "center")
```

### Are time of day and day of year different between years?
```{r}
time_btwn_yrs_aov <- aov(hour ~ year, data = daily_3yr_narm)
summary(time_btwn_yrs_aov)
TukeyHSD(time_btwn_yrs_aov)
#2019 time of day significantly earlier (by about 2.5 hrs)

day_btwn_yrs_aov <- aov(day ~ year, data = daily_3yr_narm)
summary(day_btwn_yrs_aov)
TukeyHSD(day_btwn_yrs_aov)
#day of year not significantly different between 2019 and 2020, but 2021 was significantly earlier than 2019 (24 days) and 2020 (41 days)
```

### Nice timeseries plot where each year is overlaid
```{r}
daily_3yr_dat %>% 
  filter(!is.na(total_unique)) %>% 
  ggplot(aes(x = day, y = rollmean(total_unique, 14, na.pad = TRUE, align = "right"))) +
    geom_line(aes(color = as_factor(year)), size = 1) +
    scale_color_brewer(palette = "Dark2") +
  labs(x = "Month", y = "Count", color = "Year") +
  scale_x_continuous(
  breaks = lubridate::yday(seq(as.Date("2019-01-01"), 
                               by = "1 month", length.out = 12)), 
  labels = month.abb) +
  scale_y_continuous(breaks = c(0,2,4,6,8,10)) +
  theme_cowplot() +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))

ggsave("plots/abund_years_overlaid.png", width = 7, height = 4)

daily_3yr_dat %>% 
  filter(!is.na(total_unique)) %>%
  filter(ifelse(year == 2019, !is.na(transect_area_km2), !is.na(transect_area_km2+manual_area_km2))) %>%
  mutate(total_area = ifelse(year == 2019, transect_area_km2, transect_area_km2+manual_area_km2)) %>% 
  ggplot(aes(x = day, y = rollmean(total_unique/total_area, 14, na.pad = TRUE, align = "right"))) +
    geom_line(aes(color = as_factor(year)), size = 1) +
    scale_color_brewer(palette = "Dark2") +
  labs(x = "Month", y = bquote(Density~(sharks/km^2)), color = "Year") +
  scale_x_continuous(
  breaks = lubridate::yday(seq(as.Date("2019-01-01"), 
                               by = "1 month", length.out = 12)), 
  labels = month.abb) +
  scale_y_continuous(breaks = c(0,5,10,15,20,25)) +
  theme_cowplot() +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))
ggsave("plots/dens_years_overlaid.png", width = 7, height = 4)

View(daily_3yr_dat)
```

## Size 

### first off, a justification of ASL and Depth corrections:
```{r}
BOI_1_sub_dat <- read.csv("data_raw/csulb_tests_nov_14/BOI_1_submerged_JP_calculations.csv")
#View(BOI_1_sub_dat)

BOI_1_sub_dat$test_alt <- as.factor(as.character(BOI_1_sub_dat$test_alt))

BOI_1_sub_dat %>%
  pivot_longer(cols = c(5:7), names_to = "height_type", values_to = "length") %>%
  filter(method == "video") %>% 
  ggplot(aes(x = test_alt, y = length, fill = height_type)) +
    geom_boxplot() +
    geom_hline(yintercept = 1.97, linetype = 2, color = "red")
ggsave("plots/calibration_tests/height_comp_submerged.png", width = 10)
#visually apparent that at 20m, correcting for both ASL and depth get us the closest when target is submerged 1.5 m

BOI_1_surface_dat <- read.csv("data_raw/csulb_tests_nov_14/BOI_1_surface_JP_calculations.csv")
View(BOI_1_surface_dat)

BOI_1_surface_dat$test_alt <- as.factor(as.character(BOI_1_surface_dat$test_alt))

BOI_1_surface_dat %>%
  pivot_longer(cols = c(5:8), names_to = "height_type", values_to = "length") %>%
  filter(method == "video") %>% 
  ggplot(aes(x = test_alt, y = length, fill = height_type)) +
    geom_boxplot() +
    geom_hline(yintercept = c(1.97, 2.93), linetype = 2, color = "red")
ggsave("plots/calibration_tests/height_comps_surface.png", width = 10)
#visually apparent that ASL correction gets us closer to true size at 20m (no depth correction for surface target)
```

### determining accuracy and error margins from above tests:
```{r}
sub_dat_20 <- BOI_1_sub_dat %>%
  filter(method == "video") %>% 
  filter(test_alt == "20")

n <- length(sub_dat_20$size_asl_plus_depth)
mean_size <- mean(sub_dat_20$size_asl_plus_depth)
std_err <- sd(sub_dat_20$size_asl_plus_depth)/sqrt(n)
crit_val <- qt(0.975, df=(n-1))
margin_of_error <- std_err * crit_val
margin_of_error # 0.01136 m

#95% ci:
mean_size - margin_of_error #1.925 m
mean_size + margin_of_error #1.948 m

mean_size

known_size_pvc <- 1.97

sub_dat_20 %>% 
  mutate(error = size_asl_plus_depth - known_size_pvc) %>% 
  summarize(mean_error = mean(error))
#average size estimate of pvc target at 1.5m depth was 0.0335 m too small 

sub_dat_20 %>% 
  mutate(error = (size_asl_plus_depth - known_size_pvc)/known_size_pvc) %>% 
  summarize(mean_error = mean(error), sd_error = sd(error))
# mean error for submerged target is 1.702% with an sd of 1.545% - this is pretty good!

sub_dat_20 %>% 
  mutate(error = size_pvc - known_size_pvc) %>% 
  summarize(mean_error = mean(error))
#average UNADJUSTED size estimate of pvc target at 1.5m depth was 0.252 m too small!

sub_dat_20 %>% 
  mutate(error = (size_pvc - known_size_pvc)/known_size_pvc) %>% 
  summarize(mean_error = mean(error), sd_error = sd(error))
# mean error for UNADJUSTED submerged target is 12.799% with an sd of 1.357%
# adjustments reduce mean error by over 11%!

surf_dat_20 <- BOI_1_surface_dat %>%
  filter(method == "video") %>% 
  filter(test_alt == "20")

n <- length(surf_dat_20$size_pvc_asl)
mean_size <- mean(surf_dat_20$size_pvc_asl)
std_err <- sd(surf_dat_20$size_pvc_asl)/sqrt(n)
crit_val <- qt(0.975, df=(n-1))
margin_of_error <- std_err * crit_val
margin_of_error # 0.01032 m

#95% ci:
mean_size - margin_of_error #1.989 m
mean_size + margin_of_error #2.009 m

known_size_pvc <- 1.97

surf_dat_20 %>% 
  mutate(error = size_pvc_asl - known_size_pvc) %>% 
  summarize(mean_error = mean(error))
#size estimate of pvc target at surface was 0.029 m too large on average

surf_dat_20 %>% 
  mutate(error = (size_pvc_asl - known_size_pvc)/known_size_pvc) %>% 
  summarize(mean_error = mean(error), sd_error = sd(error))
#mean error is 1.466%, with an sd of 1.403%

surf_dat_20 %>% 
  mutate(error = size_pvc - known_size_pvc) %>% 
  summarize(mean_error = mean(error))
#UNADJUSTED size estimate of pvc target at surface was 0.0725 m too big on average
```
* I have SE, margin of error, confidence intervals, and average error - not sure which of these metrics is best to report

### Overestimates at 40, 50, 60 m
```{r}
sub_dat_40 <- BOI_1_sub_dat %>%
  filter(method == "video") %>% 
  filter(test_alt == "40")

n <- length(sub_dat_40$size_asl_plus_depth)
mean_size_40 <- mean(sub_dat_40$size_asl_plus_depth)
std_err <- sd(sub_dat_40$size_asl_plus_depth)/sqrt(n)
crit_val <- qt(0.975, df=(n-1))
margin_of_error <- std_err * crit_val
margin_of_error

mean_size_40
2.035 - 1.97

sub_dat_40 %>% 
  mutate(error = size_asl_plus_depth - known_size_pvc) %>% 
  summarize(mean_error = mean(error))
#mean 40 m overestimate was 6.5 cm, 1 pixel = 1.9 cm

sub_dat_50 <- BOI_1_sub_dat %>%
  filter(method == "video") %>% 
  filter(test_alt == "50")

sub_dat_50 %>% 
  mutate(error = size_asl_plus_depth - known_size_pvc) %>% 
  summarize(mean_error = mean(error))
#mean 50 m overestimate was 8.2 cm

sub_dat_60 <- BOI_1_sub_dat %>%
  filter(method == "video") %>% 
  filter(test_alt == "60")

sub_dat_60 %>% 
  mutate(error = size_asl_plus_depth - known_size_pvc) %>% 
  summarize(mean_error = mean(error))
#mean 60 m overestimate was 9.5 cm
```

### average size of each depth category
```{r}
size_dat_3yr %>%
  filter(unique == "Y") %>% 
  filter(!is.na(length_adj)) %>%
  filter(length_adj > 0) %>% 
  summarize(mean_surface = mean(length_adj[depth..JP. == "surface"]),
            mean_shallow = mean(length_adj[depth..JP. == "shallow"]),
            mean_deep = mean(length_adj[depth..JP. == "deep"]))

#significant difference?

depth_aov_dat <- size_dat_3yr %>% 
                  filter(unique == "Y") %>%
                  filter(!is.na(length_adj)) %>% 
                  filter(length_adj > 1) %>% 
                  filter(depth..JP. == "surface" | depth..JP. == "shallow" | depth..JP. == "deep")

shapiro.test(log(depth_aov_dat$length_adj))
#normal when log-transformed

depth_aov <- aov(log(length_adj) ~ depth..JP., data = depth_aov_dat)

summary(depth_aov)
plot(depth_aov)

TukeyHSD(depth_aov)
```
*mean logged sizes not significantly different between depth categories

### histograms of each depth category
```{r}
size_dat_3yr %>% 
  filter(depth..JP. == "surface") %>%
  filter(unique == "Y") %>% 
  filter(!is.na(length_adj)) %>% 
  nrow()
#54 unique surface sharks...

size_dat_3yr %>% 
  filter(depth..JP. == "shallow") %>%
  filter(unique == "Y") %>% 
  filter(!is.na(length_adj)) %>% 
  nrow()
#...289 shallow sharks...

size_dat_3yr %>% 
  filter(depth..JP. == "deep") %>%
  filter(unique == "Y") %>% 
  filter(!is.na(length_adj)) %>% 
  nrow()
#180 deep sharks

size_dat_3yr %>% 
  filter(!is.na(depth..JP.)) %>%
  filter(unique == "Y") %>%
  filter(length_adj_m > 0) %>% 
  nrow()
#...out of 524 adjusted-sized sharks

54/524
# 10.3% surface

289/524
# 55.2% shallow

180/524
# 34.4% deep

size_dat_2021 %>% 
  filter(length_adj_m > 0) %>% 
  filter(unique == "Y") %>%
  ggplot(aes(x = length_adj)) +
    geom_histogram() +
    geom_vline(xintercept = 9.8, lty = 2, size = 1, color = "red") +
    geom_vline(xintercept = 8, lty = 2, size = 1, color = "blue") +
    theme_bw() +
    scale_x_continuous(breaks = c(4,6,8,10,12,14,16,18,20)) +
    labs(x = "Length (ft)", y = "Count")
ggsave("plots/2021_size_histo.png", height = 5, width = 7)

size_dat_3yr %>% 
  filter(length_adj_m > 0) %>% 
  filter(unique == "Y") %>%
  ggplot(aes(x = length_adj_m)) +
    geom_histogram() +
    geom_vline(xintercept = 3.5, lty = 2, size = 1, color = "red") +
    geom_vline(xintercept = 3, lty = 2, size = 1, color = "blue") +
    theme_bw() +
    scale_x_continuous(breaks = c(1,2,3,4,5)) +
    labs(x = "Length (meters)", y = "Count")
ggsave("plots/3yr_size_histo.png", height = 5, width = 7)

daily_3yr_dat %>%
  summarize(juveniles = sum(juvenile), adults = sum(adult))
#330 juveniles and 173 adults

size_dat_2021 %>% 
  filter(depth..JP. == "surface") %>% 
  ggplot(aes(x = length_raw_m)) +
    geom_histogram()
#this isn't going to be very helpful for comparing between depths

size_dat_2021 %>% 
  filter(length_adj_m > 0) %>%
  filter(unique == "Y") %>% 
  pivot_longer(c(length_raw_m, length_adj_m), names_to = "measure", values_to = "length_meters") %>% 
  ggplot(aes(x = length_meters)) +
    geom_histogram(aes(fill = measure), position = "dodge") +
    facet_wrap(~depth..JP.)
#this is ok
```

### Do adjustments affect size distribution?
```{r}
size_dat_3yr %>% 
  filter(unique == "Y") %>% 
  filter(!is.na(length_adj)) %>%
  filter(length_adj_m > 1) %>%
  mutate(year = year(as_date(date, format = '%m/%d/%Y'))) %>% 
  pivot_longer(c(length_raw_m, length_adj_m), names_to = "Measure", values_to = "Length") %>% 
  ggplot(aes(x = Length)) +
    geom_histogram(aes(fill = Measure, color = Measure), alpha = 0.6, position = "dodge", binwidth = 0.1) +
    scale_fill_brewer(palette = "Dark2", labels=c("Adjusted","Unadjusted")) +
    scale_color_brewer(palette = "Dark2", labels=c("Adjusted","Unadjusted")) +
    theme_cowplot() +
    theme(legend.position = "bottom", legend.spacing.x = unit(1, 'cm'),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA)) +
    guides(fill = guide_legend(label.position = "bottom")) +
    facet_grid(rows = vars(year)) +
    theme_clean() +
    #theme(strip.text.y = element_blank()) +
    labs(x = "Length (m)", y = "Count", fill = "Measure:", color = "Measure:")
ggsave("plots/3yr_faceted_size_adjustment_comp.png", height = 7, width = 4.6)
 
size_dat_3yr %>% 
  filter(unique == "Y") %>% 
  filter(!is.na(length_adj)) %>%
  filter(length_adj_m > 1) %>% 
  pivot_longer(c(length_raw_m, length_adj_m), names_to = "Measure", values_to = "Length") %>% 
  ggplot(aes(x = Length)) +
    geom_histogram(aes(fill = Measure, color = Measure), alpha = .5, position = "dodge", binwidth = 0.1) +
    scale_fill_brewer(palette = "Dark2", labels=c("Adjusted","Unadjusted")) +
    scale_color_brewer(palette = "Dark2", labels=c("Adjusted","Unadjusted")) +
    theme_cowplot() +
    theme(legend.position = "bottom", legend.spacing.x = unit(1, 'cm'),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA)) +
    guides(fill = guide_legend(label.position = "bottom")) +
    labs(x = "Length (m)", y = "Count", fill = "Measure:", color = "Measure:")
ggsave("plots/size_adjustment_comp.png", height = 7, width = 4.6)
#shows how peaks in raw get shifted to the right when the adjustment is made. looks cool when narrow. Probably a supplementary figure

size_dat_3yr %>% 
  filter(unique == "Y") %>% 
  filter(!is.na(length_adj_m)) %>% 
  filter(!is.na(length_raw_m)) %>%
  filter(length_adj_m > 1) %>%
  summarize(median_adj_length = median(length_adj_m), median_raw_length = median(length_raw_m), mean_adjustment = mean(length_adj_m - length_raw_m), sd_adjustment = sd(length_adj_m - length_raw_m), max_adj = max(length_adj_m - length_raw_m), min_adj = min(length_adj_m - length_raw_m))

#looking at how adjustments affect juvie:adult ratio with the 3m cutoff
size_dat_3yr %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>%
  filter(!is.na(length_raw_m)) %>%
  filter(length_adj_m > 1) %>%
  mutate(class_raw = ifelse(length_raw_m < 3, "Juvenile", "Adult")) %>% 
  mutate(class_adj = ifelse(length_adj_m < 3, "Juvenile", "Adult")) %>% 
  count(class_raw)
#86 adults and 438 juveniles with raw measurements, 189 adults and 335 juveniles with adjusted measurements - adjustments bring 103 sharks from juvenile to adult length

#looking at how adjustments affect shallow sharks (overlapping histograms):
size_dat_3yr %>% 
  filter(unique == "Y") %>%
  filter(depth..JP. == "shallow") %>% 
  filter(!is.na(length_adj)) %>% 
  pivot_longer(c(length_raw_m, length_adj_m), names_to = "measure", values_to = "length_meters") %>% 
  ggplot(aes(x = length_meters)) +
    geom_histogram(aes(fill = measure, color = measure), alpha = .5, position = "dodge", binwidth = 0.1) +
    scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2")
# I actually like this dodged the most, shows how peaks in raw get shifted to the right

# same as above but faceted:
size_dat_3yr %>% 
  filter(depth..JP. == "shallow") %>% 
  filter(!is.na(length_adj)) %>% 
  pivot_longer(c(length_raw_m, length_adj_m), names_to = "measure", values_to = "length_meters") %>% 
  ggplot(aes(x = length_meters)) +
    geom_histogram(aes(fill = measure), binwidth = 0.1) +
    facet_grid(measure~.) +
    scale_fill_brewer(palette = "Dark2")
# not sure what this really tells me. Overall smoother distribution for the adjusted lengths, which I suppose makes sense. Adjusted lengths are shifted to the right...

size_dat_3yr %>% 
  filter(unique == "Y") %>%
  filter(depth == "shallow") %>% 
  filter(!is.na(length_adj_m)) %>% 
  summarize(median_adj = median(length_adj_m), median_raw = median(length_raw_m))
#by approximately 0.3 meters

size_dat_3yr %>% 
  filter(unique == "Y") %>%
  filter(depth == "shallow") %>% 
  filter(!is.na(length_adj_m)) %>%
  mutate(adj_diff = length_adj_m - length_raw_m) %>% 
  summarize(mean_adj_diff = mean(adj_diff))
#average shallow adjustment was an increase of 0.33 meters

size_dat_3yr %>% 
  filter(unique == "Y") %>%
  filter(depth == "surface") %>% 
  filter(!is.na(length_adj_m)) %>%
  mutate(adj_diff = length_adj_m - length_raw_m) %>% 
  summarize(mean_adj_diff = mean(adj_diff))
#average surface adjustment was an increase of 0.13 meters

size_dat_3yr %>% 
  filter(unique == "Y") %>%
  filter(depth == "deep") %>% 
  filter(!is.na(length_adj_m)) %>%
  filter(!is.na(length_raw_m)) %>% 
  mutate(adj_diff = length_adj_m - length_raw_m) %>% 
  summarize(mean_adj_diff = mean(adj_diff))
#average deep adjustment was increase of 0.47 meters
```

### Size classes
```{r}
ggplot(data = daily_3yr_dat, aes(x = juvenile/total_sized)) +
  geom_histogram()

ggplot(data = daily_3yr_dat, aes(x = date, y = juvenile/total_sized)) +
  geom_point()

daily_3yr_dat %>% 
  filter(total_sized != 0) %>% 
  ggplot(aes(x = as_factor(year), y = juvenile/total_sized)) +
    geom_boxplot()
#not sure why 2020 looks weird 

daily_3yr_dat %>% 
  filter(total_sized != 0) %>% 
  filter(year == "2020") %>% 
  ggplot(aes(x = juvenile/total_sized)) +
    geom_bar()

daily_3yr_dat %>% 
  filter(total_sized != 0) %>% 
  ggplot(aes(x = juvenile/total_sized, fill = as_factor(year))) +
    geom_histogram(position = "dodge", bins = 10)
#2021 has a LOT of days where there were only adult-sized sharks, and 2020 has tons of days where only juvenile-sized sharks were seen - I want a better way to visualize this for Ch. 2

daily_3yr_dat %>% 
  filter(total_sized != 0) %>% 
  ggplot(aes(x = juvenile/total_sized, color = as_factor(year))) +
    geom_density(size = 1.1, adjust = 0.5) +
  scale_color_brewer(palette = "Dark2") +
  labs(x = "Proportion Juvenile", y = "Relative Density", color = "Year") +
  theme_cowplot() +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA),
      legend.position = c(0.3, 0.7))
ggsave("plots/yearly_juv_prop_density.png", width = 5, height = 5)

size_dat_3yr %>% 
  ggplot(aes(x = length_adj_m, color = as_factor(year(parse_date_time(date, order = "%m/%d/%y"))))) +
    geom_density(size = 1.1) +
  scale_color_brewer(palette = "Dark2") +
  labs(x = "Total Length (m)", y = "Relative Frequency", color = "Year") +
  theme_cowplot() +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA),
      legend.position = c(0.7, 0.7))
ggsave("plots/yearly_size_distribution.png", width = 6, height = 5)

### comparison to Tanaka et al. 2021:
size_dat_3yr %>% 
  filter(length_adj_m > 0) %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>% 
  filter(length_adj_m < 2.5) %>% 
  nrow()
#134 less than 2.5 m 

size_dat_unique %>% 
  filter(length_adj_m > 0) %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>%
  filter(length_adj_m >= 2.5) %>% 
  nrow()
#379 greater than 2.5 m

134/(134+379)
# 26.1%

### Comaprison to Colefax et al. 2020:
size_dat_3yr %>% 
  filter(length_adj_m > 0) %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>%
  summarize(mean = mean(length_adj_m, na.rm = TRUE))
#mean 2.87m

size_dat_3yr %>% 
  filter(length_adj_m > 0) %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>%
  group_by(as_factor(year(parse_date_time(date, order = "%m/%d/%y")))) %>% 
  summarize(mean = mean(length_adj_m, na.rm = TRUE))

size_dat_3yr %>% 
  filter(length_adj_m > 0) %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>% 
  filter(length_adj_m < 3.4) %>% 
  nrow()
#440 less than 3.4 m 

size_dat_unique %>% 
  filter(length_adj_m > 0) %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>%
  filter(length_adj_m >= 3.4) %>% 
  nrow()
#80 greater than 2.5 m

80/(80+440)
#15.4% 
```

### Change in size classes across years (INCLUDED IN THESIS)
```{r}
daily_3yr_dat %>% 
  mutate(juv_prop = juvenile/total_sized) %>% 
  group_by(as_factor(year)) %>% 
  summarize(mean = mean(juv_prop, na.rm = TRUE))
#NOT using this in the thesis

prop_dat <- daily_3yr_dat %>% 
  mutate(juv_prop = juvenile/total_sized) %>% 
  mutate(year_fac = as_factor(year))

prop_dat %>% 
  ggplot(aes(x = juv_prop)) +
    geom_density()

median(round(size_dat_3yr$length_adj_m, digits = 1), na.rm = TRUE)

size_chi_dat <- joined_3yr %>% 
  mutate(year_fac = as_factor(year(parse_date_time(date, order = "%m/%d/%y")))) %>% 
  filter(unique == "Y") %>% 
  filter(length_adj_m > 1) %>% 
  mutate(size_class = ifelse(length_adj_m < 3.000, "juvenile", "adult"))

size_chi_table <- table(size_chi_dat$year_fac, size_chi_dat$size_class)
size_chi_table
14 + 48 + 112 + 33 + 141 + 168
#516 sized sharks
#174 adults
#342 juveniles
342/516
#66.3% juveniles

size_chi_table_2 <- size_classed_3yr %>% 
  mutate(year_fac = lubridate::year(parse_date_time(date, order = "%m/%d/%y"))) %>% 
  group_by(year_fac) %>% 
  summarize(juvenile = sum(juvenile), adult = sum(adult))
#just a check, same as above

chisq.test(size_chi_table)
#sig. diff. between size distribution p < 0.005

size_chi_table[1,2]/(size_chi_table[1,1] + size_chi_table[1,2])
#70.2 % juvenile in 2019

size_chi_table[2,2]/(size_chi_table[2,1] + size_chi_table[2,2])
#74.6% juvenile in 2020

size_chi_table[3,2]/(size_chi_table[3,1] + size_chi_table[3,2])
#60.0% juvenile in 2021

#post-hoc w/ Bonferroni Adjustment - 3 comparisons so alpha = 0.05/3 = 0.0167

#2019-2020
chisq.test(size_chi_table[c(1,2),])
#not different

#2019-2021
chisq.test(size_chi_table[c(1,3),])
#not different

#2020-2021
chisq.test(size_chi_table[c(2,3),])
#different
```

## Modelling effects of environmental and detection-related variables on transect density

### Different temperature sources (LTER vs CSULB)
```{r}
#CSULB sst:
cor.test(gam_dat2$sst, gam_dat2$Temp_top, method = "pearson")
#0.80

ggplot(gam_dat2, aes(x = sst, y = Temp_top)) +
  geom_point()
#lots of missing data

daily_3yr_dat %>% 
  filter(!is.na(sst)) %>% 
  nrow()
#only 135 days with CSULB sst

#CSULB sft:
cor.test(gam_dat_lb$sft, gam_dat_lb$Temp_top, method = "pearson")
#0.85

cor.test(gam_dat_lb$sft, gam_dat_lb$sst, method = "pearson")

ggplot(gam_dat_lb, aes(x = sft, y = sst)) +
  geom_point()

ggplot(gam_dat_lb, aes(x = sft)) +
  geom_bar()
View(gam_dat_lb)
anova(lbgam_all)
daily_3yr_dat %>% 
  filter(!is.na(sft)) %>% 
  nrow()
#316 days with CSULB sft

daily_3yr_dat %>% 
  filter(!is.na(Temp_top)) %>% 
  filter(Temp_top < 100) %>% 
  nrow()
#compared to 322 with Carp LTER sft

#Visualizing data coverage:
daily_3yr_dat %>% 
  filter(Temp_top < 100) %>% 
  ggplot(aes(x = date_hour)) +
    geom_point(aes(y = sft), color = "red") +
    geom_point(aes(y = sst), color = "green") +
    geom_point(aes(y = Temp_top), color = "blue")
```

### THESIS VERSION ALL SHARKS 
```{r}
gam_dat_lb <- daily_3yr_dat %>%
  mutate(year = as.factor(as.character(year))) %>%
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(yday = yday(mdy)) %>% 
  filter(transect_area_km2 > 0.17) %>%
  mutate(beaufort = ifelse(beaufort > 1, "2+", beaufort)) %>%
  mutate(beaufort = ifelse(beaufort < 2, "0-1", beaufort)) %>%
  mutate(vis = ifelse(vis == 1 | vis == 2, "low",
                      ifelse(vis == 4 | vis == 5, "high", "med"))) %>%
  mutate(beaufort = factor(beaufort, levels = c("0-1", "2+"))) %>% 
  mutate(vis = factor(vis, levels = c("low", "med", "high"))) %>% 
  filter(!is.na(year) & !is.na(hour) & !is.na(yday) &
         !is.na(beaufort) &
         !is.na(vis) &
        !is.na(tide) &
          !is.na(sft) &
          !is.na(WVHT) & 
          !is.na(chl_interp))
View(gam_dat_lb)

lbgam_all_pois <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, 
                       method = "REML", select = TRUE)
sum(residuals(lbgam_all_pois, type = "pearson")^2) / df.residual(lbgam_all_pois)
#overdispersed, so using negative binomial

lbgam_all <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)

summary(lbgam_all)
#DE = 53, n = 272
sum(gam_dat_lb$total_unique, na.rm = TRUE)
#715 observations

gam.check(lbgam_all)
#no issues

anova(lbgam_all)
#year, day, and hour all significant
#vis significant, beaufort not
#tide and sft significant, waveheight and chl_interp not

visreg(lbgam_all, "tide", cond=list(total_area=1))

mgcv::concurvity(lbgam_all, full = FALSE)

lbgam_all_no_year <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_year)
53-39.3
#year DE = 13.7

lbgam_all_no_hour <- mgcv::gam(total_unique ~ year +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_hour)
53 - 50
#hour DE = 3.0%

lbgam_all_no_day <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_day)
53 - 39.5
#day DE = 13.5

lbgam_all_no_sft <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_sft)
53-50.4
#SFT DE = 2.6%

lbgam_all_no_chl <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_chl)
53 - 52.4
#chl DE = 0.6%

lbgam_all_no_tide <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_tide)
53 - 52
#tide DE = 1%

lbgam_all_no_wvht <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_wvht)
53 - 52.9
#wvht DE = 0.1%

lbgam_all_no_beau <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_beau)
53-52.4
#beaufort = 0.6%

lbgam_all_no_vis <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_no_vis)
53 - 50.1
#vis DE = 2.9%

### Post-hoc of year
names(coef(lbgam_all))
year_contrast_all <- glht(lbgam_all, linfct = c("year2020 = 0", "year2021 = 0", "year2021 - year2020 = 0"))
summary(year_contrast_all)

ggplot(gam_dat_lb, aes(x = year, y = total_unique)) +
  geom_bar(stat = "summary", fun = "mean")
#increase in average count by ~2 sharks each year

ggplot(gam_dat_lb, aes(x = year, y = total_unique/total_area)) +
  geom_bar(stat = "summary", fun = "mean")

### Post-hoc of vis
names(coef(lbgam_all))
vis_contrast_all <- glht(lbgam_all, linfct = c("vismed = 0", "vishigh = 0", "vishigh - vismed = 0"))
summary(vis_contrast_all)
visreg(lbgam_all, "vis")
```

### THESIS VERSION JUVENILES 
```{r}
lbgam_juv <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv)
#DE = 28.5, n = 264
sum(gam_dat_lb$juvenile)
sum(gam_dat_lb$adult)

gam.check(lbgam_juv)
#issue with sft, but increasing k to 50 did not change results. Will look at reduced model for sensitivity
visreg(lbgam_juv, "sft")

ggplot(gam_dat_lb, aes(x = sft, y = juvenile)) +
  geom_jitter() +
  geom_smooth(method = "lm")

anova(lbgam_juv)
#year and day significant
#hour marginal
#vis significant, beaufort not
#sft significant, tide, waveheight and chl_interp not

lbgam_juv_no_year <- mgcv::gam(juvenile ~ s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_year)
28.5-22.6
#year DE = 5.9

lbgam_juv_no_hour <- mgcv::gam(juvenile ~ year +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_hour)
28.5 - 27.4
#hour DE = 1%

lbgam_juv_no_day <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_day)
28.5 - 13.7
#day DE = 14.8

lbgam_juv_no_sft <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_sft)
28.5 - 26.4
#SFT DE = 2.1

lbgam_juv_no_chl <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_chl)
28.5 - 28.5
#chl DE = 0.0%

lbgam_juv_no_tide <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_tide)
28.5 - 28
#tide DE = 0.5%

lbgam_juv_no_wvht <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_wvht)
28.5 - 28.5
#wvht DE = 0.0%

lbgam_juv_no_beau <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_beau)
28.5-28.1
#beaufort = 0.6%

lbgam_juv_no_vis <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_juv_no_vis)
28.5 - 24.5
#vis DE = 3.8%

### Post-hoc of year
year_contrast_juv <- glht(lbgam_juv, linfct = c("year2020 = 0", "year2021 = 0", "year2021 - year2020 = 0"))
summary(year_contrast_juv)

### post-hoc of visibility
vis_contrast_juv <- glht(lbgam_juv, linfct = c("vismed = 0", "vishigh = 0", "vishigh - vismed = 0"))
summary(vis_contrast_juv)
visreg(lbgam_juv, "vis")
```

### THESIS VERSION ADULTS 
```{r}
lbgam_adult <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult)
#DE = 31.2, n = 264

gam.check(lbgam_adult)
#all good

anova(lbgam_adult)
#year significant, day significant in 2019 and 2021 but marginal in 2020
#hour not significant
#vis significant, beaufort not
#sft, waveheight, chl and tide not 
visreg(lbgam_adult, "sft", scale = "response", cond = list(area_20m = 1))

lbgam_adult_no_year <- mgcv::gam(adult ~ s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_year)
31.2-21.2
#year DE = 10

lbgam_adult_no_hour <- mgcv::gam(adult ~ year +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_hour)
31.2 - 30.6
#hour DE = 0.6%

lbgam_adult_no_day <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_day)
31.2 - 23.9
#day DE = 7.3

lbgam_adult_no_sft <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_sft)
31.2 - 31.2
#SFT DE = 0

lbgam_adult_no_chl <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_chl)
31.2 - 30.8
#chl DE = 0.4%

lbgam_adult_no_tide <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_tide)
31.2 - 30.9
#tide DE = 0.3%

lbgam_adult_no_wvht <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_wvht)
31.2 - 31.3
#wvht DE = < 0

lbgam_adult_no_beau <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_beau)
31.2-31.4
#beaufort = < 0

lbgam_adult_no_vis <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 10, by = year) +
                                      beaufort +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_adult_no_vis)
31.2 - 30.2
#vis DE = 1.0%

### Post-hoc of year
year_contrast_adult <- glht(lbgam_adult, linfct = c("year2020 = 0", "year2021 = 0", "year2021 - year2020 = 0"))
summary(year_contrast_adult)

### post-hoc of visibility
vis_contrast_adult <- glht(lbgam_adult, linfct = c("vismed = 0", "vishigh = 0", "vishigh - vismed = 0"))
summary(vis_contrast_adult)
visreg(lbgam_adult, "vis")

anova(lbgam_adult)
#juv vis p < 0.05
#all vis p < 0.001
#adult vis p < 0.05
```

### Visualizing SFT w/ visreg and ggplot (FOR THESIS)
```{r}
sft_all <- visreg(lbgam_all, "sft", scale = "response", cond = list(total_area = 1))
View(sft_all)
ggplot(sft_all$fit, aes(x = sft)) +
  geom_ribbon(aes(ymin = visregLwr, ymax = visregUpr), alpha = 0.2) +
  geom_line(aes(y = visregFit), color = "blue", size = 1) +
  geom_point(data = sft_all$res, aes(y = visregRes)) +
  theme_cowplot() +
  scale_x_continuous(breaks = c(10,12,14,16,18,20,22,24)) +
  labs(x = bquote("Sea Floor Temperature"), y = bquote("Relative Density")) +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))

sft_juv <- visreg(lbgam_juv, "sft", scale = "response", cond = list(area_20m = 1))

ggplot(sft_juv$fit, aes(x = sft)) +
  geom_ribbon(aes(ymin = visregLwr, ymax = visregUpr), alpha = 0.2) +
  geom_line(aes(y = visregFit), color = "blue", size = 1) +
  theme_cowplot() +
  scale_x_continuous(breaks = c(10,12,14,16,18,20,22,24)) +
  labs(x = bquote("Sea Floor Temperature"), y = bquote("Density (sharks/"~km^2~")")) +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))

sft_adult <- visreg(lbgam_adult, "sft", scale = "response", cond = list(area_20m = 1))

ggplot(sft_adult$fit, aes(x = sft)) +
  geom_ribbon(aes(ymin = visregLwr, ymax = visregUpr), alpha = 0.2) +
  geom_line(aes(y = visregFit), color = "blue", size = 1) +
  theme_cowplot() +
  scale_x_continuous(breaks = c(10,12,14,16,18,20,22,24)) +
  labs(x = bquote("Sea Floor Temperature"), y = bquote("Density (sharks/"~km^2~")")) +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))

### could show all of the model output plots, or just plot temp vs density:
ggplot(gam_dat_lb, aes(x = sft)) +
  geom_point(aes(y = total_unique/total_area)) +
  geom_point(aes(y = juvenile/area_20m), color = "blue") +
  geom_point(aes(y = adult/area_20m), color = "orange")
#this won't work

###plotting all three GAM curves on same plot:
sft_all$fit$Model <- "Overall"
sft_juv$fit$Model <- "Juvenile"
sft_adult$fit$Model <- "Adult"

names(sft_juv$fit) <- names(sft_adult$fit)
names(sft_all$fit) <- names(sft_adult$fit)

sft_bind <- rbind(sft_all$fit, sft_juv$fit, sft_adult$fit)
sft_bind$Model <- factor(sft_bind$Model, levels = c("Overall", "Juvenile", "Adult"))

ggplot(sft_bind, aes(x = sft, y = visregFit)) +
  geom_line(aes(color = Model), size = 1.4) +
  geom_ribbon(aes(ymin = visregLwr, ymax = visregUpr, fill = Model), alpha = 0.2, show.legend = FALSE) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  theme_cowplot() +
  scale_x_continuous(breaks = c(10,12,14,16,18,20,22,24)) +
  labs(x = bquote("Sea Floor Temperature (\u00B0C)"), y = bquote(Density~ (sharks/km^2))) +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA)) 
ggsave("plots/sft_smooths_with_CI.png", width = 6, height = 4)
```

# Visualizing seasonality w/ visreg
```{r}
visreg(lbgam_all, "yday", by = "year")

visreg(lbgam_juv, "yday", by = "year")

visreg(lbgam_adult, "yday", by = "year")

yday_dat <- visreg(lbgam_all, "yday", by = "year",scale = "response",
                   cond = list(total_area = 1))
View(yday_dat)

ggplot(yday_dat$fit, aes(x = yday)) +
  geom_line(aes(y = visregFit, color = year), size = 1.4) +
  geom_ribbon(aes(ymin = visregLwr, ymax = visregUpr, fill = year), alpha = 0.2, show.legend = FALSE) +
  theme_cowplot() +
  scale_x_continuous(
  breaks = lubridate::yday(seq(as.Date("2019-01-01"), by = "1 month",
                               length.out = 12)), labels = month.abb) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  labs(x = bquote("Month"), y = bquote(Density~(sharks/km^2)), color = "Year") +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))
ggsave("plots/yday_smooths_with_CI.png", width = 6, height = 4)
```

  ###Comparing directionality of effects using visreg
```{r}
visreg(lbgam_all, "year", scale = "response", cond = list(total_area = 1))
visreg(lbgam_juv, "year", scale = "response", cond = list(area_20m = 1))
visreg(lbgam_adult, "year", scale = "response", cond = list(area_20m = 1))

visreg(lbgam_all, "hour", scale = "response", cond = list(total_area = 1))
visreg(lbgam_juv, "hour", scale = "response", cond = list(area_20m = 1))
visreg(lbgam_adult, "hour", scale = "response", cond = list(area_20m = 1))
summary(lbgam_adult)

visreg(lbgam_all, "yday", by = "year", scale = "response", cond = list(total_area = 1))
visreg(lbgam_juv, "yday", by = "year", scale = "response", cond = list(area_20m = 1))
visreg(lbgam_adult, "yday", by = "year", scale = "response", cond = list(area_20m = 1))

visreg(lbgam_all, "tide", cond = list(total_area = 1))
visreg(lbgam_juv, "sft", cond = list(area_20m = 1))
visreg(lbgam_adult, "sft", scale = "response", cond = list(area_20m = 1))

visreg_data <- visreg(lbgam_all)
View(visreg_data)
fits <- as.data.frame(visreg_data[[7]][["fit"]][["visregFit"]])
sft <- as.data.frame(visreg_data[[7]][["fit"]][["sft"]])

sft_fits_all <- bind_cols(fits, sft)
View(sft_fits_all)

visreg_data_juv <- visreg(lbgam_juv)
View(visreg_data_juv)
fits_juv <- as.data.frame(visreg_data_juv[[7]][["fit"]][["visregFit"]])
sft_juv <- as.data.frame(visreg_data_juv[[7]][["fit"]][["sft"]])

sft_fits_juv <- bind_cols(fits_juv, sft_juv)
View(sft_fits_juv)

ggplot(gam_dat_lb, aes(x = sft, y = juvenile/area_20m)) +
         geom_point() +
         geom_smooth(method = "lm")

anova(lbgam_all)
```

### FOR THESIS: testing other temp sources
```{r}
lbgam_all_sst <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10) +
                                      s(yday, k = 30, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sst, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb, method = "REML",
                       family = nb, select = TRUE)
summary(lbgam_all_sst)
anova(lbgam_all_sst)

```

### Comparing a model w/ sft as only envt'l variable to one with all other envt's variables but no sft
```{r}
lbgam_sft_only <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10, by = year) +
                                      s(yday, k = 25, by = year) +
                                      s(sft, k = 50) +
                                      offset(total_area),
                       data = gam_dat_lb_tot_full, 
                       method = "REML", family = nb, select = TRUE)
gam.check(lbgam_sft_only)
summary(lbgam_sft_only)
#50.7 DE! n = 313

anova(lbgam_sft_only)

visreg(lbgam_sft_only)

summary(lbgam_tot_chl_no_sft)
#59.1% DE n = 237

summary(lbgam_tot_chl)
#58.4% n = 235

summary(lbgam_tot_full)
#DE = 62.2%, n = 249

AICc(lbgam_sft_only, lbgam_tot_chl_no_sft, lbgam_tot_chl, lbgam_tot_full)
#AIC is much higher, along with the model w/out chl

ggplot(daily_3yr_dat, aes(x = sft, y = chl_interp)) +
  geom_point() +
  geom_smooth()

lbgam_sft_chl_only <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10, by = year) +
                                      s(yday, k = 25, by = year) +
                                      beaufort +
                                      vis +
                                      s(sft, k = 50) +
                                      s(chl_interp, k = 5) +
                                      offset(total_area),
                       data = gam_dat_lb_tot_full, 
                       method = "REML", family = nb, select = TRUE)
summary(lbgam_sft_chl_only)
#chl marginal and sft penalized to zero
```

### LTER data instead of CSULB data
```{r}
ltergam_tot_full <- mgcv::gam(total_unique ~ year +
                                      s(hour, k = 10, by = year) +
                                      s(day, k = 10, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(Temp_top, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(total_area),
                       data = gam_dat_lb_tot_full, 
                       method = "REML", family = nb, select = TRUE)

summary(ltergam_tot_full)
#DE = 57%, n = 234 - should definitely use CSULB data!
anova(ltergam_tot_full)
#year, vis significant parametrics
#day sig. all three years
#hour sig. in 2020 and 2021
#sft sig, tide marginal
gam.check(ltergam_tot_full)
#marginal issues with hour (month had worse issues)
```

### comparing sst and sft using 2021 (sft model here is same as 2021 model below)
```{r}
gam_dat_2021 <- daily_3yr_dat %>%
  mutate(year = as.factor(as.character(year))) %>%
  filter(year == 2021) %>%
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(beaufort = as.factor(beaufort)) %>% 
  mutate(vis = as.factor(vis)) %>% 
  mutate(presence = ifelse(total_unique > 0, 1, 0)) %>% 
  mutate(yday = yday(mdy))

sst_2021_gam <- mgcv::gam(total_unique ~
                                      s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sst, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(sst_2021_gam)
#47.6% DE, n = 120
visreg(sst_2021_gam)

sft_2021_gam <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp) +
                                      offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(sft_2021_gam)
#45.1% DE, n = 120

anova(sst_2021_gam)
#vis, hour, day, tide, SST significant
#beaufort, chl, and wvht n.s.

anova(sft_2021_gam)
#vis, hour, day, tide significant
#SFT NOT SIGNIFICANT
#beaufort, wvht, chl also n.s.

### Same as above but just using temperature and temporal variables:

sst_only_2021_gam <- mgcv::gam(total_unique ~
                                      s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      s(sst, k = 10) +
                                      offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(sst_only_2021_gam)
#30.1% DE, n = 123

sft_only_2021_gam <- mgcv::gam(total_unique ~
                                      s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      s(sft, k = 10) +
                                      offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(sft_only_2021_gam)
#21.9% DE, n = 123

anova(sst_only_2021_gam)
visreg(sst_only_2021_gam)
#SST is significant and more or less linear (higher sst = higher density)

anova(sft_only_2021_gam)
visreg(sft_only_2021_gam)
#SFT is NOT significant, penalized to 0.2 edf

AICc(sst_2021_gam, sft_2021_gam, sst_only_2021_gam, sft_only_2021_gam)
```

### single-year models
```{r}
gam_dat_2019 <- daily_3yr_dat %>%
  mutate(year = as.factor(as.character(year))) %>%
  filter(year == 2019) %>%
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(yday = yday(mdy)) %>% 
  filter(transect_area_km2 > 0.17) %>%
  mutate(beaufort = ifelse(beaufort > 1, "2+", beaufort)) %>%
  mutate(beaufort = ifelse(beaufort < 2, "0-1", beaufort)) %>%
  mutate(vis = ifelse(vis == 1 | vis == 2, "low",
                      ifelse(vis == 4 | vis == 5, "high", "med"))) %>%
  mutate(beaufort = factor(beaufort, levels = c("0-1", "2+"))) %>% 
  mutate(vis = factor(vis, levels = c("low", "med", "high")))

lb_gam_2019 <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)

gam_dat_2020 <- daily_3yr_dat %>%
  mutate(year = as.factor(as.character(year))) %>%
  filter(year == 2020) %>%
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(beaufort = ifelse(beaufort > 1, "2+", beaufort)) %>%
  mutate(beaufort = ifelse(beaufort < 2, "0-1", beaufort)) %>%
  mutate(vis = ifelse(vis == 1 | vis == 2, "low",
                      ifelse(vis == 4 | vis == 5, "high", "med"))) %>%
  mutate(beaufort = factor(beaufort, levels = c("0-1", "2+"))) %>% 
  mutate(vis = factor(vis, levels = c("low", "med", "high"))) %>% 
  mutate(presence = ifelse(total_unique > 0, 1, 0)) %>% 
  mutate(yday = yday(mdy))

lb_gam_2020 <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp) +
                         offset(total_area),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)

gam_dat_2021 <- daily_3yr_dat %>%
  mutate(year = as.factor(as.character(year))) %>%
  filter(year == 2021) %>%
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(beaufort = ifelse(beaufort > 1, "2+", beaufort)) %>%
  mutate(beaufort = ifelse(beaufort < 2, "0-1", beaufort)) %>%
  mutate(vis = ifelse(vis == 1 | vis == 2, "low",
                      ifelse(vis == 4 | vis == 5, "high", "med"))) %>%
  mutate(beaufort = factor(beaufort, levels = c("0-1", "2+"))) %>% 
  mutate(vis = factor(vis, levels = c("low", "med", "high"))) %>%  
  mutate(presence = ifelse(total_unique > 0, 1, 0)) %>% 
  mutate(yday = yday(mdy))

lb_gam_2021 <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp) +
                         offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
```

### Checking, summarizing, anova-ing single-year models
```{r}
gam.check(lb_gam_2019)
#k indices OK

summary(lb_gam_2019)
#tide and sft penalized to zero
#DE = 83.1%, n = 73

anova(lb_gam_2019)
#day and chl are significant in 2019, hour and wvht marginal

gam.check(lb_gam_2020)
#k-indices OK

summary(lb_gam_2020)
#hour penalized to zero
#DE = 44.7%, n = 95

anova(lb_gam_2020)
#DAY, TIDE, TEMP, and WAVE HEIGHT are significant in 2020, vis marginal

gam.check(lb_gam_2021)
#p-value < 0.05 for day but edf is not close to k'
visreg(lb_gam_2021)
#nothing odd with day seems to be going on

summary(lb_gam_2021)
#wave height penalized to zero
#DE = 41.8%, n = 120

anova(lb_gam_2021)
#VIS, HOUR, DAY and TIDE are significant in 2021
```

### Dropping significant terms from 2019 model
```{r}
visreg(lb_gam_2019)
summary(lb_gam_2019)
#full model DE is 83.1
#sig. terms are day and chl, hour and wvht are marginal

lb_gam_2019_no_day <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(sft, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2019_no_day)
83.1 - 75
#day DE = 8.1

lb_gam_2019_no_hour <- mgcv::gam(total_unique ~ 
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2019_no_hour)
83.1 - 78.8
#hour DE = 4.3

lb_gam_2019_no_wvht <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2019_no_wvht)
83.1 - 82
#wvht DE = 1.1

lb_gam_2019_no_chl <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10),
                       data = gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2019_no_chl)
83.1 - 68.1
#15%
```

### 2019 temporal + sft model, dropping terms
```{r}
temporal_gam_dat_2019 <- daily_3yr_dat %>%
  mutate(year = as.factor(as.character(year))) %>%
  filter(year == 2019) %>%
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(yday = yday(mdy)) %>% 
  filter(transect_area_km2 > 0.17)

lb_gam_2019_temporal_sft <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         s(sft, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2019_temporal_sft)
#DE = 62.4%, hour penalized to zero
anova(lb_gam_2019_temporal_sft)
#day and sft significant
gam.check(lb_gam_2019_temporal_sft)

lb_gam_2019_temporal <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2019_temporal)
62.4 - 54.1
#temp DE = 8.3%

lb_gam_2019_hour_sft <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(sft, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2019_hour_sft)
62.4 - 57.4
#day DE = 5.0%

lb_gam_2019_day_sft <- mgcv::gam(total_unique ~
                         s(yday, k = 10) +
                         s(sft, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2019_day_sft)
#hour DE = 0
```

### Dropping significant terms from 2020 model
```{r}
summary(lb_gam_2020)
#DE = 44.7%
#sig terms are day, sft, tide, and waveheight. Vis is marginal

lb_gam_2020_no_day <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp) +
                         offset(total_area),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2020_no_day)
44.7 - 21.4
#day DE = 23.3

lb_gam_2020_no_sft <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp) +
                         offset(total_area),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2020_no_sft)
44.7 - 44.2
#sft DE = 0.5%

lb_gam_2020_no_tide <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp) +
                         offset(total_area),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2020_no_tide)
44.7 - 41.4
#tide DE = 3.3

lb_gam_2020_no_wvht <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(chl_interp) +
                         offset(total_area),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2020_no_wvht)
44.7 - 36.4
#wvht DE = 8.3%

lb_gam_2020_no_vis <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp) +
                         offset(total_area),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_gam_2020_no_vis)
44.7 - 43.2
#vis DE = 1.5%
```

### Dropping significant terms from 2021 model
```{r}
summary(lb_gam_2021)
#full model DE = 41.8%
#significant terms are day, hour, tide, and vis

sft_2021_gam_no_day <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp) +
                                      offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(sft_2021_gam_no_day)
41.8 - 36.8
#day DE = 5

sft_2021_gam_no_hour <- mgcv::gam(total_unique ~ s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp) +
                                      offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(sft_2021_gam_no_hour)
41.8 - 29.7
#hour DE = 12.1

sft_2021_gam_no_tide <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp) +
                                      offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(sft_2021_gam_no_tide)
41.8 - 39.4
#tide DE = 2.4

sft_2021_gam_no_vis <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp) +
                                      offset(total_area),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(sft_2021_gam_no_vis)
41.8 - 37.6
#vis DE = 4.2
```

### Juvenile and Adult density models with CSULB sft data (all years)
```{r}
lb_juv_gam <- mgcv::gam(juvenile ~ year +
                                      s(hour, k = 10, by = year) +
                                      s(yday, k = 35, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 30) +
                                      s(sft, k = 30) +
                                      s(WVHT, k = 30) +
                                      s(salinity, k = 10) +
                                      s(chl_interp, k = 30) +
                                      offset(area_20m),
                       data = gam_dat_lb_tot_full, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_juv_gam)
#DE = 29.8%, n = 280

lb_adult_gam <- mgcv::gam(adult ~ year +
                                      s(hour, k = 10, by = year) +
                                      s(yday, k = 35, by = year) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 30) +
                                      s(sft, k = 30) +
                                      s(WVHT, k = 30) +
                                      s(salinity, k = 10) +
                                      s(chl_interp, k = 30) +
                                      offset(area_20m),
                       data = gam_dat_lb_tot_full, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_adult_gam)
#32.7% DE, n = 280

anova(lb_juv_gam)
#year and vis significant
#hour in 2021 significant
#day in 2019 and 2020 significant, marginal in 2021
#tide marginal
#sft significant!
#wvht, salinity, and chl all penalized to zero

anova(lb_adult_gam)
#year significant, vis and sea state not
#hour significant in 2019 only
#day significant in 2020 and 2021
#no envt'l or detection variables significant
```

### Juvenile and Adult density, 2019
```{r}
juv_gam_2019 <- mgcv::gam(juvenile ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
gam.check(juv_gam_2019)
#k-indices OK

summary(juv_gam_2019)
#DE = 74.8
#hour and tide penalized to zero
anova(juv_gam_2019)
#day and chl sig, sft marginal

adult_gam_2019 <- mgcv::gam(adult ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
gam.check(adult_gam_2019)
#k-index for day p < 0.05, but edf <<< k'
visreg(adult_gam_2019)
#looks fine

summary(adult_gam_2019)
#DE = 65.8
#tide, sft, wvht penalized to zero

anova(adult_gam_2019)
#hour and chl significant
```

### Dropping significant terms from 2019 juvenile model
```{r}
juv_gam_2019_no_hour <- mgcv::gam(juvenile ~ s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2019_no_hour)
#model is stable to removal of non-significant hour

juv_gam_2019_no_day <- mgcv::gam(juvenile ~ s(hour, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2019_no_day)
#marginal sft becomes sig. when day removed, otherwise stable
74.8 - 70.2
#day DE = 4.6

juv_gam_2019_no_chl <- mgcv::gam(juvenile ~ s(hour, k = 10) +
                                   s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(WVHT, k = 10) +
                         s(sft, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2019_no_chl)
#marginal sft becomes sig. when day removed, otherwise stable
74.8 - 64
#chl DE = 10.8

juv_gam_2019_no_sft <- mgcv::gam(juvenile ~ s(hour, k = 10) +
                                   s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2019_no_sft)
#stable to removal of marginal sft
74.8 - 71.9
#sft DE = 2.9
```

### Dropping significant terms from 2019 adult model
```{r}
summary(adult_gam_2019)
#full model DE = 65.8%
#sig. terms are hour and chl

adult_gam_2019_no_hour <- mgcv::gam(adult ~ s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10) +
                         s(chl_interp, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2019_no_hour)
#looks stable
65.8 - 50.9
#hour DE = 14.9

adult_gam_2019_no_chl <- mgcv::gam(adult ~ s(hour, k = 10) +
                         s(yday, k = 10) +
                         beaufort +
                         vis +
                         s(tide, k = 10) +
                         s(sft, k = 10) +
                         s(WVHT, k = 10),
                       data = gam_dat_2019,
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2019_no_chl)
65.8 - 61.6
#chl DE = 4.2
```

### Juvenile and Adult density, 2019 - temporal and sft-only models
```{r}
juv_gam_2019_sft_temporal <- mgcv::gam(juvenile ~  s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      s(sft, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)

adult_gam_2019_sft_temporal <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      s(sft, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)

gam.check(juv_gam_2019_sft_temporal)

summary(juv_gam_2019_sft_temporal)
#DE = 58.7%, n = 76
#hour penalized to zero

summary(adult_gam_2019_sft_temporal)
#DE = 46.9%, n = 76
#temp penalized to zero

anova(juv_gam_2019_sft_temporal)
#temp significant in 2019 for juveniles

anova(adult_gam_2019_sft_temporal)
#HOUR significant in 2019 for adults
```

### Dropping significant terms from 2019 Juvenile and Adult models (temporal and sft-only versions)
```{r}
#juvenile full DE = 58.7, only sig. term is temp

juv_gam_2019_no_temp <- mgcv::gam(juvenile ~  s(hour, k = 10) +
                                      s(yday, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2019_no_temp)
58.7 - 48.1
#temp DE = 10.6

juv_gam_2019_no_hour <- mgcv::gam(juvenile ~  s(sft, k = 10) +
                                      s(yday, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2019_no_hour)

juv_gam_2019_no_day <- mgcv::gam(juvenile ~  s(sft, k = 10) +
                                      s(hour, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2019_no_day)
#2019 juvenile model is stable

#adult full DE = 46.9%, only sig. term is hour

adult_gam_2019_no_hour <- mgcv::gam(adult ~ s(yday, k = 10) +
                                            s(sft, k = 10),
                       data = temporal_gam_dat_2019, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2019_no_hour)
```

### Juvenile and Adult density, 2020
```{r}
juv_gam_2020 <- mgcv::gam(juvenile ~  s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)

adult_gam_2020 <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
gam.check(juv_gam_2020)
summary(juv_gam_2020)
#DE = 23%, n = 95
#hour penalized to zero

gam.check(adult_gam_2020)
summary(adult_gam_2020)
#DE = 18.9%
#day, tide, and sft penalized to zero

anova(juv_gam_2020)
#DAY, TEMP, WVHT significant for juveniles in 2020 (tide marginal)

anova(adult_gam_2020)
#Wave height significant for adults in 2020
```

### Dropping significant terms from 2020 Juvenile model
```{r}
# full DE = 23%, day, temp, and wvht are significant

juv_gam_2020_no_day <- mgcv::gam(juvenile ~  s(hour, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2020_no_day)
#potentially instability - chl becomes penalized to zero and temp becomes insignificant
23 - 12.6
#day DE = 10.4

juv_gam_2020_no_sft <- mgcv::gam(juvenile ~  s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2020_no_sft)
#not stable, chl becomes penalized to zero when sft is removed

visreg(juv_gam_2020)
```

### Dropping significant term from 2020 adult model
```{r}
summary(adult_gam_2020)
#DE = 18.9

adult_gam_2020_no_wvht <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)

summary(adult_gam_2020_no_wvht)
#sensitive - day becomes significant when it was previously penalized to zero
```

### Reduced 2020 juv/adult models
```{r}
juv_gam_2020_reduced <- mgcv::gam(juvenile ~
                                      s(yday, k = 10) +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
gam.check(juv_gam_2020_reduced)
#low k-index for day, but increasing k to 50 did not increase k-index

summary(juv_gam_2020_reduced)
anova(juv_gam_2020_reduced)
#day significant, sft and wvht marginal

juv_2020_reduced_no_day <-mgcv::gam(juvenile ~
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(juv_2020_reduced_no_day)
#potential stability issue, sft no longer marginal

juv_2020_reduced_no_sft <-mgcv::gam(juvenile ~
                                      s(yday, k = 10) +
                                      s(tide, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(juv_2020_reduced_no_sft)
#not stable, DE higher than original model


adult_gam_2020_reduced <- mgcv::gam(adult ~
                                      s(yday, k = 10) +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
gam.check(adult_gam_2020_reduced)
#all good
summary(adult_gam_2020_reduced)
#DE = 15.5
anova(adult_gam_2020_reduced)
#wvht significant, day and tide penalized to zero

adult_gam_2020_reduced_no_wvht <- mgcv::gam(adult ~
                                      s(yday, k = 10) +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2020_reduced_no_wvht)
15.5 - 10.7
#wvht DE = 4.8

adult_gam_2020_reduced_no_day <- mgcv::gam(adult ~
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2020, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2020_reduced_no_day)
```

### Juvenile and Adult density, 2021
```{r}
juv_gam_2021 <- mgcv::gam(juvenile ~  s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)

adult_gam_2021 <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
gam.check(juv_gam_2021)
summary(juv_gam_2021)
#DE = 11.2%, n = 113
#temp and chl penalized to zero

summary(adult_gam_2021)
#DE = 22.4%, wvht and chl penalized to zero
gam.check(adult_gam_2021)
visreg(adult_gam_2021)

anova(juv_gam_2021)
#HOUR significant for juveniles in 2021

anova(adult_gam_2021)
#day, tide and sft significant for adults in 2021
```

### Dropping significant terms from 2021 juvenile model - stable
```{r}
#DE = 11.2, hour significant

juv_gam_2021_no_hour <- mgcv::gam(juvenile ~  s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(juv_gam_2021_no_hour)
11.2 - 6.8
#DE = 4.4
```

### Dropping significant terms from 2021 adult model - unstable
```{r}
# DE = 22.4%, sig. terms are day, tide and sft

adult_gam_2021_no_day <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2021_no_day)
22.4 - 19.6
#day DE = 2.8

adult_gam_2021_no_tide <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2021_no_tide)
22.4 - 18.4
#tide DE = 4%

adult_gam_2021_no_sft <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2021_no_sft)

summary(adult_gam_2021)
```

### Reduced 2021 adult model
```{r}
adult_gam_2021_reduced <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      vis +
                                      s(tide, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2021_reduced)
#DE = 25.7
gam.check(adult_gam_2021_reduced)
anova(adult_gam_2021_reduced)
#day and tide significant, hour marginal

adult_gam_2021_reduced_no_day <- mgcv::gam(adult ~ s(hour, k = 10)+
                                      vis +
                                      s(tide, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2021_reduced_no_day)
25.7 - 12.1
#day DE = 13.6

adult_gam_2021_reduced_no_hour <- mgcv::gam(adult ~ 
                                      s(yday, k = 10) +
                                      vis +
                                      s(tide, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2021_reduced_no_hour)
25.7 - 23.8
#hour DE = 1.9%

adult_gam_2021_reduced_no_tide <- mgcv::gam(adult ~   s(hour, k = 10) +
                                      s(yday, k = 10) +
                                      vis +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2021_reduced_no_tide)
25.7 - 20
#tide DE = 5.7
```

### 2021 adult model with month (factor) instead of day of year (smooth)
```{r}
gam_dat_2021_month <- gam_dat_2021 %>% 
  mutate(month = as_factor(month(mdy(date))))


adult_gam_2021_month <- mgcv::gam(adult ~ s(hour, k = 10) +
                                      month +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021_month, 
                       method = "REML", family = nb, select = TRUE)

summary(adult_gam_2021_month)
visreg(adult_gam_2021_month)
anova(adult_gam_2021_month)

gam_2021_month <- mgcv::gam(total_unique ~ s(hour, k = 10) +
                                      month +
                                      beaufort +
                                      vis +
                                      s(tide, k = 10) +
                                      s(sft, k = 10) +
                                      s(WVHT, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(total_area),
                       data = gam_dat_2021_month, 
                       method = "REML", family = nb, select = TRUE)
summary(adult_gam_2021_month)
visreg(adult_gam_2021_month)
```

### Quantatative discussion of effect directionality using visreg data
```{r}
summary(lb_gam_2019)
visreg_data_2019 <- visreg(lb_gam_2019)
View(visreg_data_2019)

###
summary(lb_gam_2019)
anova(lb_gam_2021)
visreg(lb_gam_2020)
###

###
names(coef(lb_gam_2020))
vis_contrast_2020 <- glht(lb_gam_2020, linfct = c("vismed = 0", "vishigh = 0", "vishigh - vismed = 0"))
summary(vis_contrast_2020)

vis_contrast_2021 <- glht(lb_gam_2021, linfct = c("vismed = 0", "vishigh = 0", "vishigh - vismed = 0"))
summary(vis_contrast_2021)
###

fits_2019 <- as.data.frame(visreg_data_2019[[8]][["fit"]][["visregFit"]])
chl_2019 <- as.data.frame(visreg_data_2019[[8]][["fit"]][["chl_interp"]])
chl_res_2019 <- as.data.frame(visreg_data_2019[[8]][["res"]][["visregRes"]])
res_chl_2019 <- as.data.frame(visreg_data_2019[[8]][["res"]][["chl_interp"]])

chl_fits_2019 <- bind_cols(fits_2019, chl_2019)
chl_res_2019 <- bind_cols(chl_res_2019, res_chl_2019)

chl_plot_dat_2019 <- full_join(chl_fits_2019, chl_res_2019, by = )
View(chl_fits_2019)

ggplot(chl_fits_2019, aes(x = visreg_data_2019[[8]][["fit"]][["chl_interp"]], y = visreg_data_2019[[8]][["fit"]][["visregFit"]])) +
  geom_point() +
  scale_x_continuous(breaks = seq(0, 120, by = 10))
#checks out (and will make for nicer plotting)

visreg_data_2020 <- visreg(lb_gam_2020)

fits_2020 <- as.data.frame(visreg_data_2020[[2]][["fit"]][["visregFit"]])
days_2020 <- as.data.frame(visreg_data_2020[[2]][["fit"]][["yday"]])

day_fits_2020 <- bind_cols(fits_2020, days_2020)
View(day_fits_2020)

ggplot(day_fits_2020, aes(x = visreg_data_2020[[2]][["fit"]][["yday"]], y = visreg_data_2020[[2]][["fit"]][["visregFit"]])) +
  geom_point() +
  scale_x_continuous(breaks = seq(100, 350, by = 20))

visreg_data_2021 <- visreg(lb_gam_2021)

fits_2021 <- as.data.frame(visreg_data_2021[[2]][["fit"]][["visregFit"]])
days_2021 <- as.data.frame(visreg_data_2021[[2]][["fit"]][["yday"]])

day_fits_2021 <- bind_cols(fits_2021, days_2021)
View(day_fits_2021)

ggplot(day_fits_2021, aes(x = visreg_data_2021[[2]][["fit"]][["yday"]], y = visreg_data_2021[[2]][["fit"]][["visregFit"]])) +
  geom_point() +
  scale_x_continuous(breaks = seq(70, 350, by = 20))

```

### Juvenile and adult density with 2021 SST
```{r}
lb_juv_gam_sst <- mgcv::gam(juvenile ~
                                      s(hour, k = 10) +
                                      s(yday, k = 20) +
                                      beaufort +
                                      vis +
                                      s(tide, k = 20) +
                                      s(sst, k = 25) +
                                      s(WVHT, k = 10) +
                                      s(salinity, k = 10) +
                                      s(chl_interp, k = 10) +
                                      offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_juv_gam_sst)
#DE = 13.2%, n = 108
visreg(lb_juv_gam_sst)

lb_adult_gam_sst <- mgcv::gam(adult ~
                                 s(hour, k = 10) +
                                 s(yday, k = 20) +
                                 vis +
                                 s(tide, k = 20) +
                                 s(sst, k = 25) +
                                 s(WVHT, k = 10) +
                                 s(salinity, k = 10) +
                                 s(chl_interp, k = 10) +
                                 offset(area_20m),
                       data = gam_dat_2021, 
                       method = "REML", family = nb, select = TRUE)
summary(lb_adult_gam_sst)
#DE = 26.1%, n = 108
visreg(lb_adult_gam_sst)
#hmm

gam.check(lb_adult_gam_sst)

ggplot(gam_dat_2021, aes(x = beaufort)) +
  geom_histogram(stat = "count")

ggplot(daily_3yr_dat, aes(x = as.numeric(beaufort), y = as.numeric(vis))) +
  geom_jitter()

anova(lb_juv_gam_sst)
#hour only significant variable, day marginal

anova(lb_adult_gam_sst)
#tide and sst significant
```

### determining deviance explained of each term by dropping it from the global TRANSECT model - CSULB VERSION - as of 6/16 
*note from Simon Wood: predictors aren't strictly orthogonal, so DE of each term might not sum to DE of global model
```{r}
summary(gam4lb)
# global model explains 59.6% of deviance

gam4lb_year <- mgcv::gam(transect_total ~ s(hour, k = 10, by = year) +
                                          s(month, k = 8, by = year) +
                                          beaufort +
                                          vis +
                                          s(tide, k = 10) +
                                          s(Temp_top, k = 10) +
                                          s(WVHT, k = 50) +
                                          offset(transect_area_km2),
                         data = gam_dat_lb, method = "REML", 
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(gam4lb_year)
59.6 - 47.3
#year DE = 12.3%

gam4lb_hour <- mgcv::gam(transect_total ~ year +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                         data = gam_dat_lb, method = "REML", 
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(gam4lb_hour)
59.6 - 49.3
#hour DE = 10.3%

gam4lb_month <- mgcv::gam(transect_total ~ year +
                                   s(hour, k = 10, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                          data = gam_dat_lb, method = "REML", 
                          family = nb, select = TRUE,
                          na.action = "na.fail")
summary(gam4lb_month)
59.6 - 41.7
#month DE = 17.9%

gam4lb_beau <- mgcv::gam(transect_total ~ year +
                                          s(hour, k = 10, by = year) +
                                          s(month, k = 8, by = year) +
                                          vis +
                                          s(tide, k = 10) +
                                          s(Temp_top, k = 10) +
                                          s(WVHT, k = 50) +
                                          offset(transect_area_km2),
                         data = gam_dat_lb, method = "REML",
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(gam4lb_beau)
59.6 - 52.7
#beaufort DE = 6.9%

gam4lb_vis <- mgcv::gam(transect_total ~ year +
                                         s(hour, k = 10, by = year) + 
                                         s(month, k = 8, by = year) +
                                         beaufort +
                                         s(tide, k = 10) +
                                         s(Temp_top, k = 10) +
                                         s(WVHT, k = 50) +
                                         offset(transect_area_km2),
                        data = gam_dat_lb, method = "REML",
                        family = nb, select = TRUE,
                        na.action = "na.fail")
summary(gam4lb_vis)
59.6 - 53.3
#vis DE = 6.3%

gam4lb_tide <- mgcv::gam(transect_total ~ year +
                                          s(hour, k = 10, by = year) +
                                          s(month, k = 8, by = year) +
                                          beaufort +
                                          vis +
                                          s(Temp_top, k = 10) +
                                          s(WVHT, k = 50) +
                                          offset(transect_area_km2),
                         data = gam_dat_lb, method = "REML",
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(gam4lb_tide)
59.6 - 55.9
#tide DE = 3.7%

gam4lb_temp <- mgcv::gam(transect_total ~ year +
                                       s(hour, k = 10, by = year) + 
                                       s(month, k = 8, by = year) +
                                       beaufort +
                                       vis+
                                       s(tide, k = 10) +
                                       s(WVHT, k = 50) +
                                       offset(transect_area_km2),
                         data = gam_dat_lb, method = "REML",
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(gam4lb_temp)
59.6 - 56.5
#temp DE = 3.1%

gam4lb_wvht <- mgcv::gam(transect_total ~ year +
                                          s(hour, k = 10, by = year)+
                                          s(month, k = 8, by = year) +
                                          beaufort +
                                          vis +
                                          s(tide, k = 10) +
                                          s(Temp_top, k = 10) +
                                          offset(transect_area_km2),
                         data = gam_dat_lb, method = "REML",
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(gam4lb_wvht)
59.6 - 56.1
#wvht DE = 3.5%
```

### determining deviance explained of each term by dropping it from the global TOTAL model - CSULB VERSION - as of 6/17
*note from Simon Wood: predictors aren't strictly orthogonal, so DE of each term might not sum to DE of global model
```{r}
summary(lbgam_tot)
# global model explains 51.2% of deviance

lbgam_tot_year <- mgcv::gam(total_unique ~ s(hour, k = 10, by = year) +
                                          s(month, k = 8, by = year) +
                                          beaufort +
                                          vis +
                                          s(tide, k = 10) +
                                          s(Temp_top, k = 10) +
                                          s(WVHT, k = 50) +
                                          offset(transect_area_km2),
                         data = gam_dat_lb_tot, method = "REML", 
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(lbgam_tot_year)
51.2 - 41.5
#year DE = 9.7%

lbgam_tot_hour <- mgcv::gam(total_unique ~ year +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                         data = gam_dat_lb_tot, method = "REML", 
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(lbgam_tot_hour)
51.2 - 47.4
#hour DE = 3.8%

lbgam_tot_month <- mgcv::gam(total_unique ~ year +
                                   s(hour, k = 10, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                          data = gam_dat_lb_tot, method = "REML", 
                          family = nb, select = TRUE,
                          na.action = "na.fail")
summary(lbgam_tot_month)
51.2 - 45.5
#month DE = 5.7%

lbgam_tot_beau <- mgcv::gam(total_unique ~ year +
                                          s(hour, k = 10, by = year) +
                                          s(month, k = 8, by = year) +
                                          vis +
                                          s(tide, k = 10) +
                                          s(Temp_top, k = 10) +
                                          s(WVHT, k = 50) +
                                          offset(transect_area_km2),
                         data = gam_dat_lb_tot, method = "REML",
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(lbgam_tot_beau)
51.2 - 52.2
#beaufort DE = -1%

lbgam_tot_vis <- mgcv::gam(total_unique ~ year +
                                         s(hour, k = 10, by = year) + 
                                         s(month, k = 8, by = year) +
                                         beaufort +
                                         s(tide, k = 10) +
                                         s(Temp_top, k = 10) +
                                         s(WVHT, k = 50) +
                                         offset(transect_area_km2),
                        data = gam_dat_lb_tot, method = "REML",
                        family = nb, select = TRUE,
                        na.action = "na.fail")
summary(lbgam_tot_vis)
51.2 - 49.4
#vis DE = 1.8%

lbgam_tot_tide <- mgcv::gam(total_unique ~ year +
                                          s(hour, k = 10, by = year) +
                                          s(month, k = 8, by = year) +
                                          beaufort +
                                          vis +
                                          s(Temp_top, k = 10) +
                                          s(WVHT, k = 50) +
                                          offset(transect_area_km2),
                         data = gam_dat_lb_tot, method = "REML",
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(lbgam_tot_tide)
51.2 - 54.2
#tide DE = -3%

lbgam_tot_temp <- mgcv::gam(total_unique ~ year +
                                       s(hour, k = 10, by = year) + 
                                       s(month, k = 8, by = year) +
                                       beaufort +
                                       vis+
                                       s(tide, k = 10) +
                                       s(WVHT, k = 50) +
                                       offset(transect_area_km2),
                         data = gam_dat_lb_tot, method = "REML",
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(lbgam_tot_temp)
51.2 - 54.4
#temp DE = -3.2%

lbgam_tot_wvht <- mgcv::gam(total_unique ~ year +
                                          s(hour, k = 10, by = year)+
                                          s(month, k = 8, by = year) +
                                          beaufort +
                                          vis +
                                          s(tide, k = 10) +
                                          s(Temp_top, k = 10) +
                                          offset(transect_area_km2),
                         data = gam_dat_lb_tot, method = "REML",
                         family = nb, select = TRUE,
                         na.action = "na.fail")
summary(lbgam_tot_wvht)
51.2 - 54.4
#wvht DE = 3.5%
```

### determining deviance explained of each term by dropping it from the global model LTER VERSION - as of 6/16
```{r}
summary(gam4)
# global model explains 55.6% of deviance

gam4year <- mgcv::gam(transect_total ~ s(hour, k = 10, by = year) +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                  data = gam_dat2, method = "REML", family = nb, select = TRUE, na.action = "na.fail")
summary(gam4year)
55.6 - 47.9
#year DE = 7.7%

gam4hour <- mgcv::gam(transect_total ~ year +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                  data = gam_dat2, method = "REML", family = nb, select = TRUE, na.action = "na.fail")
summary(gam4hour)
55.6 - 48.5
#hour DE = 7.1%

gam4month <- mgcv::gam(transect_total ~ year +
                                   s(hour, k = 10, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                  data = gam_dat2, method = "REML", family = nb, select = TRUE, na.action= "na.fail")
summary(gam4month)
55.6 - 38
#month DE = 17.6%

gam4beau <- mgcv::gam(transect_total ~ year +
                                   s(hour, k = 10, by = year) + 
                         s(month, k = 8, by = year) +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                  data = gam_dat2, method = "REML", family = nb, select = TRUE, na.action = "na.fail")
summary(gam4beau)
55.6 - 52.4
#beaufort DE = 3.2%

gam4vis <- mgcv::gam(transect_total ~ year +
                                      s(hour, k = 10, by = year) + 
                                      s(month, k = 8, by = year) +
                                      beaufort +
                                      s(tide, k = 10) +
                                      s(Temp_top, k = 10) +
                                      s(WVHT, k = 50) +
                                      offset(transect_area_km2),
                  data = gam_dat2, method = "REML", family = nb, select = TRUE, na.action = "na.fail")
summary(gam4vis)
55.6 - 53.4
#vis DE = 2.2

gam4tide <- mgcv::gam(transect_total ~ year +
                                   s(hour, k = 10, by = year) + 
                         s(month, k = 8, by = year) +
                                   beaufort +
                       vis+
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(transect_area_km2),
                  data = gam_dat2, method = "REML", family = nb, select = TRUE, na.actipon = "na.fail")
summary(gam4tide)
55.6 - 55.6
#tide DE = 0.0%

gam4temp <- mgcv::gam(transect_total ~ year +
                                       s(hour, k = 10, by = year) + 
                                       s(month, k = 8, by = year) +
                                       beaufort +
                                       vis+
                                       s(tide, k = 10) +
                                       s(WVHT, k = 50) +
                                       offset(transect_area_km2),
                  data = gam_dat2, method = "REML", family = nb, select = TRUE, na.action = "na.fail")
summary(gam4temp)
55.6 - 53.4
#temp DE = 2.2%

gam4wvht <- mgcv::gam(transect_total ~ year +
                                       s(hour, k = 10, by = year) + 
                                       s(month, k = 8, by = year) +
                                       beaufort +
                                       vis +
                                       s(tide, k = 10) +
                                       s(Temp_top, k = 10) +
                                       offset(transect_area_km2),
                  data = gam_dat2, method = "REML", family = nb, select = TRUE, na.action = "na.fail")
summary(gam4wvht)
55.6 - 54.3
#wvht DE = 1.3%
```

### Comparing gam4 models (local LTER vs regional)
```{r}
MuMIn::AICc(gam4, glob_gam, cabrillo3_gam4, scripps3_gam4, cabrillo_3, scripps_3)
#cabrillo+carp and just Cabrillo have lowest AIC

summary(gam4) #55.2% DE with just Carp temp - Cabrillo temp is definitely doing a lot of work
summary(cabrillo3_gam4) #64.3% DE with both Carp and Cabrillo temp
summary(cabrillo_3) #63.1% DE with just Cabrillo temp
```

### Global LTER GAM, but with total unique rather than transect count
```{r}
glob_gam_tot <- mgcv::gam(total_unique ~ year +
                                   s(month, k = 8, by = year) +
                                   s(hour, k = 10, by = year) +
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(cabrillo_temp_3wk, k = 12) +
                                   s(scripps_temp_3wk, k = 12) +
                                   s(WVHT, k = 50) +
                                   offset(total_area),
                  data = gam_dat2, method = "REML", family = nb)
summary(glob_gam_tot)
#64.5% DE, n = 202
summary(glob_gam)
#69% DE, n = 208

anova.gam(glob_gam_tot)
anova.gam(glob_gam)
#same terms are significant when transect or total count is used

visreg(glob_gam_tot)
```

## Modelling proportion of juveniles (probably want to do separate models instead)

### Build the dataset
```{r}
prop_dat <- daily_3yr_dat %>%
  filter(!is.na(juvenile)) %>% 
  filter(!is.na(total_sized)) %>%
  filter(total_sized > 0) %>% 
  filter(!is.na(year)) %>% 
  filter(!is.na(date_hour)) %>% 
  mutate(hour = as.numeric(hour(date_hour))) %>% 
  filter(!is.na(day)) %>% 
  filter(!is.na(beaufort)) %>% 
  mutate(beaufort = as.factor(beaufort)) %>% 
  filter(!is.na(vis)) %>% 
  mutate(vis = as.factor(vis)) %>% 
  filter(Temp_top < 9000) %>% 
  filter(!is.na(WVHT)) %>% 
  filter(!is.na(Temp_top)) %>% 
  filter(!is.na(tide))
```

### Examine relationships
```{r}
ggplot(prop_dat, aes(x = as.numeric(beaufort), y = juvenile/total_sized)) + 
  geom_point() +
  geom_smooth()

ggplot(prop_dat, aes(x = as.numeric(vis), y = juvenile/total_sized)) +
  geom_point() +
  geom_smooth()

ggplot(prop_dat, aes(x = Temp_top, y = juvenile/total_sized)) + 
  geom_jitter() +
  geom_smooth() + 
  facet_grid(year~.)
```

### Modelling proportion of juveniles
```{r}
propgam1 <- mgcv::gam(juvenile ~ year +
                                 s(hour, k = 10, by = year) +
                                 s(month, k = 8, by = year) + 
                                 beaufort +
                                 vis +
                                 s(tide, k = 10) +
                                 s(Temp_top, k = 10) +
                                 s(WVHT, k = 50) +
                                 offset(total_sized), data = prop_dat,
                                 method = "REML", family = nb,
                                 na.action = "na.fail", select = TRUE)

summary(propgam1)
# only 11.9 % of deviance explained. almost everything is being modelled as a flat line

gam.check(propgam1)
#all good

visreg(propgam1)

anova(propgam1)
#month in 2021 is significant, hour in 2021 is marginal (p = 0.555)

#propgam1_dredge_drop_1 <- dredge(propgam1, m.min = 8, fixed = "offset(total_sized)")
propgam1_dredge_drop_1

#propgam1_dredge_full <- dredge(propgam1, m.min = 3, fixed = "offset(total_sized)")
propgam1_dredge_full
```

### determining deviance explained of each term by dropping it from the global model
```{r}
summary(propgam1)
#global model explains 11.9% of deviance

propgam1year <- mgcv::gam(juvenile ~ s(hour, k = 10, by = year) +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(total_sized),
                  data = prop_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(propgam1year)
11.9 - 10.6
#year DE = 1.3%

propgam1hour <- mgcv::gam(juvenile ~ year +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(total_sized),
                  data = prop_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(propgam1hour)
11.9 - 8.36
#hour DE = 3.54% (not sure why it gave me an extra decimal place here)

propgam1month <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(total_sized),
                  data = prop_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(propgam1month)
11.9 - 8.62
#month DE = 3.28%

propgam1beau <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                         s(month, k = 8, by = year) +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(total_sized),
                  data = prop_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(propgam1beau)
11.9 - 12.1
#beaufort DE = -0.2 !?!?!?!

propgam1vis <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                         s(month, k = 8, by = year) +
                                   beaufort +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(total_sized),
                  data = prop_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(propgam1vis)
11.9 - 11.8
#vis DE = 0.1%

propgam1tide <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                         s(month, k = 8, by = year) +
                                   beaufort +
                       vis+
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(total_sized),
                  data = prop_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(propgam1tide)
11.9 - 10.9
#tide DE = 1.0%

propgam1temp <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                         s(month, k = 8, by = year) +
                                   beaufort +
                       vis+
                                   s(tide, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(total_sized),
                  data = prop_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(propgam1temp)
11.9 - 11.9
#temp DE = 0%

propgam1wvht <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                         s(month, k = 8, by = year) +
                                   beaufort +
                       vis+
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   offset(total_sized),
                  data = prop_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(propgam1wvht)
11.9 - 11.9
#wvht DE = 0%
```

## Modelling density of juveniles

### Building the dataset
```{r}
juv_dat <- daily_3yr_dat %>%
  filter(!is.na(area_20m)) %>% 
  filter(!is.na(juvenile)) %>% 
  filter(!is.na(year)) %>% 
  filter(!is.na(date_hour)) %>% 
  mutate(hour = as.numeric(hour(date_hour))) %>% 
  filter(!is.na(day)) %>% 
  filter(!is.na(beaufort)) %>% 
  mutate(beaufort = as.factor(beaufort)) %>% 
  filter(!is.na(vis)) %>% 
  mutate(vis = as.factor(vis)) %>% 
  filter(Temp_top < 9000) %>% 
  filter(!is.na(WVHT)) %>% 
  filter(!is.na(Temp_top)) %>% 
  filter(!is.na(tide))

juv_dat_all <- daily_3yr_dat %>% 
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(month = as.factor(month)) %>% 
  mutate(beaufort = as.factor(beaufort)) %>% 
  mutate(vis = as.factor(vis)) %>% 
  filter(Temp_top < 9000)

juv_datlb <- daily_3yr_dat %>%
  mutate(year = as.factor(as.character(year))) %>%
  mutate(month = month(mdy)) %>%
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(vis = as.factor(vis)) %>%
  mutate(beaufort = as.factor(beaufort)) %>%
  filter(!is.na(area_20m)) %>% 
  filter(!is.na(juvenile)) %>% 
  filter(!is.na(year)) %>% 
  filter(!is.na(date_hour)) %>% 
  filter(!is.na(day)) %>% 
  filter(!is.na(beaufort)) %>% 
  filter(!is.na(vis)) %>% 
  filter(!is.na(WVHT)) %>% 
  filter(!is.na(sft)) %>% 
  filter(!is.na(tide))
```

### Examine relationships
```{r}
ggplot(juv_dat, aes(x = as.numeric(beaufort), y = juvenile)) + 
  geom_point() +
  geom_smooth()

ggplot(juv_dat, aes(x = as.numeric(vis), y = juvenile)) +
  geom_point() +
  geom_smooth()

ggplot(juv_dat, aes(x = Temp_top, y = juvenile)) + 
  geom_jitter() +
  geom_smooth() + 
  facet_grid(year~.)
```

### Modelling density of juveniles - LTER DATA
```{r}
juvgam1 <- mgcv::gam(juvenile ~ year +
                                s(hour, k = 10, by = year) +
                                s(month, k = 8, by = year) + 
                                beaufort +
                                vis +
                                s(tide, k = 10) +
                                s(Temp_top, k = 10) +
                                s(WVHT, k = 50) +
                                offset(area_20m), data = juv_dat,
                                method = "REML", family = nb, select = TRUE, na.action = "na.fail")

summary(juvgam1)
# 27.5% of deviance explained, n = 254

gam.check(juvgam1)
#issues with month

visreg(juvgam1)

anova(juvgam1)
#year, month in 2019 and 2021 are significant, temperature p = 0.068

juvgam1_dredge_drop_1 <- dredge(juvgam1, m.min = 8, fixed = "offset(area_20m)")
juvgam1_dredge_drop_1
# no vis and no beaufort are best two

#juvgam1_dredge_full <- dredge(juvgam1, m.min = 3, fixed = "offset(area_20m)")
juvgam1_dredge_full

juv_year_emms <- emmeans(juvgam1, "year")
pwpm(juv_year_emms, type = "response")
#2020 and 2021 significantly higher than 2019
```

### determining deviance explained of each term by dropping it from the global model - LTER DATA
```{r}
summary(juvgam1)
#global model explains 27.5% of deviance

juvgam1year <- mgcv::gam(juvenile ~ s(hour, k = 10, by = year) +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam1year)
27.5 - 20.7
#year DE = 6.8%

juvgam1hour <- mgcv::gam(juvenile ~ year +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam1hour)
27.5 - 25.6
#hour DE = 1.9%

juvgam1month <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam1month)
27.5 - 19.4
#month DE = 8.1

juvgam1beau <- mgcv::gam(juvenile ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    vis +
                                    s(tide, k = 10) +
                                    s(Temp_top, k = 10) +
                                    s(WVHT, k = 50) +
                                    offset(area_20m),
                  data = juv_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam1beau)
27.5 - 26.1
#beaufort DE = 1.4

juvgam1vis <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                                   s(month, k = 8, by = year) +
                                   beaufort +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam1vis)
27.5 - 25.5
#vis DE = 2.0%

juvgam1tide <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                                   s(month, k = 8, by = year) +
                                   beaufort +
                                   vis +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam1tide)
27.5 - 27.5
#tide DE = 0%

juvgam1temp <- mgcv::gam(juvenile ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    beaufort +
                                    vis +
                                    s(tide, k = 10) +
                                    s(WVHT, k = 50) +
                                    offset(area_20m),
                  data = juv_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam1temp)
27.5 - 25.7
#temp DE = 1.8%

juvgam1wvht <- mgcv::gam(juvenile ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    beaufort +
                                    vis +
                                    s(tide, k = 10) +
                                    s(Temp_top, k = 10) +
                                    offset(area_20m),
                  data = juv_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam1wvht)
27.5 - 27.5
#wvht DE = 0%
```

### Modelling density of juveniles - CSULB DATA
```{r}
juvgam_lb <- mgcv::gam(juvenile ~ year +
                                s(hour, k = 10, by = year) +
                                s(month, k = 8, by = year) + 
                                beaufort +
                                vis +
                                s(tide, k = 10) +
                                s(sft, k = 10) +
                                s(WVHT, k = 50) +
                         offset(area_20m), data = juv_datlb,
                                method = "REML", family = nb,
                       select = TRUE, na.action = "na.fail")

summary(juvgam_lb)
# 27.3% of deviance explained, n = 248

gam.check(juvgam_lb)
#issues with month, not sure if one order of magnitude counts as "edf much lower than k"

visreg(juvgam_lb)

anova(juvgam_lb)
#year, month in 2019 and 2021 are significant

juvgamlb_dredge_drop_1 <- dredge(juvgamlb, m.min = 8, fixed = "offset(area_20m)")
juvgamlb_dredge_drop_1
# no vis and no beaufort are best two

#juvgamlb_dredge_full <- dredge(juvgam_lb, m.min = 3, fixed = "offset(area_20m)")
juvgamlb_dredge_full

#post-hoc test of significant parametric terms:
juvlb_year_emms <- emmeans(juvgam_lb, "year")
pwpm(juvlb_year_emms, type = "response")
#2020 and 2021 significantly higher than 2019
```

### determining deviance explained of each term by dropping it from the global model - CSULB DATA
```{r}
summary(juvgam_lb)
#global model explains 27.3% of deviance

juvgam_lb_year <- mgcv::gam(juvenile ~ s(hour, k = 10, by = year) +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_datlb, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam_lb_year)
27.3 - 21.1
#year DE = 6.2%

juvgam_lb_hour <- mgcv::gam(juvenile ~ year +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_datlb, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam_lb_hour)
27.3 - 25.9
#hour DE = 3.0%

juvgam_lb_month <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_datlb, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam_lb_month)
27.3 - 19.3
#month DE = 8.0

juvgam_lb_beau <- mgcv::gam(juvenile ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    vis +
                                    s(tide, k = 10) +
                                    s(sft, k = 10) +
                                    s(WVHT, k = 50) +
                                    offset(area_20m),
                  data = juv_datlb, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam_lb_beau)
27.5 - 26.2
#beaufort DE = 1.3%

juvgam_lb_vis <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                                   s(month, k = 8, by = year) +
                                   beaufort +
                                   s(tide, k = 10) +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_datlb, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam_lb_vis)
27.3 - 24.6
#vis DE = 2.7%

juvgam_lb_tide <- mgcv::gam(juvenile ~ year +
                                   s(hour, k = 10, by = year) + 
                                   s(month, k = 8, by = year) +
                                   beaufort +
                                   vis +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = juv_datlb, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam_lb_tide)
27.3 - 27.3
#tide DE = 0%

juvgam_lb_temp <- mgcv::gam(juvenile ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    beaufort +
                                    vis +
                                    s(tide, k = 10) +
                                    s(WVHT, k = 50) +
                                    offset(area_20m),
                  data = juv_datlb, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam_lb_temp)
27.3 - 26.7
#temp DE = 0.6%

juvgam_lb_wvht <- mgcv::gam(juvenile ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    beaufort +
                                    vis +
                                    s(tide, k = 10) +
                                    s(sft, k = 10) +
                                    offset(area_20m),
                  data = juv_datlb, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(juvgam_lb_wvht)
27.3 - 27.3
#wvht DE = 0%
```

## Modelling density of adults

### Building the dataset
```{r}
ad_dat <- daily_3yr_dat %>%
  filter(!is.na(area_20m)) %>% 
  filter(!is.na(adult)) %>% 
  filter(!is.na(year)) %>% 
  filter(!is.na(date_hour)) %>% 
  mutate(hour = as.numeric(hour(date_hour))) %>% 
  filter(!is.na(day)) %>% 
  filter(!is.na(beaufort)) %>% 
  mutate(beaufort = as.factor(beaufort)) %>% 
  filter(!is.na(vis)) %>% 
  mutate(vis = as.factor(vis)) %>% 
  filter(Temp_top < 9000) %>% 
  filter(!is.na(WVHT)) %>% 
  filter(!is.na(Temp_top)) %>% 
  filter(!is.na(tide))

ad_datlb <- daily_3yr_dat %>%
  mutate(year = as.factor(as.character(year))) %>%
  mutate(month = month(mdy)) %>%
  mutate(hour = as.numeric(hour(date_hour))) %>%
  mutate(vis = as.factor(vis)) %>%
  mutate(beaufort = as.factor(beaufort)) %>%
  filter(!is.na(area_20m)) %>% 
  filter(!is.na(adult)) %>% 
  filter(!is.na(year)) %>% 
  filter(!is.na(date_hour)) %>% 
  filter(!is.na(day)) %>% 
  filter(!is.na(beaufort)) %>% 
  filter(!is.na(vis)) %>% 
  filter(!is.na(WVHT)) %>% 
  filter(!is.na(sft)) %>% 
  filter(!is.na(tide))
```

### Modelling density of adults - CSULB DATA
```{r}
adgam_lb <- mgcv::gam(adult ~ year +
                                s(hour, k = 10, by = year) +
                                s(month, k = 8, by = year) + 
                                beaufort +
                                vis +
                                s(tide, k = 10) +
                                s(sft, k = 10) +
                                s(WVHT, k = 50) +
                                offset(area_20m), data = ad_datlb,
                      method = "REML", family = nb,
                      select = TRUE, na.action = "na.fail")

summary(adgam_lb)
# 37% of deviance explained, n = 248

gam.check(adgam_lb)
#issues with month, not sure if 7 vs 0 counts as "edf much lower than k"

visreg(adgam_lb)

anova(adgam_lb)
#year, hour (in 2019 and 2021), month (0.0556 in 2019 and p < 0.05 in 2021), and tide are significant

#adgamlb_dredge_drop_1 <- dredge(adgam_lb, m.min = 8, fixed = "offset(area_20m)")
adgamlb_dredge_drop_1
#dropping beaufort and vis improve fit over global model, dropping temp is equal to global

#adgamlb_dredge_full <- dredge(adgam_lb, m.min = 3, fixed = "offset(area_20m)")
adgamlb_dredge_full

#post-hoc test of significant parametric terms:
adlb_year_emms <- emmeans(adgam_lb, "year")
pwpm(adlb_year_emms, type = "response")
#2020 and 2021 significantly higher than 2019
```

### Determining DE by dropping each term from the adult model - CSULB DATA
```{r}
summary(adgam_lb)
#global model explains 37% of deviance

adgam_lb_year <- mgcv::gam(adult ~ s(hour, k = 10, by = year) +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                           data = ad_datlb, method = "REML",
                           family = nb, na.action = "na.fail", select = TRUE)
summary(adgam_lb_year)
37 - 29
#year DE = 8.0%

adgam_lb_hour <- mgcv::gam(adult ~ year +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                           data = ad_datlb, method = "REML",
                           family = nb, na.action = "na.fail", select = TRUE)
summary(adgam_lb_hour)
37 - 32.9
#hour DE = 4.1%

adgam_lb_month <- mgcv::gam(adult ~ year +
                                   s(hour, k = 10, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                            data = ad_datlb, method = "REML", family = nb,
                            na.action = "na.fail", select = TRUE)
summary(adgam_lb_month)
37 - 29.6
#month DE = 7.4

adgam_lb_beau <- mgcv::gam(adult ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    vis +
                                    s(tide, k = 10) +
                                    s(sft, k = 10) +
                                    s(WVHT, k = 50) +
                                    offset(area_20m),
                           data = ad_datlb, method = "REML",
                           family = nb, na.action = "na.fail", select = TRUE)
summary(adgam_lb_beau)
37 - 36.2
#beaufort DE = 0.8%

adgam_lb_vis <- mgcv::gam(adult ~ year +
                                   s(hour, k = 10, by = year) + 
                                   s(month, k = 8, by = year) +
                                   beaufort +
                                   s(tide, k = 10) +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                          data = ad_datlb, method = "REML",
                          family = nb, na.action = "na.fail", select = TRUE)
summary(adgam_lb_vis)
37 - 35.7
#vis DE = 2.7%

adgam_lb_tide <- mgcv::gam(adult ~ year +
                                   s(hour, k = 10, by = year) + 
                                   s(month, k = 8, by = year) +
                                   beaufort +
                                   vis +
                                   s(sft, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                           data = ad_datlb, method = "REML", family = nb,
                           na.action = "na.fail", select = TRUE)
summary(adgam_lb_tide)
37 - 31.6
#tide DE = 5.4%

adgam_lb_temp <- mgcv::gam(adult ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    beaufort +
                                    vis +
                                    s(tide, k = 10) +
                                    s(WVHT, k = 50) +
                                    offset(area_20m),
                           data = ad_datlb, method = "REML",
                           family = nb, na.action = "na.fail", select = TRUE)
summary(adgam_lb_temp)
37 - 37
#temp DE = 0%

adgam_lb_wvht <- mgcv::gam(adult ~ year +
                                    s(hour, k = 10, by = year) + 
                                    s(month, k = 8, by = year) +
                                    beaufort +
                                    vis +
                                    s(tide, k = 10) +
                                    s(sft, k = 10) +
                                    offset(area_20m),
                           data = ad_datlb, method = "REML",
                           family = nb, na.action = "na.fail", select = TRUE)
summary(adgam_lb_wvht)
37 - 37
#wvht DE = 0%
```

### Modelling density of adults - LTER DATA
```{r}
adgam1 <- mgcv::gam(adult ~ year +
                                 s(hour, k = 10, by = year) +
                                 s(month, k = 8, by = year) + 
                                 beaufort +
                                 vis +
                                 s(tide, k = 10) +
                                 s(Temp_top, k = 10) +
                                 s(WVHT, k = 50) +
                                 offset(area_20m), data = ad_dat,
                                 method = "REML", family = nb,
                                 na.action = "na.fail", select = TRUE)

summary(adgam1)
#38% DE, n = 254

gam.check(adgam1)

visreg(adgam1)

anova(adgam1)
#year, hour (2019 & 2021), month (2019 & 2021), and tide significant

#adgam1_dredge_drop_1 <- dredge(adgam1, m.min = 8, fixed = "offset(area_20m)")
adgam1_dredge_drop_1
#no beaufort and no vis are best (same as juvenile model)

#adgam1_dredge_full <- dredge(adgam1, m.min = 3, fixed = "offset(total_sized)")
adgam1_dredge_full
```

### determining deviance explained of each term by dropping it from the global model
```{r}
summary(adgam1)
#global model explains 38% of deviance

adgam1year <- mgcv::gam(adult ~ s(hour, k = 10, by = year) +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = ad_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(adgam1year)
38 - 29.8
#year DE = 8.2%

adgam1hour <- mgcv::gam(adult ~ year +
                                   s(month, k = 8, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = ad_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(adgam1hour)
38 - 33.8
#hour DE = 4.2

adgam1month <- mgcv::gam(adult ~ year +
                                   s(hour, k = 10, by = year) + 
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = ad_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(adgam1month)
38 - 32
#month DE = 6%

adgam1beau <- mgcv::gam(adult ~ year +
                                s(hour, k = 10, by = year) + 
                                s(month, k = 8, by = year) +
                                vis +
                                s(tide, k = 10) +
                                s(Temp_top, k = 10) +
                                s(WVHT, k = 50) +
                                offset(area_20m),
                  data = ad_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(adgam1beau)
38 - 37.5
#beaufort DE = 0.5

adgam1vis <- mgcv::gam(adult ~ year +
                                   s(hour, k = 10, by = year) + 
                         s(month, k = 8, by = year) +
                                   beaufort +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = ad_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(adgam1vis)
38 - 37.5
#vis DE = 0.5

adgam1tide <- mgcv::gam(adult ~ year +
                                   s(hour, k = 10, by = year) + 
                                   s(month, k = 8, by = year) +
                                   beaufort +
                                   vis +
                                   s(Temp_top, k = 10) +
                                   s(WVHT, k = 50) +
                                   offset(area_20m),
                  data = ad_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(adgam1tide)
38 - 30.3
#tide DE = 7.7%

adgam1temp <- mgcv::gam(adult ~ year +
                                s(hour, k = 10, by = year) + 
                                s(month, k = 8, by = year) +
                                beaufort +
                                vis+
                                s(tide, k = 10) +
                                s(WVHT, k = 50) +
                                offset(area_20m),
                              data = ad_dat, method = "REML", family = nb,
                              na.action = "na.fail", select = TRUE)
summary(adgam1temp)
38 - 38.3
#temp DE = -0.3

adgam1wvht <- mgcv::gam(adult ~ year +
                                   s(hour, k = 10, by = year) + 
                                   s(month, k = 8, by = year) +
                                   beaufort +
                                   vis +
                                   s(tide, k = 10) +
                                   s(Temp_top, k = 10) +
                                   offset(area_20m),
                  data = ad_dat, method = "REML", family = nb, na.action = "na.fail", select = TRUE)
summary(adgam1wvht)
38 - 38.3
#wvht DE = -0.3%
```

===============================================================================

# Exploratory Visualizations
* Older individual year visualizations are below 3yr visualizations

## Temp vs density by year
```{r}
ggplot(daily_3yr_dat, aes(x = sft, y = (total_unique/total_area))) +
  geom_smooth(aes(color = as_factor(year)), se = F)

ggplot(daily_3yr_dat, aes(x = sft, y = log1p(total_unique/total_area))) +
  geom_point(aes(color = as_factor(year))) +
  geom_smooth(aes(color = as_factor(year)), se = F)
```

## Time of day
```{r}
#scatterplot
ggplot(gam_dat_lb_tot_full, aes(x = hour, y = total_unique/total_area)) +
  geom_point() +
  scale_color_brewer(palette = "Dark2") +
  labs(x = "Hour of Day", y = "Density", color = "Year") +
  theme_cowplot() +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA)) +
  geom_smooth(method = "lm")

#scatterplot by year
ggplot(gam_dat_lb_tot_full, aes(x = hour, y = total_unique/total_area, color = year)) +
  geom_point() +
  scale_color_brewer(palette = "Dark2") +
  labs(x = "Hour of Day", y = "Density", color = "Year") +
  theme_cowplot() +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))

#barplot
gam_dat_lb_tot_full %>% 
  group_by(hour, year) %>% 
  summarize(mean_se = mean_se(total_unique/total_area)) %>% 
  unnest(mean_se) %>% 
  ggplot(aes(x = as_factor(hour), y = y)) +
    geom_bar(stat = "identity") +
    labs(x = "Hour of Day", y = "Density") +
    theme_cowplot() +
    theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))

#barplot, by year (averaged by day)
gam_dat_lb_tot_full %>% 
  group_by(hour, year) %>% 
  summarize(mean_se = mean_se(total_unique/total_area)) %>% 
  unnest(mean_se) %>%
  ungroup() %>% 
  add_row(hour = 18, y = 0, year = "2019") %>% 
  filter(!is.na(hour)) %>%
  ggplot(aes(x = as_factor(hour), fill = year)) +
    geom_bar(aes(y = y), position = "dodge", stat = "identity") +
    #geom_errorbar(aes(ymax = ymax, ymin = ymin), position = "dodge") +
    scale_fill_brewer(palette = "Dark2") +
    labs(x = "Hour of Day", y = bquote("Density (sharks/"~km^2~")"), fill = "Year") +
    theme_cowplot() +
    theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA),
      legend.position = c(0.25, 0.7))
ggsave("plots/hour_barplot.png", height = 5, width = 5)
```

### vis vs time of day, chlA
```{r}
gam_dat_lb_tot_full %>% 
  group_by(hour) %>% 
  summarize(mean_vis = mean(as.numeric(vis), na.rm = TRUE)) %>% 
  ggplot(aes(x = hour, y = mean_vis)) +
    geom_point() +
    geom_smooth(method = "lm")

ggplot(gam_dat_lb_tot_full, aes(x = hour, y = as.numeric(vis))) +
    geom_jitter() +
    geom_smooth()

ggplot(gam_dat_2021, aes(y = chl_interp, x = vis)) +
    geom_bar(stat = "summary", fun = "mean") +
    geom_jitter()

kruskal.test(chl_interp ~ vis, data = daily_3yr_dat)
#no association btwn vis and chl

kruskal.test(hour ~ vis, data = gam_dat_lb_tot_full)
#no association btwn vis and hour

vis_hour_table <- table(gam_dat_lb_tot_full$hour, gam_dat_lb_tot_full$vis)
vis_hour_table
chisq.test(vis_hour_table)
```

### Chl-A
```{r}
gam_dat_2019 %>% 
  ggplot(aes(x = log(chl_interp), y = total_unique)) +
    geom_jitter() +
    geom_smooth()

chl_fits_2019 %>% 
  rename(density = 1, chl = 2) %>% 
  ggplot(aes(x = chl)) +
    geom_point()
    geom_line(aes(y = density), color = "red")

v19 <- visreg(lb_gam_2019, "chl_interp")
View(v19)

visreg(lb_gam_2021, "vis")

daily_3yr_dat %>% 
  ggplot(aes(x = as_factor(year), y = WVHT)) +
    geom_boxplot()

ggplot(v19$fit, aes(x = chl_interp)) +
  geom_line(aes(y = visregFit), color = "blue", size = 1, alpha = 0.5) +
  geom_point(data = v19$res, aes(y = visregRes)) +
  theme_cowplot() +
  labs(x = bquote("Chlorophyll-A (mg/"~m^3~")"), y = "Relative Density") +
  theme(panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA))
ggsave("plots/2019_chl_fit.png", width = 5, height = 4)
```

## 3yr abundance visualizations

Summary table
```{r}
yearly_abund_summary <- daily_3yr_dat %>% 
  group_by(year(date)) %>% 
  summarize("Total sightings" = sum(total_unique, na.rm = TRUE),
            "Survey days" = n(),
            "Sightings per day" = sum(total_unique, na.rm = TRUE)/n(),
            "Maximum abundance" = max(total_unique, na.rm = TRUE)) %>% 
  gt() %>% 
    fmt_number(columns = 4, decimals = 2) %>% 
    cols_label("year(date)" = "Year") %>% 
    cols_width("Total sightings" ~ px(80),
               "Maximum abundance" ~ px(80),
               "Sightings per day" ~ px(80)) %>% 
    cols_align(align = "center")
gtsave(yearly_abund_summary, "plots/yearly_abund_summary.png")
```

Years stacked (pretty ugly):
```{r}
daily_3yr_dat %>% 
  group_by(year(date), week(date)) %>% 
  summarize(mean = mean(total_unique, na.rm = TRUE)) %>%
  rename(week = "week(date)", year = "year(date)") %>% 
  ungroup() %>% 
  ggplot(aes(x = as.Date(paste(week, 1, sep="-"), "%U-%u"), y = mean, fill = as_factor(year))) +
    geom_bar(stat = "identity", position = "stack") +
    scale_fill_brewer("Year", palette = "Set1") +
    theme_clean() +
    expand_limits(y = 0) +
    scale_x_date("Date", date_labels = "%B", breaks = "1 month") +
    scale_y_continuous("Abundance", expand = c(0,0))
ggsave("plots/3yr_abund_stacked.png", width = 8, height = 5)
```

Years faceted (good option, potentially as a second graph after years averaged?):
```{r}
daily_3yr_dat %>% 
  group_by(year(date), week(date)) %>% 
  summarize(mean = mean(total_unique, na.rm = TRUE)) %>%
  rename(week = "week(date)", year = "year(date)") %>% 
  ungroup() %>% 
  ggplot(aes(x = as.Date(paste(week, 1, sep="-"), "%U-%u"), y = mean, fill = as_factor(year))) +
    geom_bar(stat = "identity") +
    facet_grid(as_factor(year)~.) +
    scale_fill_brewer("Year", palette = "Set1") +
    theme_clean() +
    theme(strip.background = element_blank(),
          strip.text.y = element_blank(),
          panel.spacing.y = unit(1, "lines"),
          panel.background = element_blank(),
          plot.background = element_blank(),
          legend.background = element_rect(fill = 'transparent'),
          panel.border = element_blank()) +
    expand_limits(y = 0) +
    scale_x_date("Date", date_labels = "%B", breaks = "1 month") +
    scale_y_continuous("Abundance", expand = c(0,0))
ggsave("plots/3yr_abund_yrs_facet.png", width = 8, height = 5)
```

Years averaged:
```{r}
daily_3yr_dat %>% 
  group_by(week(date)) %>% 
  summarize(mean = mean(total_unique, na.rm = TRUE)) %>%
  rename(week = "week(date)") %>%
  ungroup() %>% 
  ggplot(aes(x = as.Date(paste(week, 1, sep="-"), "%U-%u"), y = mean)) +
    geom_bar(stat = "identity") +
    scale_x_date(date_labels = "%B", breaks = "1 month") +
    labs(x = "Date", y = "Abundance") +
    theme_clean()
```

Rolling abundance:
WHAT LENGTH WINDOW DO I WANT?
```{r}
daily_3yr_dat %>%
  group_by(yday(date)) %>% 
  summarize(mean = mean(total_unique, na.rm = TRUE)) %>%
  rename(day = "yday(date)") %>%
  ungroup() %>%
  filter(!is.na(mean)) %>% 
  ggplot(aes(x = as_date(day), y = rollmean(mean, 10, na.pad = TRUE, align = "right"))) +
    geom_line(size = 1) +
    theme_clean() +
    expand_limits(y = 0) +
    scale_y_continuous("Abundance", expand = c(0, 0)) +
    scale_x_date("Date", date_labels = "%B", breaks = "1 month")
ggsave("plots/3yr_rolling_abund_10day.png", width = 9, height = 5)
```

Rolling abundance, only including days within survey window for all three years:
```{r}
#find latest start and earliest stop dates:
daily_3yr_dat %>% 
  group_by(year(date)) %>% 
  summarize(min_day = min(yday(date)),
            max_day = max(yday(date)))
#2019 is latest start date (day 150) and 2021 is earliest stop date (day 312)

daily_3yr_dat %>%
  filter(yday(date) > 149 & yday(date) < 313) %>% 
  group_by(yday(date)) %>% 
  summarize(mean = mean(total_unique, na.rm = TRUE)) %>%
  rename(day = "yday(date)") %>%
  ungroup() %>%
  filter(!is.na(mean)) %>% 
  ggplot(aes(x = as_date(day), y = rollmean(mean, 7, na.pad = TRUE, align = "right"))) +
    geom_line(size = 1) +
    theme_clean() +
    expand_limits(y = 0) +
    scale_y_continuous("Abundance", expand = c(0, 0), limits = c(0,6)) +
    scale_x_date("Date", date_labels = "%B", breaks = "1 month",
                 limits = c(as_date(155), as_date(315)))
    
ggsave("plots/3yr_rolling_abund_bounded_7day.png", width = 9, height = 3)
```

## 3yr environmental variable visualizations
```{r}
daily_3yr_dat %>% 
  gather("data", "value", WDIR:WTMP) %>% 
  ggplot(aes(x = value)) +
    geom_histogram() +
    facet_wrap(~data, scales = "free")

daily_3yr_dat %>%
 ggplot(aes(x = wharf_temp, y = WTMP)) +
  geom_point()

wharf_channel_temp_mod <- lm(WTMP ~ wharf_temp, data = daily_3yr_dat)
summary(wharf_channel_temp_mod)
# r2 = 0.43, p < 0.001

daily_3yr_dat %>%
 ggplot(aes(x = ((9/5)*(wharf_temp) + 32), y = water_temp_padaro)) +
  geom_point() +
  geom_smooth(method = "lm") +
  coord_cartesian(xlim = c(58, 70))

wharf_padaro_temp_mod <- lm(((9/5)*(wharf_temp) + 32) ~ water_temp_padaro, data = daily_3yr_dat)
summary(wharf_padaro_temp_mod)
#r2 = 0.69, p < 0.001
```

# Correlations of Abundance with Environmental Variables

### Vis and Beaufort
```{r}
daily_3yr_dat %>% 
  ggplot(aes(x = as.factor(vis), y = total_unique)) +
    geom_boxplot()

daily_3yr_dat %>% 
  ggplot(aes(x = as.factor(beaufort), y = total_unique)) +
    geom_boxplot()

daily_3yr_dat %>% 
  ggplot(aes(x = as_factor(year), y = vis)) +
    geom_boxplot()

daily_3yr_dat %>% 
  group_by(as_factor(year)) %>% 
  summarize(mean = mean(vis, na.rm = TRUE))

daily_3yr_dat %>% 
  ggplot(aes(x = yday(mdy), y = vis, color = as_factor(year))) +
    geom_point() +
    geom_smooth(se = FALSE, aes(color = as_factor(year)))
```

### Channel Water Temp
```{r}
dat_no_19 %>% 
  ggplot(aes(x = WTMP)) +
    geom_histogram(binwidth = 0.5)

dat_no_19 %>% 
  filter(total_unique != 0) %>% 
  ggplot(aes(x = WTMP, y = total_unique)) +
    geom_point()

temp_mod <- lm(log1p(total_unique) ~ WTMP, data = (daily_3yr_dat %>% filter(total_unique != 0)))
summary(temp_mod)
# no linear relationship between channel water temp and total unique
plot(temp_mod)

temp_mod_transect <- 

```

### Wharf Water Temp
```{r}
daily_3yr_dat %>% 
  ggplot(aes(x = wharf_temp)) +
    geom_histogram(binwidth = 0.5)

daily_3yr_dat %>% 
  filter(total_unique != 0) %>% 
  ggplot(aes(x = wharf_temp, y = total_unique)) +
    geom_point()

temp_mod <- lm(log(total_unique) ~ wharf_temp, data = (daily_3yr_dat %>% filter(total_unique != 0)))
summary(temp_mod)
plot(temp_mod)

temp_mod_0 <- lm(log1p(total_unique) ~ wharf_temp, data = daily_3yr_dat)
summary(temp_mod_0)
plot(temp_mod)

#no linear relationship between wharf temp and total unique (with or without total = 0)

daily_3yr_dat <- mutate(daily_3yr_dat, wharf_temp2 = (wharf_temp)^2)

temp_mod2 <- lm(log(total_unique) ~ wharf_temp + wharf_temp2, data = (daily_3yr_dat %>% filter(total_unique != 0)))
summary(temp_mod2)

temp_mod2_0 <- lm(log1p(total_unique) ~ wharf_temp + wharf_temp2, data = daily_3yr_dat)
summary(temp_mod2_0)

#no quadratic relationship between wharf temp and total unique (with or without total = 0)

daily_3yr_dat %>%
  filter(year(transect_datetime) == 2020) %>% 
  filter(total_unique != 0) %>% 
  ggplot(aes(x = wharf_temp, y = total_unique)) +
    geom_point()

daily_3yr_dat %>% 
  #filter(transect_total_density != 0) %>% 
  ggplot(aes(x = wharf_temp, y = transect_total_density)) +
    geom_point() +
    geom_smooth(method = "lm")

daily_3yr_dat %>% 
  filter(manual_total_density != 0) %>% 
  ggplot(aes(x = wharf_temp, y = manual_total_density)) +
    geom_point() +
    geom_smooth(method = "loess")
```

### Padaro Water Temp
```{r}
daily_3yr_dat %>% 
  ggplot(aes(x = water_temp_bucket)) +
    geom_histogram(binwidth = 0.5)

daily_3yr_dat %>% 
  #filter(total_unique != 0) %>% 
  ggplot(aes(x = water_temp_bucket, y = log1p(total_unique))) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE)
ggsave("plots/bucket_lm_plot.png")

temp_mod <- lm(log(total_unique) ~ water_temp_bucket, data = (daily_3yr_dat %>% filter(total_unique != 0)))
summary(temp_mod)
plot(temp_mod)

temp_mod_0 <- lm(log1p(total_unique) ~ water_temp_bucket, data = daily_3yr_dat)
summary(temp_mod_0)
plot(temp_mod_0)

# significant linear relationship between padaro temp and total unique (with or without total = 0)

daily_3yr_dat <- mutate(daily_3yr_dat, water_temp_bucket2 = (water_temp_bucket)^2)

temp_mod2 <- lm(log(total_unique) ~ water_temp_bucket + water_temp_bucket2, data = (daily_3yr_dat %>% filter(total_unique != 0)))
summary(temp_mod2)

temp_mod2_0 <- lm(log1p(total_unique) ~ water_temp_bucket + water_temp_bucket2, data = daily_3yr_dat)
summary(temp_mod2_0)

#no quadratic relationship between padaro temp and total unique (with or without total = 0)

daily_3yr_dat %>%
  filter(year(transect_datetime) == 2020) %>% 
  filter(total_unique != 0) %>% 
  ggplot(aes(x = water_temp_bucket, y = total_unique)) +
    geom_point()

daily_3yr_dat %>% 
  #filter(transect_total_density != 0) %>% 
  ggplot(aes(x = water_temp_bucket, y = transect_total_density)) +
    geom_point() +
    geom_smooth(method = "lm")

daily_3yr_dat %>% 
  filter(manual_total_density != 0) %>% 
  ggplot(aes(x = water_temp_bucket, y = manual_total_density)) +
    geom_point() +
    geom_smooth(method = "loess")
```

### Swell
```{r}
daily_3yr_dat %>% 
  ggplot(aes(x = WVHT_m)) +
    geom_histogram(binwidth = 0.1)

dat_no_19 %>%
  ggplot(aes(x = total_unique)) +
    geom_histogram(binwidth = 1)

dat_no_19 %>% 
  filter(total_unique != 0) %>% 
  ggplot(aes(x = WVHT_m, y = total_unique)) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE)
ggsave("plots/wvht_lm_plot.png")

wvht_mod <- lm(log1p(total_unique) ~ log(WVHT_m), data = (dat_no_19))
summary(wvht_mod)
# highly significant correlation between wave height and abundance, r2 = 0.15
#slope is negative (see predictions below)
plot(wvht_mod)

shapiro.test(dat_no_19 %>% mutate(total_unique = log1p(total_unique)) %>% .$total_unique)
# not normal even w/ log transformation
dat_no_19 %>% 
  filter(total_unique > 0) %>% 
  #mutate(total_unique = log10(total_unique)) %>% 
  ggplot(aes(x = total_unique)) +
    geom_histogram()

shapiro.test(dat_no_19 %>%  mutate(WVHT_m = log(WVHT_m)) %>% .$WVHT_m)
# normal w/ log transformation

wvht_sim <- simulateResiduals(fittedModel = wvht_mod, plot = F, n = 1000)
testResiduals(wvht_sim, plot = T)
#looks good
predict(wvht_mod, data.frame(WVHT_m = 1))
# 0.5 m swell = 1.41 individuals, 1 m swell = 0.78, 1.5 m swell = 0.40, 2 m swell = 0.14

daily_3yr_dat %>% 
  ggplot(aes(x = MWD)) +
    geom_histogram(binwidth = 5)

dat_no_19 %>% 
  ggplot(aes(x = MWD, y = total_unique)) +
    geom_point() +
    geom_smooth(method = "lm")

wvdir_mod <- lm(log1p(total_unique) ~ MWD, data = (dat_no_19))
summary(wvdir_mod)
```

### Other
```{r}
daily_3yr_dat %>% 
  #filter(total_unique != 0) %>% 
  ggplot(aes(x = pressure, y = total_unique)) +
    geom_point()

daily_3yr_dat %>% 
  #filter(total_unique != 0) %>% 
  ggplot(aes(x = salinity, y = total_unique)) +
    geom_point()

daily_3yr_dat %>% 
  filter(total_unique != 0) %>% 
  ggplot(aes(x = chlorophyll, y = total_unique)) +
    geom_point() +
    geom_smooth(method = "lm")
```

## Morning vs afternoon abundance
```{r}
daily_3yr_dat %>%
  filter(hh < 12) %>% 
  drop_na(total_unique) %>% 
  dplyr::summarize(mean = mean(total_unique), days = n()) 

daily_3yr_dat %>% 
  filter(hh >= 12) %>% 
  drop_na(total_unique) %>% 
  dplyr::summarize(mean = mean(total_unique), days = n()) 

dat_2020 %>% 
  ggplot(aes(x = hms::as_hms(datetime), y = total_unique)) +
    geom_point()

dat_2020 %>% 
  ggplot(aes(x = hour(datetime))) +
    geom_histogram(bins = 6, color = "white")
ggsave("plots/2020_time_histogram.png", width = 7, height = 5)

dat_2019 %>% 
  ggplot(aes(x = hour(datetime))) +
    geom_histogram(binwidth = 1, color = "white")
ggsave("plots/2019_time_histogram.png", width = 7, height = 5)

View(dat_2021)

daily_3yr_dat %>%
  #filter(month(datetime) > 6, month(datetime) < 8) %>% 
  dplyr::group_by(hh) %>%
  drop_na(total_unique) %>%
  dplyr::summarize(Abundance = list(mean_se(total_unique))) %>%
  unnest(Abundance) %>% 
  dplyr::rename(Hour = 1, Abundance = y) %>% 
  ggplot(aes(x = Hour, y = Abundance)) +
    geom_bar(stat = "identity") +
    #geom_errorbar(aes(ymax = ymax, ymin = ymin), size = 0.5, width = 0.2) +
    geom_vline(xintercept = 11.5, size = 1) +
    annotate("text", label = "Morning mean: 1.66 (n = 82)", x = 9, y = 3.5) +
    annotate("text", label = "Afternoon mean: 3.19 (n = 70)", x = 15, y = 5.2) +
    theme_classic()
ggsave("plots/3yr_am_vs_pm.png", width = 7, height = 5)
```

```{r}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
Mode(size_dat_2020$length)

size_dat_2020 %>% 
  slice(1:201) %>% 
   ggplot(aes(x = length))+
    geom_histogram()

size_dat_2020 %>% 
  slice(1:201) %>% 
  summarize(mean = mean(length, na.rm = TRUE))

size_dat_2020 %>% 
  slice(202:nrow(size_dat_2020)) %>% 
   ggplot(aes(x = length))+
    geom_histogram()

size_dat_2020 %>% 
  slice(202:nrow(size_dat_2020)) %>% 
  summarize(mean = mean(length, na.rm = TRUE))

dat_2020 %>% 
  slice(1:86) %>% 
  summarize(daily_avg = sum(total_unique, na.rm = TRUE)/86)

dat_2020 %>% 
  slice(86:nrow(dat_2020)) %>% 
  summarize(daily_avg = sum(total_unique, na.rm = TRUE)/((nrow(dat_2020))-86))
```

## Size over Time

### Individual years
```{r}
size_dat_2020 %>%
  drop_na(length) %>%
  filter(unique == "Y") %>% 
  dplyr::group_by(date) %>% 
  dplyr::summarize(mean_length = mean(length_m)) %>% 
  ggplot(aes(x = date, y = mean_length)) + 
    geom_point() +
    geom_smooth()

size_dat_2020 %>% 
  filter(unique == "Y") %>%
  ggplot(aes(x = date, y = length_m)) + 
    geom_point() + 
    geom_smooth

#2021:
size_dat_2021 %>% 
  filter(unique == "Y") %>%
  filter(length_adj_m > 0) %>% 
  ggplot(aes(x = mdy(date), y = length_adj_m)) + 
    geom_point() +
    geom_smooth(method = "lm", se = F) +
    theme_clean() +
    scale_x_date(date_labels = "%B", breaks = "1 month") +
    labs(x = "Date", y = "Length (m)")
ggsave("plots/2021_size_regression.png", width = 5, height = 5)

size_lm_2021 <- lm(length_m ~ date, data = size_dat_2021)
summary(size_lm_2021)

#2021, quadratic:
size_dat_2021 <- mutate(size_dat_2021, date2 = (as.numeric(date))^2)

size_dat_2021 %>% 
  filter(unique == "Y") %>%
  ggplot(aes(x = mdy(date), y = length_adj_m)) + 
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = F) +
    theme_clean() +
    scale_x_date(date_labels = "%B", breaks = "1 month") +
    labs(x = "Date", y = "Length (m)")
ggsave("plots/2021_size_regression_quad.png", width = 5, height = 5)

#need date as numeric or something for this to work
size_lm_2021_quad <- lm(length_adj_m ~ date + (date)^2, data = size_dat_2021)
summary(size_lm_2021_quad)
```

### Comparing size across years

Histogram of Daily Age Structure:
```{r}
size_classed_3yr %>% 
  mutate(prop = juvenile/(juvenile + adult)) %>% 
  ggplot(aes(x = prop)) +
    geom_histogram()

#no 2019:
size_classed_3yr %>%
  dplyr::slice(-c(1:19)) %>% 
  mutate(prop = juvenile/(juvenile + adult)) %>% 
  ggplot(aes(x = prop)) +
    geom_histogram()

#2020 only:
size_classed_3yr %>%
  dplyr::slice(-c(1:19, 71:144)) %>% 
  mutate(prop = juvenile/(juvenile + adult)) %>% 
  ggplot(aes(x = prop)) +
    geom_histogram()

#2021 only:
size_classed_3yr %>%
  dplyr::slice(-c(1:70)) %>% 
  mutate(prop = juvenile/(juvenile + adult)) %>% 
  ggplot(aes(x = prop)) +
    geom_histogram()
ggsave("plots/adult_swim.png")
#VERY pronounced bimodal distribution in 2021
#despite adults being just 40% of observations, there are MORE days where we saw only adults than where we saw only juveniles
#WHAT factors determine "adult swim" days???
```

Histogram faceted by year:
```{r}
size_dat_unique %>%
  filter(length_adj_m > 0) %>% 
  mutate(year = as_factor(year(mdy(date)))) %>%
  ggplot(aes(x = length_adj_m, fill = year)) +
    geom_histogram() +
    facet_grid(rows = vars(year)) +
    theme_cowplot() +
    labs(y = "Count", x = "Length (m)", fill = "Year") +
    theme(strip.text.y = element_blank()) +
    scale_fill_brewer(palette = "Dark2")
ggsave("plots/size_3yrs_histo.png", height = 5, width = 5)
```

Years overlaid:
```{r}
size_dat_unique %>%
  filter(length_adj_m > 0) %>% 
  mutate(day = as_date(yday(mdy(date)))) %>% 
  mutate(year = as_factor(year(mdy(date)))) %>% 
  ggplot(aes(x = day, y = length_adj_m)) +
    geom_point(aes(color = year), alpha = 0.8) +
    geom_smooth() +
    theme_clean() +
    scale_x_date(date_labels = "%B", breaks = "1 month") +
    labs(x = "Date", y = "Length (m)", color = "Year") +
    scale_color_brewer(palette = "Dark2")
    #geom_hline(yintercept = 3)
ggsave("plots/size_3yrs_scatter.png", height = 5, width = 9)
```

years overlaid, separate regressions:
```{r}
size_dat_unique %>% 
  ggplot(aes(x = as_date(yday(date)), y = length, color = as.factor(year))) +
    geom_point(alpha = 0.2) +
    geom_smooth(method= "lm", se = F) +
    theme_clean() +
    scale_x_date(date_labels = "%b", breaks = "1 month") +
    labs(x = "Date", y = "Length (m)", color = "Year") +
    scale_color_brewer(palette = "Set1")
ggsave("plots/size_3yrs_scatter_regressions.png", height = 5, width = 5)

#years overlaid, windowed:
size_dat_unique %>% 
  filter(yday(date) > 149 & yday(date) < 313) %>% 
  ggplot(aes(x = as_date(yday(date)), y = length)) +
    geom_point() +
    #geom_smooth() +
    theme_clean() +
    scale_x_date(date_labels = "%B", breaks = "1 month") +
    labs(x = "Date", y = "Length (m)") +
    scale_color_brewer(palette = "Set1")
    #geom_hline(yintercept = 3)
ggsave("plots/size_3yrs_scatter.png", height = 5, width = 9)

#years separated, violin plot, July-September:
size_dat_unique %>% 
  filter(month(date) == c(7:9)) %>% 
  ggplot(aes(x = as.factor(year), y = length)) +
    geom_violin(fill = "dodgerblue") #+
    #geom_hline(yintercept = 3)
ggsave("plots/size_violin_july-sept.png")

#years separated, box plot:
size_dat_unique %>% 
  filter(length < 5) %>% 
  ggplot(aes(x = as.factor(year(date)), y = length, color = as.factor(year(date)))) +
    geom_boxplot(show.legend = FALSE) +
    theme_clean() +
    theme(panel.background = element_blank(),
          plot.background = element_blank(),
          legend.background = element_rect(fill = 'transparent'),
          panel.border = element_blank()) +
    labs(x = "Date", y = "Length (m)") +
    scale_color_brewer(palette = "Set1")
ggsave("plots/size_3yrs_box.png", width = 4, height = 5)

year_size_mod <- aov(length ~ as.factor(year(date)), data = size_dat_unique)
summary(year_size_mod)
plot(year_size_mod)
TukeyHSD(year_size_mod)
```

```{r}
#years separated, overlap window, box plot:
size_dat_unique %>% 
  filter(yday(date) > 149 & yday(date) < 313) %>% 
  ggplot(aes(x = as.factor(year(date)), y = length, color = as.factor(year(date)))) +
    geom_boxplot(show.legend = FALSE) +
    theme_clean() +
    labs(x = "Date", y = "Length (m)") +
    scale_color_brewer(palette = "Set1")
ggsave("plots/size_3yrs_box_windowed.png", width = 4, height = 5)

#size summary table in FEET
size_dat_unique %>% 
  group_by(year) %>% 
  summarize(min = min(length_ft, na.rm = TRUE),
            max = max(length_ft, na.rm = TRUE),
            median = round(mean(length_ft, na.rm = TRUE), digits = 1),
            "Juveniles" = sum(size_class == "Juvenile", na.rm = TRUE),
            "Adults" = sum(size_class == "Adult", na.rm = TRUE),
            "Juveniles per Adult" = sum(size_class == "Juvenile", na.rm = TRUE)/
                                    sum(size_class == "Adult", na.rm = TRUE))

#size summary table in METERS, percentage adults
yearly_size_summary <- size_dat_unique %>% 
  group_by(year) %>% 
  summarize("Mean TL" = mean(length, na.rm = TRUE),
            min = min(length, na.rm = TRUE),
            max = max(length, na.rm = TRUE),
            "Juveniles" = sum(size_class == "Juvenile", na.rm = TRUE),
            "Adults" = sum(size_class == "Adult", na.rm = TRUE),
            "Percent Adults" = 
              sum(size_class == "Adult", na.rm = TRUE)/
                (sum(size_class == "Juvenile", na.rm = TRUE) +
                 sum(size_class == "Adult", na.rm = TRUE))) %>%
  gt() %>%
    fmt_number(2:4, decimals = 1) %>% 
    fmt_number(7, decimals = 2) %>% 
    fmt_number(5:6, decimals = 0) %>% 
    cols_merge_range(3,4) %>% 
    cols_label("year" = "Year", "min" = "Range") %>% 
    cols_width("Percent Adults" ~ px(100)) %>% 
    cols_align(align = "center")
yearly_size_summary
gtsave(yearly_size_summary, "plots/yearly_size_summary_table.png")

#size summary table in METERS, juveniles per adult
size_dat_unique %>% 
  group_by(year) %>% 
  summarize("Mean TL" = mean(length, na.rm = TRUE),
            min = min(length, na.rm = TRUE),
            max = max(length, na.rm = TRUE),
            "Juveniles" = sum(size_class == "Juvenile", na.rm = TRUE),
            "Adults" = sum(size_class == "Adult", na.rm = TRUE),
            "Juveniles per Adult" = 
              sum(size_class == "Juvenile", na.rm = TRUE)/
              sum(size_class == "Adult", na.rm = TRUE)) %>% 
  gt() %>% 
    fmt_number(7, decimals = 1) %>% 
    fmt_number(5:6, decimals = 0) %>% 
    cols_merge_range(3,4) %>% 
    cols_label("year" = "Year", "min" = "Range")
```

## Haphazard vs Transect Visualizations
```{r}
dat_2020 %>% 
  filter(total_unique > 0) %>% 
  filter(!is.na(manual_total), !is.na(transect_total)) %>% 
  dplyr::rename(Date = date, Haphazard = manual_total, Transect = transect_total) %>% 
  dplyr::select(Date, Haphazard, Transect) %>%
  gather("Flight", "Abundance", 2:3) %>%
  pad(interval = "day", start_val = as.Date("2020-06-24")) %>%
  replace_na(list(Flight = "DNF", Abundance = -0.1)) %>%
  ggplot(aes(x = Date, y = Abundance)) + 
    geom_bar(aes(fill = Flight), stat = "identity", position = "dodge") +
    scale_x_date(date_breaks = "1 week", date_labels = "%b %e", limits = c(as.Date("2020-06-27"), as.Date("2020-12-15")))+
    scale_y_continuous(breaks = 1:10) +
    scale_fill_manual(values = brewer.pal(8, "Dark2")[c(8,1,2)], "") + theme_wsj() + theme(plot.title = element_text(size=40), legend.text = element_text(size = 16), axis.text = element_text(size = 16)) +
    labs(title = "2020 Great White Shark Abundance, 6/24 - DD/MM")
ggsave("plots/wsj_survey_comp_plot.png", width = 16, height = 9)

daily_3yr_dat %>%
  select(transect_total, manual_unique) %>% 
  dplyr::rename(Transect = transect_total, Manual = manual_unique) %>% 
  gather("Method", "Abundance", 1:2) %>%
  drop_na() %>% 
  group_by(Method) %>% 
  dplyr::summarize(Mean_Abundance = list(mean_se(Abundance))) %>%
  unnest(Mean_Abundance) %>% 
    ggplot(aes(x = Method, y = y, fill = Method)) +
      geom_bar(stat = "identity") +
      geom_errorbar(aes(ymax = ymax, ymin = ymin), size = 1.5, width = 0.2) +
      scale_fill_manual(values = c("red3", "dodgerblue")) +
      scale_y_continuous(name = "Mean Abundance") +
      theme_classic() +
      theme(legend.position = "none") +
      theme(axis.title = element_text(size = 14), axis.text = element_text(size = 14))
      
ggsave("plots/3yr_methods_abundance.png", width = 7, height = 7)

daily_3yr_dat %>%
  select(transect_total_density, manual_total_density) %>% 
  dplyr::rename(Transect = transect_total_density, Manual = manual_total_density) %>% 
  gather("Method", "Density", 1:2) %>%
  drop_na() %>% 
  group_by(Method) %>% 
  dplyr::summarize(Mean_Density = list(mean_se(Density))) %>%
  unnest(Mean_Density) %>% 
    ggplot(aes(x = Method, y = y, fill = Method)) +
      geom_bar(stat = "identity") +
      geom_errorbar(aes(ymax = ymax, ymin = ymin), size = 1.5, width = 0.2) +
      scale_fill_manual(values = c("red3", "dodgerblue")) +
      scale_y_continuous(name = "Mean Density (individuals/km2/min)") +
      theme_classic() +
      theme(legend.position = "none") +
      theme(axis.title = element_text(size = 14), axis.text = element_text(size = 14))
  
ggsave("plots/3yr_methods_density.png", width = 7, height = 7)

daily_3yr_dat %>%
  mutate(transect_frequency = transect_total/transect_duration_min,
         manual_frequency = manual_unique/manual_duration_min) %>% 
  select(transect_frequency, manual_frequency) %>%
  dplyr::rename(Transect = transect_frequency, Manual = manual_frequency) %>%
  gather("Method", "Frequency", 1:2) %>%
  drop_na() %>% 
  group_by(Method) %>% 
  dplyr::summarize(Mean_Freq = list(mean_se(Frequency))) %>%
  unnest(Mean_Freq) %>% 
    ggplot(aes(x = Method, y = y, fill = Method)) +
      geom_bar(stat = "identity") +
      geom_errorbar(aes(ymax = ymax, ymin = ymin), size = 1.5, width = 0.2) +
      scale_fill_manual(values = c("red3", "dodgerblue")) +
      scale_y_continuous(name = "Mean Frequency (individuals/min)") +
      theme_classic() +
      theme(legend.position = "none") +
      theme(axis.title = element_text(size = 14), axis.text = element_text(size = 14))

# Density WITHOUT time:
dat_2020 %>%
  mutate(transect_density = transect_total/transect_area_km2,
         manual_density = manual_unique/manual_area_km2) %>% 
  select(transect_density, manual_density) %>%
  dplyr::rename(Transect = transect_density, Manual = manual_density) %>%
  gather("Method", "Density", 1:2) %>%
  drop_na() %>% 
  group_by(Method) %>% 
  dplyr::summarize(Mean_Dens = list(mean_se(Density))) %>%
  unnest(Mean_Dens) %>% 
    ggplot(aes(x = Method, y = y, fill = Method)) +
      geom_bar(stat = "identity") +
      geom_errorbar(aes(ymax = ymax, ymin = ymin), size = 1.5, width = 0.2) +
      scale_fill_manual(values = c("red3", "dodgerblue")) +
      scale_y_continuous(name = "Mean Density (individuals/km2)") +
      theme_classic() +
      theme(legend.position = "none") +
      theme(axis.title = element_text(size = 14), axis.text = element_text(size = 14))
```

## Comparative Analysis of Methods
```{r}
daily_3yr_dat %>%
  select(transect_total, manual_unique) %>%
  dplyr::rename(Transect = transect_total, Manual = manual_unique) %>%
  gather("Method", "Density", 1:2) %>%
  group_by(Method) %>% 
  summarize(mean = list(mean_se(Density))) %>% 
  unnest(mean) %>%
  mutate(se = ymax - y) %>% 
  View()

daily_3yr_dat %>%
  select(transect_total, manual_unique) %>%
  dplyr::rename(Transect = transect_total, Manual = manual_unique) %>%
  gather("Method", "Density", 1:2) %>%
  drop_na() %>%
  t.test(Density ~ Method, .)
  
shapiro.test(daily_3yr_dat$transect_total_density) 
shapiro.test(daily_3yr_dat$manual_unique) 

daily_3yr_dat %>% 
  ggplot(aes(x = transect_total_density)) +
    geom_density()

daily_3yr_dat %>% 
  ggplot(aes(x = manual_total_density)) +
    geom_density()

# Abundance
daily_3yr_dat %>%
  select(transect_total, manual_unique) %>%
  dplyr::rename(Transect = transect_total, Manual = manual_unique) %>%
  gather("Method", "Density", 1:2) %>%
  drop_na() %>%
  wilcox.test(Density ~ Method, ., conf.int = TRUE)

# Manual abundance (mean = 2.3, SE = 0.20) was higher than transect abundance (mean = 1.3, SE = 0.14, p < 0.001)

# Effort-Corrected Density:
daily_3yr_dat %>%
  select(transect_total_density, manual_total_density) %>%
  dplyr::rename(Transect = transect_total_density, Manual = manual_total_density) %>%
  gather("Method", "Density", 1:2) %>%
  group_by(Method) %>% 
  summarize(mean = list(mean_se(Density))) %>% 
  unnest(mean) %>%
  mutate(se = ymax - y) %>% 
  View()

daily_3yr_dat %>%
  select(transect_total_density, manual_total_density) %>%
  dplyr::rename(Transect = transect_total_density, Manual = manual_total_density) %>%
  gather("Method", "Density", 1:2) %>%
  group_by(Method) %>%
  summarize(mean = list(mean_se(Density))) %>% 
  unnest(mean) %>% 
  rename("Density" = y) %>% 
  ggplot(aes(x = Method, y = Density)) +
    geom_bar(stat = "identity") +
    geom_errorbar(aes(ymax = ymax, ymin = ymin), width = 0.4)
ggsave("plots/methods_comp_plot.png")

daily_3yr_dat %>%
  select(transect_total_density, manual_total_density) %>%
  dplyr::rename(Transect = transect_total_density, Manual = manual_total_density) %>%
  gather("Method", "Density", 1:2) %>%
  drop_na() %>%
  wilcox.test(Density ~ Method, ., conf.int = TRUE)

# Manual effort-corrected density (mean = 0.64, SE = 0.1) was higher than transect abundance (mean = 0.48, SE = 0.06, p < 0.001)

# Raw Density:
dat_2020 %>%
  mutate(transect_density = transect_total/transect_area_km2,
         manual_density = manual_unique/manual_area_km2) %>% 
  select(transect_density, manual_density) %>%
  dplyr::rename(Transect = transect_density, Manual = manual_density) %>%
  gather("Method", "Density", 1:2) %>%
  drop_na() %>% 
  group_by(Method) %>% 
  dplyr::summarize(Mean_Dens = list(mean_se(Density))) %>%
  unnest(Mean_Dens)

daily_3yr_dat %>% 
  ggplot(aes(x = transect_total/transect_area_km2)) +
    geom_density()

daily_3yr_dat %>% 
  ggplot(aes(x = manual_unique/manual_area_km2)) +
    geom_density()

dat_2020 %>%
  mutate(transect_density = transect_total/transect_area_km2,
         manual_density = manual_unique/manual_area_km2) %>% 
  select(transect_density, manual_density) %>%
  dplyr::rename(Transect = transect_density, Manual = manual_density) %>%
  gather("Method", "Density", 1:2) %>%
  drop_na() %>%
  wilcox.test(Density ~ Method, ., conf.int = TRUE)
## Manual density (mean = 7.12, SE = 1.05) was not higher than transect density (mean = 6.78, SE = 0.06, p < 0.001)
```

## Heatmaps

### All 3 years
```{r}
size_dat_3yr %>%
  filter(video_YN == "manual" | video_YN == "manual_1" | video_YN == "manual_2") %>% 
  filter(unique == "Y") %>%
  #filter(!is.na(length)) %>% 
  ggplot(aes(x = long, y = lat)) +
    geom_point() +
    geom_smooth()
#follows a certain distance from the coastline

size_dat_unique %>%
  filter(video_YN == "manual" | video_YN == "manual_1" | video_YN == "manual_2") %>%
  ggplot(aes(x = long, y = lat)) +
    geom_hex(bins = 15) +
    scale_fill_distiller(palette = "YlOrRd", direction = 1) +
    theme_classic() +
    geom_point(aes(x = -119.56, y = 34.405), color = "darkblue", alpha = 0.2)
ggsave("plots/heatmap_3yrs.png", width = 6, height = 4)

size_dat_3yr %>%
  filter(video_YN == "inner" | video_YN == "outer") %>%
  filter(unique == "Y") %>%
  filter(!is.na(length_adj_m)) %>%
  dplyr::filter(lat > 0) %>% 
  ggplot(aes(x = long, y = lat)) +
    geom_hex(bins = 15) +
    scale_fill_distiller(palette = "YlOrRd", direction = 1) +
    theme_classic() +
    geom_point(aes(x = -119.56, y = 34.405))

View(size_dat_3yr)
```

### All Sharks, 2020
```{r}
size_dat_2020 %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length)) %>% 
  ggplot(aes(x = long, y = lat)) +
    geom_point(aes(color = size_class))

size_dat_2020 %>% 
  filter(unique == "Y") %>%
  filter(!is.na(length)) %>%
  ggplot(aes(x = long, y = lat)) +
  geom_hex(bins = 12) +
  scale_fill_distiller(palette = "YlOrRd", direction = 1) +
  theme_classic()
ggsave("grfp_hexmap.png")

register_google(key = "[AIzaSyDmz6xT3R938U6s5VWXuguMSq6ROr3X2KM]", write = TRUE)

location <- c(-120, 34, -119, 35)

carp <- get_map(location = location, source = "osm", zoom = 7)

ggmap(carp) +
  geom_hex(data = size_dat_2020, aes(x = long, y = lat), bins = 12) +
  scale_fill_distiller(palette = "YlOrRd", direction = 1) +
  theme_classic()
```

### Juveniles, 2020
```{r}
size_dat_2020 %>%
  drop_na(lat, size_class) %>%
  filter(size_class == "Juvenile") %>% 
  filter(unique == "Y") %>%
  ggplot(aes(x = long, y = lat)) +
    geom_hex(bins = 12) +
    scale_fill_distiller(palette = "YlOrRd", direction = 1) +
    theme_classic() +
    theme(panel.background = element_rect(fill = "black"))
ggsave("plots/2020_juvenile_heatmap.png", width = 7, height = 6)
```

### Adults, 2020
```{r}
size_dat_2020 %>%
  drop_na(lat, size_class) %>%
  filter(size_class == "Adult") %>% 
  filter(unique == "Y") %>%
  ggplot(aes(x = long, y = lat)) +
    geom_hex(bins = 12) +
    scale_fill_distiller(palette = "YlOrRd", direction = 1) +
    theme_classic() +
    theme(panel.background = element_rect(fill = "black"))
ggsave("plots/2020_adult_heatmap.png", width = 7, height = 6)

mean(size_dat_2020$length_m, na.rm = TRUE)
median(size_dat_2020$length, na.rm = TRUE)

sum(size_dat_2020$size_class == "Adult" & size_dat_2020$unique == "Y", na.rm = "TRUE")/sum(size_dat_2020$unique == "Y", na.rm = "TRUE")
```



# Modelling

## Factors affecting total manual density
```{r}
dat_no_19 <- daily_3yr_dat %>% 
  filter(year(transect_datetime) != 2019) %>% 
  mutate(hour = hour(transect_datetime))

total_density_mod <- glmmTMB(manual_unique ~ offset(log(manual_effort)) + wharf_temp + hour, data = dat_no_19, family = poisson, ziformula = ~1)

total_density_sim <- simulateResiduals(fittedModel = total_density_mod, plot = F, n = 1000)
testResiduals(ratio_sim, plot = T)

dredge(total_density_mod)
#time of day, wharf temp, and manual effort are all predictors in best fit model, model without hour has weight of 0.234

summary(total_density_mod)
#hour significant, wharf temp not

plot(allEffects(total_density_mod))
```

## Factors affecting ratio of juveniles to adults NOT WORKING
```{r}
dat_no_19 <- dat_no_19 %>% 
  mutate(hour = hour(transect_datetime))

View(dat_no_19)

ratio_mod <- glmmTMB(cbind(manual_small, manual_large) ~ offset(log(manual_effort)) + wharf_temp + hour, data = dat_no_19, family = binomial)

ratio_sim <- simulateResiduals(fittedModel = ratio_mod, plot = F, n = 1000)
testResiduals(ratio_sim, plot = T)

ratio_mod2 <- glmmTMB(cbind(manual_small, manual_large) ~ offset(log(manual_effort)) + wharf_temp, data = dat_no_19, family = binomial)

AICctab(ratio_mod, ratio_mod2)

dredge(ratio_mod)
#not working?

summary(ratio_mod)
# hour significant, wharf temp not
plot(allEffects(ratio_mod))

summary(ratio_mod2)
# higher AIC than temp + hour model

emmeans(ratio_mod)
```

## Modelling Transect vs Manual abundance estimates
```{r}


```

## Modelling Time of Day Effects on Abundance, 2020
```{r}
View(dat_2020_full)
ggplot(aes(x = total_unique), data = dat_2020) +
  geom_bar()

diel_model <- glmmTMB(total_unique ~ hour(datetime.x) + mean_wtemp_previous_24 + WVHT_m + vis + beaufort, data = dat_2020_full, family = nbinom2)
dredge(diel_model)

diel_mod_1 <- glmmTMB(total_unique ~ mean_wtemp_previous_24 + WVHT_m + vis, data = dat_2020_full, family = nbinom2)

fam_list <- list(family = alist(
    binomial = binomial,
    genpois = genpois,
    poisson = poisson,
    nbinom1 = nbinom1,
    nbinom2 = nbinom2,
    ))

getAllTerms(diel_mod_1)

dredge(diel_mod_1, fixed = ~ cond(mean_wtemp_previous_24) + cond(vis) + cond(WVHT_m), varying = fam_list)

diel_mod <- update(diel_mod_1, family = nbinom1)
dredge(diel_mod)

summary(diel_mod)

diel_simulationOutput <- simulateResiduals(fittedModel = diel_mod, n = 250)
plotSimulatedResiduals(simulationOutput = diel_simulationOutput)
testOverdispersion(diel_mod)

plot(allEffects(diel_model), partial.residuals = TRUE)
```

## Abundance Histogram, 2020
```{r}
dat_2020 %>% 
  #filter(total_unique != 0) %>%
  gather("Size", "Abundance", 20:21) %>% 
  ggplot(aes(x = Abundance, fill = Size)) +
    geom_bar(position = "dodge") +
    scale_x_continuous(breaks = 0:10) +
    theme_classic()
```

## Comparing size between methods
```{r}
joined_2020 %>% 
  filter(video.y == "outer") %>% 
  summarize(mean = mean(length_m, na.rm = TRUE))
# mean size on outer transect is 2.88

joined_2020 %>% 
  filter(video.y == "outer") %>%
  nrow()
# only 13 sharks seen in outer video?

joined_2020 %>% 
  filter(video.y == "inner") %>% 
  summarize(mean = mean(length_m, na.rm = TRUE))
# mean size on inner transect is 2.49

joined_2020 %>% 
  filter(video.y == "inner") %>%
  nrow()
# 65 sharks in inner video

joined_2020 %>% 
  filter(video.y != "manual") %>% 
  summarize(mean = mean(length_m, na.rm = TRUE))
#mean size for transect flights overall is 2.55

joined_2020 %>% 
  filter(video.y == "manual") %>% 
  summarize(mean = mean(length_m, na.rm = TRUE))
#mean size on manual flights in 2.43 - bias towards larger sharks in transect flights?

#Comparing abundance estimates between methods:
aov_method_abund_dat <- dat_2020 %>% 
                      dplyr::select(date, transect_total, manual_unique) %>% 
                      slice(23:nrow(dat_2020)) %>%
                      filter(!is.na(transect_total)) %>%
                      filter(!is.na(manual_unique)) %>%
                      gather("method", "abundance", 2:3)

aov_method_abund_2_dat <- dat_2020 %>% 
                        dplyr::select(date, transect_total, haphazard_unique) %>% 
                        slice(23:nrow(dat_2020)) %>%
                        gather("method", "abundance", 2:3) %>% 
                        filter(!is.na(abundance))

aov_method_abund_dat_no_zero <- dat_2020 %>% 
                      dplyr::select(date, transect_total, manual_unique) %>% 
                      slice(23:nrow(dat_2020)) %>%
                      filter(!is.na(transect_total)) %>%
                      filter(!is.na(manual_unique)) %>%
                      filter(transect_total != 0) %>% 
                      filter(manual_unique != 0) %>%
                      gather("method", "abundance", 2:3)

pairwise.t.test(log1p(aov_method_abund_dat$abundance), aov_method_abund_dat$method)
# p = 0.017
# IMPORTANT: I'm not sure how the NAs affect this - First version removes all dates with an NA for either method, while second version only removes the method that has the NA. First version makes more sense to me.

leveneTest(log1p(abundance) ~ method, data = aov_method_abund_dat)
#approximately equal variances

qqPlot(log1p(aov_method_abund_dat$abundance))
# lol

aov_method_abund_dat %>% 
  ggplot(aes(x = abundance)) +
    geom_histogram()

pairwise.t.test(log1p(aov_method_abund_dat_no_zero$abundance), aov_method_abund_dat_no_zero$method)
#p = 0.042

leveneTest(abundance ~ method, data = aov_method_abund_dat_no_zero)
# fine

qqPlot(log(aov_method_abund_dat_no_zero$abundance))

shapiro.test(aov_method_abund_dat_no_zero$abundance)

#Comparing size estimates between methods:

size_dat_unique <- size_dat_unique %>% 
  mutate(method = ifelse(video == "manual", "manual", "transect"))

pairwise.t.test(size_dat_unique$length_m, size_dat_unique$method)
# p = 0.029

leveneTest(length_m ~ method, data = size_dat_unique)
#equal variances

qqPlot(size_dat_unique$length_m)
# lookin good

shapiro.test(size_dat_unique$length_m)
# hmm

size_dat_unique %>% 
  ggplot(aes(x = length_m)) +
    geom_histogram()
```


## Water temperature (old)
```{r}
mean(flights$water_temp, na.rm=T)

# number of days with each temp 
ggplot(flights, aes(x=water_temp))+
  geom_histogram(binwidth=0.5)+
  geom_vline(xintercept=64.90645, color="red")

# same as above but with channel temps 
ggplot(flights, aes(x=water_temp_channel))+
  geom_histogram(binwidth=0.5)+
  geom_vline(xintercept=64.90645, color="red")

# HOBO temp over time + shark data
temp_plot <- ggplot(flights, aes(x=date, y=water_temp, group=beach))+
  geom_line(size=0.5, linetype=5)+
  #geom_line(aes(y=water_temp)) +
  geom_hline(yintercept=64.90645, color="red") +
  #geom_hline(yintercept=mean(flights$water_temp), color="blue")+
  geom_smooth(se=T, color="blue", size=0.5)+
  geom_point(aes(color=detection, shape=detection), size=2) +
  scale_color_manual(values=c("black","forestgreen","red"))+
  scale_shape_manual(values=c(4,19,19))+
  theme_bw()
temp_plot
ggsave("temp_plot.png", width=10, height=7)

# same as above but with channel temps
ggplot(flights, aes(x=date, y=water_temp_channel, group=beach))+
  geom_line(size=0.5, linetype=5)+
  #geom_line(aes(y=water_temp_channel)) +
  geom_hline(yintercept=64.90645, color="red") +
  #geom_hline(yintercept=mean(flights$water_temp_channel), color="blue")+
  geom_smooth(se=F, color="blue", size=0.5)+
  geom_point(aes(color=detection, shape=detection), size=2) +
  scale_color_manual(values=c("black","forestgreen","red"))+
  scale_shape_manual(values=c(4,19,19))+
  theme_bw()

# Air and water temperature over time
ggplot(temps.long, aes(x=date, y=temp, group=type, color=type))+
  geom_line()+
  geom_hline(yintercept=64.90645)

#Air vs channel water temperature
ggplot(flights, aes(x=air_temp, y=water_temp_channel))+
  geom_point()+
  coord_cartesian(xlim=c(55,80))+
  geom_hline(yintercept=64.90645, color="red")+
  stat_smooth(method=lm, se=F, fullrange=T)
```

## Wind
```{r}
wind_avg <- flights %>% ddply(.(wind_dir), summarize, mean=mean(wind_spd)) %>% na.omit(.)
#View(wind_avg)

# Average speed of each direction
ggplot(wind_avg, aes(x=wind_dir, y=mean))+
  geom_bar(stat="identity")+
  coord_polar(theta="x", start=2.7, direction=-1)

# Histogram of wind directions
flights %>% drop_na("wind_dir") %>%
  ggplot(., aes(x=wind_dir))+
    geom_bar()+
    coord_polar(theta="x",start=2.7, direction=-1)

# Wind vs water temp
ggplot(flights, aes(x=wind_spd..kts., y=water_temp))+
  geom_point()+
  geom_smooth(method="lm", se=F)

# Wind vs sky
ggplot(flights, aes(x=wind_spd, y=sky))+
  geom_count()

# Wind vs waves
ggplot(flights, aes(x=wind_spd, y=swell))+
  geom_jitter()+
  geom_smooth(method=lm)
```

## Sky
```{r}
# sky condition vs detections/DNF
ggplot(flights, aes(x=sky, fill=detection))+
  geom_bar(position="stack")+
  scale_fill_manual(values=c("black", "forestgreen", "red"))
```


## Visibility
```{r}
# beaufort vs total abundance
dat_2020 %>% 
  slice(23:73) %>%
  group_by(beaufort) %>% 
  summarize(mean = list(mean_se(total_unique))) %>%
  unnest(mean) %>% 
  ggplot(aes(x = beaufort, y = y) )+
    geom_bar(stat = "identity") +
    geom_errorbar(aes(ymax = ymax, ymin = ymin), width = 0.2)

# vis vs total abundance
dat_2020 %>% 
  slice(23:73) %>%
  group_by(vis) %>% 
  summarize(mean = list(mean_se(total_unique))) %>%
  unnest(mean) %>% 
ggplot(aes(x = vis, y = y) )+
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymax = ymax, ymin = ymin), width = 0.2)
```

## Tide
```{r}
# tide over time + shark data
ggplot(flights, aes(x=date, y=tide, group=beach))+
  geom_line(size=0.5, linetype=2)+
  geom_point(aes(color=detection, shape=detection), size=2) +
  scale_color_manual(values=c("black","forestgreen","red"))+
  scale_shape_manual(values=c(4,19,19))+
  theme_bw()
```

# Detection analysis

```{r}
#count(flights, detection)
ggplot(dat_2019, aes(y=wind_spd, x=detection))+
  geom_point()+
  geom_smooth(se=F)
```

## t-test of small vs large abundance, 2020
```{r}
aov_dat <- dat_2020 %>% 
            dplyr::rename(Date = date, Small = transect_small, Large = transect_large) %>% 
            dplyr::select(Date, Small, Large) %>% 
            slice(23:nrow(dat_2020)) %>%
            filter(!is.na(Small)) %>%
            gather("Size", "Abundance", 2:3)

pairwise.t.test(aov_dat$Abundance, aov_dat$Size)

leveneTest(Abundance ~ Size, data = aov_dat)
```

## t-test of small vs large abundance, 2021
```{r}
aov_dat <- dat_2021 %>% 
            dplyr::rename(Date = date, Small = transect_small,
                          Large = transect_large) %>% 
            dplyr::select(Date, Small, Large) %>% 
            slice(23:nrow(dat_2021)) %>%
            filter(!is.na(Small)) %>%
            gather("Size", "Abundance", 2:3)

pairwise.t.test(aov_dat$Abundance, aov_dat$Size)

leveneTest(Abundance ~ Size, data = aov_dat)
```

## GLMs to test effects of water temp and sky condition on detections
```{r}
flights_DNF.rm <- filter(flights, detection!="DNF")
det_mod <- glm(detection~water_temp*sky,data=flights_DNF.rm,family=binomial(link="logit"),na.action="na.fail") 
dredge(det_mod)
```
* best model is null model, followed by ~wind_gust, then ~wind_speed

```{r}
DNF_1 <- glm(detection~wind_gust,data=flights,family=binomial(link="logit"))
summary(DNF_1)

ggplot(flights, aes(x=wind_gust, y=detection))+
  geom_count()
```
* even most-correlated variable wind_gust has insignificant effect on detection (p=0.441)

## Diagnostics
```{r}
DNF_simulationOutput <- simulateResiduals(fittedModel = DNF_1, n = 250)
plotSimulatedResiduals(simulationOutput = DNF_simulationOutput)
plotResiduals(flights$wind_spd, DNF_simulationOutput$scaledResiduals) #wonky residuals
#not sure what the differences between the two above lines are

testUniformity(simulationOutput = DNF_simulationOutput)
#testU gives QQ plot, looks normal

#effect plot
plot(allEffects(DNF_1), partial.residuals=TRUE)
```

# Swell analysis
```{r}
ggplot(flights, aes(x=log(swell)))+
  geom_histogram(binwidth=0.25)
```

## GLMs to test effects of wind speed, gust, and direction on swell height
```{r}
swell_mod <- glm(swell~wind_spd*wind_gust*wind_dir, data=flights, family=gaussian(link="log"), na.action="na.fail")
dredge(swell_mod)
```
* ~wind gust is best, but only somewhat better than null model and ~wind_speed

```{r}
swell_1 <- glm(swell~wind_gust, data=flights, family=gaussian(link="log"))
summary(swell_1)
```
* 1 kt increase in wind gust speed increases log wave height by 0.028; not a significant effect

```{r}
#diagnostics
swell_simulationOutput <- simulateResiduals(fittedModel = swell_1, n = 250)
plotSimulatedResiduals(simulationOutput = swell_simulationOutput)

plot(allEffects(swell_1), partial.residuals=TRUE)
```

# Water Temperature Analysis

```{r}
ggplot(flights, aes(x=water_temp))+
  geom_histogram(binwidth=1)
```


# GLMs to test effects of air temp, wind speed, gust and direction on water temp
```{r}
wt_mod <- glm(water_temp~air_temp*wind_spd*wind_gust*wind_dir, data=flights, family=gaussian(link="identity"), na.action="na.fail")
View(dredge(wt_mod))
```
* best two models (equal AIC) are 
  + 1) ~air_temp*wind_dir*wind_spd+wind_gust*wind_spd+wind_gust*wind_dir
  + 2) ~air_temp*wind_dir*wind_spd+wind_gust*wind_spd*wind_dir

```{r}
wt_1 <- glm(water_temp~air_temp*wind_dir*wind_spd+wind_gust*wind_spd*wind_dir, data=flights, family=gaussian(link="identity"))
summary(wt_1)
```
* way too many coefficients, re-doing dredge with max terms = 4

```{r}
dredge(wt_mod, m.max=4)
```
* ~air_temp is best model

```{r}
wt_2 <- glm(water_temp~air_temp, data=flights, family=gaussian(link="identity"))
summary(wt_2)
```
* 1 degree increase in air temp increases water temp by 0.27 degrees, marginally significant effect (p<0.1)